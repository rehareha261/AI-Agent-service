# ğŸ¯ Guide d'ImplÃ©mentation - DÃ©tection LLM Intelligente

**Date**: 11 octobre 2025  
**Objectif**: Permettre au LLM de dÃ©tecter automatiquement le langage du projet clonÃ© (Webflow, Python, etc.)

---

## ğŸ“‹ Ã‰tapes Ã  Suivre

### âœ… Ã‰tape 1 : Corriger le Module LLM Enhanced Detector (5 min)

**Fichier**: `utils/llm_enhanced_detector.py`

Le fichier a dÃ©jÃ  Ã©tÃ© crÃ©Ã© mais a une erreur d'import. Il faut juste vÃ©rifier qu'il n'y a plus d'erreurs :

```bash
cd /Users/rehareharanaivo/Desktop/AI-Agent
python -c "from utils.llm_enhanced_detector import detect_project_with_llm; print('âœ… Import OK')"
```

Si erreur, les imports sont dÃ©jÃ  corrigÃ©s. Passer Ã  l'Ã©tape suivante.

---

### âœ… Ã‰tape 2 : IntÃ©grer dans `implement_node.py` (15 min)

**Fichier Ã  modifier**: `nodes/implement_node.py`

**Ligne ~407** - Remplacer la fonction `_analyze_project_structure()` :

```python
async def _analyze_project_structure(claude_tool: ClaudeCodeTool) -> Dict[str, Any]:
    """
    Analyse la structure du projet avec enrichissement LLM.
    
    Combine dÃ©tection automatique + analyse LLM pour cas complexes.
    """
    try:
        # 1. Lister TOUS les fichiers
        ls_result = await claude_tool._arun(
            action="execute_command", 
            command="find . -type f -not -path './.git/*' -not -path './venv/*' -not -path './node_modules/*' | head -50"
        )
        
        structure_info = "Structure du projet:\n"
        files_found = []
        
        if ls_result["success"]:
            structure_info += ls_result["stdout"]
            files_found = ls_result["stdout"].strip().split('\n') if ls_result["stdout"].strip() else []
        
        # 2. Lire README si disponible
        readme_content = None
        try:
            readme_result = await claude_tool._arun(action="read_file", file_path="README.md", required=False)
            if readme_result["success"]:
                readme_content = readme_result.get("content", "")[:2000]
        except:
            pass
        
        # 3. Lire package.json si disponible
        package_json_content = None
        try:
            pkg_result = await claude_tool._arun(action="read_file", file_path="package.json", required=False)
            if pkg_result["success"]:
                package_json_content = pkg_result.get("content", "")[:1000]
        except:
            pass
        
        # 4. Lire requirements.txt si disponible
        requirements_content = None
        try:
            req_result = await claude_tool._arun(action="read_file", file_path="requirements.txt", required=False)
            if req_result["success"]:
                requirements_content = req_result.get("content", "")[:1000]
        except:
            pass
        
        # 5. âœ¨ NOUVEAU : DÃ©tection enrichie avec LLM
        from utils.llm_enhanced_detector import detect_project_with_llm
        
        logger.info("ğŸ¤– Analyse du projet avec enrichissement LLM...")
        
        enhanced_info = await detect_project_with_llm(
            files=files_found,
            readme_content=readme_content,
            package_json_content=package_json_content,
            requirements_txt_content=requirements_content,
            use_llm=True  # Activer l'analyse LLM
        )
        
        # 6. Logger les rÃ©sultats
        logger.info(f"ğŸ“Š Langage principal: {enhanced_info.primary_language.name} (confiance: {enhanced_info.confidence:.2f})")
        logger.info(f"ğŸ“Š Type de projet: {enhanced_info.project_type}")
        logger.info(f"ğŸ“Š Framework: {enhanced_info.framework or 'Aucun'}")
        logger.info(f"ğŸ“Š Stack technique: {', '.join(enhanced_info.tech_stack)}")
        logger.info(f"ğŸ“Š Architecture: {enhanced_info.architecture}")
        
        if enhanced_info.secondary_languages:
            logger.info(f"ğŸ“Š Langages secondaires: {', '.join(enhanced_info.secondary_languages)}")
        
        # 7. Construire le retour avec informations enrichies
        return {
            "language_info": enhanced_info.primary_language,
            "enhanced_info": enhanced_info,  # âœ¨ NOUVEAU
            "project_type": enhanced_info.primary_language.type_id,
            "structure_text": structure_info,
            "files": files_found,
            "main_language": enhanced_info.primary_language.name,
            "confidence": enhanced_info.confidence,
            "extensions": enhanced_info.primary_language.primary_extensions,
            "build_files": enhanced_info.primary_language.build_files,
            "conventions": enhanced_info.primary_language.conventions,
            # Nouvelles informations enrichies
            "detected_framework": enhanced_info.framework,
            "detected_project_type": enhanced_info.project_type,
            "tech_stack": enhanced_info.tech_stack,
            "architecture": enhanced_info.architecture,
            "llm_recommendations": enhanced_info.recommendations
        }
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'analyse du projet: {e}", exc_info=True)
        # Fallback sur dÃ©tection de base
        from utils.language_detector import detect_language, LanguageInfo
        
        basic_detection = detect_language(files_found if 'files_found' in locals() else [])
        
        return {
            "language_info": basic_detection,
            "enhanced_info": None,
            "project_type": basic_detection.type_id,
            "structure_text": "Structure du projet non disponible",
            "files": [],
            "main_language": basic_detection.name,
            "confidence": basic_detection.confidence,
            "extensions": basic_detection.primary_extensions,
            "build_files": basic_detection.build_files,
            "conventions": basic_detection.conventions
        }
```

---

### âœ… Ã‰tape 3 : Enrichir le Prompt d'ImplÃ©mentation (10 min)

**Fichier**: `nodes/implement_node.py`  
**Ligne ~506** - Dans `_create_implementation_prompt()` :

Ajouter aprÃ¨s la gÃ©nÃ©ration des instructions de langage :

```python
# âœ¨ NOUVEAU : Ajouter contexte enrichi si disponible
if hasattr(project_analysis.get('enhanced_info'), 'description'):
    enhanced = project_analysis['enhanced_info']
    prompt += f"""

## ğŸ¤– ANALYSE ENRICHIE DU PROJET

**Type de projet dÃ©tectÃ©**: {enhanced.project_type}
**Framework**: {enhanced.framework or 'Aucun framework spÃ©cifique dÃ©tectÃ©'}
**Architecture**: {enhanced.architecture}
**Stack technique complÃ¨te**: {', '.join(enhanced.tech_stack)}

**Description du projet**:
{enhanced.description}

**Recommandations du LLM pour l'implÃ©mentation**:
"""
    for i, rec in enumerate(enhanced.recommendations, 1):
        prompt += f"\n{i}. {rec}"
    
    if enhanced.secondary_languages:
        prompt += f"""

**âš ï¸ ATTENTION - Langages secondaires dÃ©tectÃ©s**: {', '.join(enhanced.secondary_languages)}
Assure-toi que ton implÃ©mentation est compatible avec ces langages si nÃ©cessaire.
"""
```

---

### âœ… Ã‰tape 4 : Tester le SystÃ¨me (10 min)

#### Test 1 : Projet Python Simple

```bash
# CrÃ©er un projet test
mkdir -p /tmp/test-python-project
cd /tmp/test-python-project
echo "flask==2.0.0" > requirements.txt
echo "# My Flask App" > README.md
mkdir -p src
echo "from flask import Flask" > src/app.py

# Tester la dÃ©tection
cd /Users/rehareharanaivo/Desktop/AI-Agent
python -c "
import asyncio
from utils.llm_enhanced_detector import detect_project_with_llm

async def test():
    files = ['requirements.txt', 'README.md', 'src/app.py']
    result = await detect_project_with_llm(
        files=files,
        readme_content='# My Flask App',
        requirements_txt_content='flask==2.0.0',
        use_llm=True
    )
    print(f'âœ… Langage: {result.primary_language.name}')
    print(f'âœ… Framework: {result.framework}')
    print(f'âœ… Type: {result.project_type}')
    print(f'âœ… Description: {result.description}')

asyncio.run(test())
"
```

#### Test 2 : Projet Webflow/HTML

```bash
# Tester avec projet Webflow
python -c "
import asyncio
from utils.llm_enhanced_detector import detect_project_with_llm

async def test():
    files = [
        'index.html',
        'css/style.css', 
        'js/webflow.js',
        'images/logo.png'
    ]
    result = await detect_project_with_llm(
        files=files,
        readme_content='# My Webflow Site',
        use_llm=True
    )
    print(f'âœ… Langage: {result.primary_language.name}')
    print(f'âœ… Framework: {result.framework}')
    print(f'âœ… Type: {result.project_type}')
    print(f'âœ… Stack: {result.tech_stack}')

asyncio.run(test())
"
```

---

### âœ… Ã‰tape 5 : Activer dans le Workflow Complet (5 min)

**Fichier**: `nodes/implement_node.py`  
**Ligne ~141** - Dans `implement_task()` :

Ajouter aprÃ¨s la rÃ©cupÃ©ration de `project_analysis` :

```python
# Logger les informations enrichies
if "enhanced_info" in project_analysis and project_analysis["enhanced_info"]:
    enhanced = project_analysis["enhanced_info"]
    logger.info("=" * 60)
    logger.info("ğŸ¤– ANALYSE LLM DU PROJET")
    logger.info("=" * 60)
    logger.info(f"Type: {enhanced.project_type}")
    logger.info(f"Framework: {enhanced.framework or 'Aucun'}")
    logger.info(f"Architecture: {enhanced.architecture}")
    logger.info(f"Stack: {', '.join(enhanced.tech_stack)}")
    logger.info(f"Description: {enhanced.description[:100]}...")
    logger.info("=" * 60)
```

---

## ğŸ¯ RÃ©sultat Attendu

### Avant (DÃ©tection de base uniquement)
```
ğŸ“Š Langage dÃ©tectÃ©: Python (confiance: 0.90)
ğŸ“Š Extensions: .py
ğŸ“Š Structure: structured
```

### AprÃ¨s (Avec enrichissement LLM)
```
ğŸ¤– Analyse du projet avec enrichissement LLM...
ğŸ“Š Langage principal: Python (confiance: 0.95)
ğŸ“Š Type de projet: web-app
ğŸ“Š Framework: Flask
ğŸ“Š Stack technique: Python, Flask, SQLAlchemy, PostgreSQL
ğŸ“Š Architecture: monolithic
ğŸ“Š Description: Application web Flask avec API REST et base de donnÃ©es PostgreSQL

ğŸ¤– ANALYSE LLM DU PROJET
============================================================
Type: web-app
Framework: Flask
Architecture: monolithic
Stack: Python, Flask, SQLAlchemy, PostgreSQL
Description: Application web Flask avec API REST et base de donnÃ©es...
============================================================
```

---

## ğŸ”„ Cas d'Usage SpÃ©cifiques

### Cas 1 : Projet Webflow

**Fichiers dÃ©tectÃ©s** :
```
index.html
css/webflow.css
js/webflow.js
```

**RÃ©sultat attendu** :
```
ğŸ“Š Langage principal: HTML (confiance: 0.85)
ğŸ“Š Type de projet: web-app
ğŸ“Š Framework: Webflow
ğŸ“Š Stack: HTML, CSS, JavaScript, Webflow
ğŸ“Š Architecture: jamstack
```

### Cas 2 : Projet Python/Django

**Fichiers dÃ©tectÃ©s** :
```
manage.py
requirements.txt (avec Django)
myapp/models.py
```

**RÃ©sultat attendu** :
```
ğŸ“Š Langage principal: Python (confiance: 0.95)
ğŸ“Š Type de projet: web-app
ğŸ“Š Framework: Django
ğŸ“Š Stack: Python, Django, PostgreSQL
ğŸ“Š Architecture: monolithic
```

### Cas 3 : Projet React/TypeScript

**Fichiers dÃ©tectÃ©s** :
```
package.json (avec react, typescript)
tsconfig.json
src/App.tsx
```

**RÃ©sultat attendu** :
```
ğŸ“Š Langage principal: TypeScript (confiance: 0.90)
ğŸ“Š Type de projet: web-app
ğŸ“Š Framework: React
ğŸ“Š Stack: TypeScript, React, Node.js
ğŸ“Š Architecture: jamstack
```

---

## âš™ï¸ Configuration Optionnelle

### DÃ©sactiver le LLM (Mode Fallback)

Si vous voulez dÃ©sactiver l'analyse LLM et revenir Ã  la dÃ©tection de base :

Dans `implement_node.py`, ligne de l'appel :

```python
enhanced_info = await detect_project_with_llm(
    files=files_found,
    readme_content=readme_content,
    package_json_content=package_json_content,
    requirements_txt_content=requirements_content,
    use_llm=False  # â¬…ï¸ DÃ©sactiver ici
)
```

### Changer le ModÃ¨le LLM

Dans `utils/llm_enhanced_detector.py`, ligne ~61 :

```python
def __init__(self, use_llm: bool = True, llm_model: str = "gpt-4o-mini"):  # â¬…ï¸ Changer ici
```

Options :
- `"gpt-4o-mini"` (rapide, moins cher)
- `"gpt-4o"` (plus prÃ©cis, plus cher)
- `"claude-3-5-sonnet-20241022"` (Anthropic)

---

## ğŸ› DÃ©pannage

### Erreur : "Impossible de rÃ©soudre l'importation"

**Solution** : Les imports ont Ã©tÃ© corrigÃ©s. Relancer :
```bash
python -c "from utils.llm_enhanced_detector import detect_project_with_llm; print('OK')"
```

### Erreur : "LLM API Key manquante"

**Solution** : VÃ©rifier `.env` :
```bash
OPENAI_API_KEY=sk-...
# ou
ANTHROPIC_API_KEY=sk-ant-...
```

### Le LLM ne se lance pas

**Solution** : Le systÃ¨me utilise automatiquement le fallback (dÃ©tection de base sans LLM)

---

## ğŸ“Š Temps EstimÃ© Total

| Ã‰tape | Temps |
|-------|-------|
| 1. VÃ©rifier module LLM | 5 min |
| 2. IntÃ©grer dans implement_node | 15 min |
| 3. Enrichir le prompt | 10 min |
| 4. Tester le systÃ¨me | 10 min |
| 5. Activer dans workflow | 5 min |
| **TOTAL** | **45 min** |

---

## âœ… Checklist Finale

- [ ] Module `llm_enhanced_detector.py` sans erreur d'import
- [ ] Fonction `_analyze_project_structure()` modifiÃ©e
- [ ] Fonction `_create_implementation_prompt()` enrichie
- [ ] Tests avec projet Python rÃ©ussis
- [ ] Tests avec projet Webflow/HTML rÃ©ussis
- [ ] Logs enrichis visibles dans la console
- [ ] Workflow complet testÃ© avec un vrai projet

---

## ğŸ¯ Prochaines Ã‰tapes (Optionnel)

1. **Ajouter plus de contexte** : Lire plus de fichiers de config (tsconfig.json, etc.)
2. **AmÃ©liorer le prompt LLM** : Affiner les instructions pour de meilleurs rÃ©sultats
3. **Ajouter un cache** : Ã‰viter de re-analyser le mÃªme projet
4. **Metrics** : Tracker la prÃ©cision de la dÃ©tection LLM

---

*Guide crÃ©Ã© le 11 octobre 2025*  
*Temps estimÃ© : 45 minutes*
