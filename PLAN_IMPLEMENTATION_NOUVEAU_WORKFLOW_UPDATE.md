# üöÄ Plan d'Impl√©mentation - Nouveau Workflow sur Updates Monday

**Date**: 11 octobre 2025  
**Objectif**: D√©clencher automatiquement un nouveau workflow quand un nouveau commentaire de **demande** arrive dans les Updates Monday d'une t√¢che termin√©e.

---

## üìã Table des Mati√®res

1. [Contexte et Besoin](#contexte-et-besoin)
2. [Architecture de la Solution](#architecture-de-la-solution)
3. [√âtapes d'Impl√©mentation](#√©tapes-dimpl√©mentation)
4. [Structure de la Base de Donn√©es](#structure-de-la-base-de-donn√©es)
5. [Fichiers √† Modifier](#fichiers-√†-modifier)
6. [Tests √† Cr√©er](#tests-√†-cr√©er)
7. [Checklist de D√©ploiement](#checklist-de-d√©ploiement)

---

## üéØ Contexte et Besoin

### Situation Actuelle
- ‚úÖ Le workflow se d√©clenche quand un nouvel item est cr√©√© dans Monday
- ‚úÖ Le workflow attend les r√©ponses de validation dans les Updates
- ‚ùå Apr√®s qu'une t√¢che soit termin√©e, un nouveau commentaire ne d√©clenche PAS de workflow

### Besoin Identifi√©
Quand une t√¢che est **termin√©e** (`internal_status = 'completed'` ou `monday_status = 'Done'`), et qu'un nouveau commentaire **de demande** (pas d'affirmation) arrive dans les Updates Monday :
- ‚úÖ D√©tecter automatiquement ce commentaire
- ‚úÖ Analyser s'il s'agit d'une **nouvelle demande** (pas juste une affirmation/remerciement)
- ‚úÖ D√©clencher un **nouveau workflow** pour traiter cette demande
- ‚úÖ Cr√©er un nouveau `task_run` li√© √† la m√™me t√¢che

---

## üèóÔ∏è Architecture de la Solution

### Composants Principaux

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Monday.com Webhook                        ‚îÇ
‚îÇ              (create_update / create_reply)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         WebhookPersistenceService                            ‚îÇ
‚îÇ  _handle_update_event() - MODIFI√â                           ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  1. R√©cup√©rer la t√¢che par pulse_id                         ‚îÇ
‚îÇ  2. V√©rifier le statut de la t√¢che (completed?)             ‚îÇ
‚îÇ  3. Analyser le contenu du commentaire avec LLM             ‚îÇ
‚îÇ  4. Si nouvelle demande ‚Üí d√©clencher workflow               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         UpdateAnalyzerService (NOUVEAU)                      ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚Ä¢ analyze_update_intent(text) ‚Üí Intent                     ‚îÇ
‚îÇ  ‚Ä¢ is_new_request(text) ‚Üí bool                              ‚îÇ
‚îÇ  ‚Ä¢ extract_requirements(text) ‚Üí Dict                        ‚îÇ
‚îÇ  ‚Ä¢ classify_update_type() ‚Üí UpdateType                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         WorkflowTriggerService (NOUVEAU)                     ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚Ä¢ trigger_new_workflow_from_update()                       ‚îÇ
‚îÇ  ‚Ä¢ create_task_run_from_update()                            ‚îÇ
‚îÇ  ‚Ä¢ submit_to_celery()                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux de Donn√©es

```
1. Update Monday ‚Üí Webhook ‚Üí FastAPI
                              ‚îÇ
2. Persist Webhook ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                              ‚îÇ
3. Check Task Status ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                              ‚îÇ
4. Analyze Update (LLM) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚Üí Is New Request?
                              ‚îÇ         ‚îÇ
                              ‚îÇ         ‚îú‚îÄ NO ‚Üí Log + Ignorer
                              ‚îÇ         ‚îÇ
                              ‚îÇ         ‚îî‚îÄ YES ‚Üí Create TaskRequest
                              ‚îÇ                        ‚îÇ
5. Create new task_run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                                       ‚îÇ
6. Submit to Celery Queue ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                                       ‚îÇ
7. Execute Workflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù √âtapes d'Impl√©mentation

### **√âTAPE 1 : Cr√©er le Service d'Analyse des Updates** (45 min)

#### Fichier : `services/update_analyzer_service.py`

**Fonctionnalit√©s** :
1. **Analyser l'intention** d'un commentaire avec LLM
2. **Classifier** : Nouvelle demande vs Affirmation/Question/Remerciement
3. **Extraire les requirements** d'une nouvelle demande

**M√©thodes principales** :
```python
class UpdateAnalyzerService:
    async def analyze_update_intent(self, update_text: str, context: Dict) -> UpdateIntent
    async def is_new_request(self, update_text: str) -> bool
    async def extract_requirements(self, update_text: str) -> Dict[str, Any]
    def classify_update_type(self, update_text: str) -> UpdateType
```

**Types d'Updates √† d√©tecter** :
- ‚úÖ **NEW_REQUEST** : Nouvelle demande d'impl√©mentation
- ‚ö†Ô∏è **MODIFICATION** : Modification d'une feature existante
- üêõ **BUG_REPORT** : Signalement de bug
- ‚ùì **QUESTION** : Question (pas d'action)
- üí¨ **AFFIRMATION** : Commentaire/Remerciement (pas d'action)
- üìã **VALIDATION_RESPONSE** : R√©ponse √† une validation (d√©j√† g√©r√©)

**Prompt LLM** :
```python
ANALYZE_UPDATE_PROMPT = """
Analyse ce commentaire Monday.com et d√©termine s'il s'agit d'une NOUVELLE DEMANDE n√©cessitant un workflow.

CONTEXTE:
- T√¢che : {task_title}
- Statut actuel : {task_status}
- Description originale : {original_description}

COMMENTAIRE √Ä ANALYSER:
{update_text}

INSTRUCTIONS:
1. D√©termine le TYPE de commentaire :
   - NEW_REQUEST : Nouvelle fonctionnalit√©/impl√©mentation demand√©e
   - MODIFICATION : Modification d'une feature existante
   - BUG_REPORT : Signalement de bug n√©cessitant correction
   - QUESTION : Simple question sans action requise
   - AFFIRMATION : Commentaire/Remerciement
   - VALIDATION_RESPONSE : R√©ponse √† une validation (oui/non/approuv√©)

2. Si NEW_REQUEST, MODIFICATION ou BUG_REPORT, extrais :
   - Ce qui est demand√© (description claire)
   - Type de t√¢che (feature/bugfix/refactor/etc)
   - Priorit√© estim√©e (low/medium/high/urgent)
   - Fichiers potentiellement concern√©s

R√âPONDS EN JSON:
{{
  "type": "NEW_REQUEST|MODIFICATION|BUG_REPORT|QUESTION|AFFIRMATION|VALIDATION_RESPONSE",
  "confidence": 0.0-1.0,
  "requires_workflow": true/false,
  "reasoning": "Explication de la d√©cision",
  "extracted_requirements": {{
    "title": "Titre court de la demande",
    "description": "Description d√©taill√©e",
    "task_type": "feature|bugfix|refactor|etc",
    "priority": "low|medium|high|urgent",
    "files_mentioned": ["file1.py", "file2.js"],
    "technical_keywords": ["React", "API", "Database"]
  }}
}}
"""
```

---

### **√âTAPE 2 : Cr√©er le Service de D√©clenchement de Workflow** (30 min)

#### Fichier : `services/workflow_trigger_service.py`

**Fonctionnalit√©s** :
1. **Cr√©er un nouveau TaskRequest** depuis un update analys√©
2. **Cr√©er un nouveau task_run** li√© √† la t√¢che existante
3. **Soumettre √† Celery** pour ex√©cution

**M√©thodes principales** :
```python
class WorkflowTriggerService:
    async def trigger_workflow_from_update(
        self, 
        task_id: int, 
        update_analysis: UpdateIntent,
        monday_item_id: int,
        update_id: str
    ) -> Dict[str, Any]
    
    async def create_task_request_from_update(
        self,
        original_task: Dict,
        update_analysis: UpdateIntent
    ) -> TaskRequest
    
    async def create_new_task_run(
        self,
        task_id: int,
        task_request: TaskRequest
    ) -> int  # Returns run_id
    
    def submit_to_celery(
        self,
        task_request: TaskRequest,
        priority: int = 5
    ) -> str  # Returns celery_task_id
```

**Logique importante** :
```python
async def trigger_workflow_from_update(self, ...):
    # 1. R√©cup√©rer la t√¢che originale depuis la DB
    original_task = await db_persistence.get_task_by_id(task_id)
    
    # 2. Cr√©er un nouveau TaskRequest bas√© sur l'update
    task_request = await self.create_task_request_from_update(
        original_task, 
        update_analysis
    )
    
    # 3. Cr√©er un nouveau run dans la DB
    run_id = await self.create_new_task_run(task_id, task_request)
    
    # 4. Logger l'√©v√©nement
    await db_persistence.log_application_event(
        task_id=task_id,
        level="INFO",
        source_component="workflow_trigger",
        action="new_workflow_triggered_from_update",
        message=f"Nouveau workflow d√©clench√© depuis update: {update_analysis.extracted_requirements.title}",
        metadata={
            "update_id": update_id,
            "run_id": run_id,
            "task_type": task_request.task_type,
            "priority": task_request.priority
        }
    )
    
    # 5. Soumettre √† Celery
    celery_task_id = self.submit_to_celery(task_request, priority=7)
    
    # 6. Poster un commentaire dans Monday
    await monday_tool.add_comment(
        item_id=monday_item_id,
        comment=f"ü§ñ Nouvelle demande d√©tect√©e et prise en compte !\n\n"
                f"üìã **{task_request.title}**\n"
                f"üéØ Type: {task_request.task_type}\n"
                f"‚ö° Priorit√©: {task_request.priority}\n\n"
                f"Le workflow a √©t√© lanc√© automatiquement."
    )
    
    return {
        "success": True,
        "run_id": run_id,
        "celery_task_id": celery_task_id,
        "task_request": task_request.dict()
    }
```

---

### **√âTAPE 3 : Modifier le Service de Persistence des Webhooks** (45 min)

#### Fichier : `services/webhook_persistence_service.py`

**Modifications dans `_handle_update_event()`** :

```python
@staticmethod
async def _handle_update_event(payload: Dict[str, Any], webhook_id: int):
    """Traite un √©v√©nement d'update/commentaire Monday.com."""
    try:
        pulse_id = payload.get("pulseId")
        update_text = payload.get("textBody", "")
        update_id = payload.get("updateId") or payload.get("id")
        
        # Rechercher la t√¢che li√©e
        task_id = await db_persistence._find_task_by_monday_id(pulse_id)
        
        if not task_id:
            logger.warning(f"‚ö†Ô∏è T√¢che non trouv√©e pour pulse_id {pulse_id}")
            return
        
        # ‚úÖ NOUVEAU: R√©cup√©rer les d√©tails de la t√¢che
        async with db_persistence.pool.acquire() as conn:
            task_details = await conn.fetchrow("""
                SELECT 
                    tasks_id,
                    monday_item_id,
                    title,
                    description,
                    internal_status,
                    monday_status,
                    repository_url,
                    priority,
                    task_type
                FROM tasks 
                WHERE tasks_id = $1
            """, task_id)
        
        if not task_details:
            logger.error(f"‚ùå Impossible de r√©cup√©rer les d√©tails de la t√¢che {task_id}")
            return
        
        # ‚úÖ NOUVEAU: V√©rifier si la t√¢che est termin√©e
        is_completed = (
            task_details['internal_status'] == 'completed' or
            task_details['monday_status'] == 'Done'
        )
        
        # Logger le commentaire
        await db_persistence.log_application_event(
            task_id=task_id,
            level="INFO",
            source_component="monday_webhook",
            action="item_update_received",
            message=f"Commentaire Monday.com: {update_text[:200]}...",
            metadata={
                "webhook_id": webhook_id,
                "full_text": update_text,
                "monday_pulse_id": pulse_id,
                "update_id": update_id,
                "task_completed": is_completed
            }
        )
        
        await db_persistence._link_webhook_to_task(webhook_id, task_id)
        
        # ‚úÖ NOUVEAU: Si t√¢che termin√©e, analyser le commentaire
        if is_completed:
            logger.info(f"üîç T√¢che {task_id} termin√©e - analyse du commentaire pour nouveau workflow")
            
            # Initialiser le service d'analyse
            from services.update_analyzer_service import update_analyzer_service
            from services.workflow_trigger_service import workflow_trigger_service
            
            # Pr√©parer le contexte pour l'analyse
            context = {
                "task_title": task_details['title'],
                "task_status": task_details['internal_status'],
                "monday_status": task_details['monday_status'],
                "original_description": task_details['description']
            }
            
            # Analyser l'intention du commentaire
            update_analysis = await update_analyzer_service.analyze_update_intent(
                update_text=update_text,
                context=context
            )
            
            logger.info(f"üìä Analyse update: type={update_analysis.type}, "
                       f"requires_workflow={update_analysis.requires_workflow}, "
                       f"confidence={update_analysis.confidence}")
            
            # ‚úÖ NOUVEAU: Si c'est une nouvelle demande, d√©clencher le workflow
            if update_analysis.requires_workflow and update_analysis.confidence > 0.7:
                logger.info(f"üöÄ D√©clenchement d'un nouveau workflow depuis update {update_id}")
                
                try:
                    trigger_result = await workflow_trigger_service.trigger_workflow_from_update(
                        task_id=task_id,
                        update_analysis=update_analysis,
                        monday_item_id=task_details['monday_item_id'],
                        update_id=update_id
                    )
                    
                    if trigger_result['success']:
                        logger.info(f"‚úÖ Nouveau workflow d√©clench√©: run_id={trigger_result['run_id']}, "
                                  f"celery_task_id={trigger_result['celery_task_id']}")
                    else:
                        logger.error(f"‚ùå √âchec d√©clenchement workflow: {trigger_result.get('error')}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Erreur lors du d√©clenchement du workflow: {e}", exc_info=True)
                    # Ne pas bloquer - juste logger l'erreur
            else:
                logger.info(f"‚ÑπÔ∏è Commentaire analys√© mais pas de workflow requis: "
                          f"type={update_analysis.type}, confidence={update_analysis.confidence}")
        else:
            logger.info(f"üí¨ Commentaire trait√© pour t√¢che en cours {task_id} (status={task_details['internal_status']})")
                
    except Exception as e:
        logger.error(f"‚ùå Erreur traitement update event: {e}", exc_info=True)
        raise
```

---

### **√âTAPE 4 : Ajouter les Mod√®les de Donn√©es** (15 min)

#### Fichier : `models/schemas.py`

**Nouveaux Enums et Classes** :

```python
class UpdateType(str, Enum):
    """Types d'updates Monday d√©tect√©s."""
    NEW_REQUEST = "new_request"
    MODIFICATION = "modification"
    BUG_REPORT = "bug_report"
    QUESTION = "question"
    AFFIRMATION = "affirmation"
    VALIDATION_RESPONSE = "validation_response"


class UpdateIntent(BaseModel):
    """Intention d√©tect√©e dans un update Monday."""
    type: UpdateType
    confidence: float = Field(ge=0.0, le=1.0, description="Confiance du LLM (0-1)")
    requires_workflow: bool
    reasoning: str
    extracted_requirements: Optional[Dict[str, Any]] = None
    
    class Config:
        use_enum_values = True


class UpdateAnalysisContext(BaseModel):
    """Contexte pour l'analyse d'un update."""
    task_title: str
    task_status: str
    monday_status: Optional[str] = None
    original_description: str
    task_type: Optional[str] = None
    priority: Optional[str] = None
```

---

### **√âTAPE 5 : Mettre √† Jour la Base de Donn√©es** (15 min)

#### Nouvelle Table : `task_update_triggers`

```sql
-- Table pour tracker les d√©clenchements de workflow depuis des updates
CREATE TABLE IF NOT EXISTS task_update_triggers (
    trigger_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE CASCADE,
    monday_update_id VARCHAR(255) NOT NULL,
    webhook_id BIGINT REFERENCES webhooks(webhook_id) ON DELETE SET NULL,
    update_text TEXT NOT NULL,
    
    -- Analyse LLM
    detected_type VARCHAR(50) NOT NULL,  -- UpdateType enum
    confidence FLOAT NOT NULL,
    requires_workflow BOOLEAN NOT NULL DEFAULT FALSE,
    analysis_reasoning TEXT,
    extracted_requirements JSONB,
    
    -- Workflow d√©clench√©
    triggered_workflow BOOLEAN DEFAULT FALSE,
    new_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE SET NULL,
    celery_task_id VARCHAR(255),
    
    -- M√©tadonn√©es
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    processed_at TIMESTAMPTZ,
    
    CONSTRAINT unique_monday_update UNIQUE (monday_update_id)
);

CREATE INDEX idx_update_triggers_task_id ON task_update_triggers(task_id);
CREATE INDEX idx_update_triggers_workflow ON task_update_triggers(triggered_workflow) 
    WHERE triggered_workflow = TRUE;
CREATE INDEX idx_update_triggers_created_at ON task_update_triggers(created_at DESC);

COMMENT ON TABLE task_update_triggers IS 'Suivi des d√©clenchements de workflow depuis des updates Monday';
```

#### Nouvelle colonne dans `task_runs` :

```sql
-- Ajouter une colonne pour lier un run √† un update Monday
ALTER TABLE task_runs 
ADD COLUMN IF NOT EXISTS triggered_by_update_id VARCHAR(255);

COMMENT ON COLUMN task_runs.triggered_by_update_id IS 'ID de l''update Monday qui a d√©clench√© ce run';
```

---

### **√âTAPE 6 : Cr√©er les Tests** (60 min)

#### Fichier : `test_update_workflow_trigger.py`

**Tests √† impl√©menter** :

```python
import pytest
from services.update_analyzer_service import update_analyzer_service
from services.workflow_trigger_service import workflow_trigger_service

class TestUpdateAnalyzer:
    """Tests pour l'analyse des updates Monday."""
    
    @pytest.mark.asyncio
    async def test_detect_new_request(self):
        """Test: D√©tecter une nouvelle demande."""
        update_text = "Bonjour, j'aimerais ajouter un bouton d'export CSV sur la page des utilisateurs"
        context = {
            "task_title": "Cr√©er dashboard admin",
            "task_status": "completed",
            "original_description": "Dashboard avec liste des utilisateurs"
        }
        
        result = await update_analyzer_service.analyze_update_intent(update_text, context)
        
        assert result.type == "NEW_REQUEST"
        assert result.requires_workflow == True
        assert result.confidence > 0.7
        assert "export" in result.extracted_requirements['description'].lower()
    
    @pytest.mark.asyncio
    async def test_detect_affirmation(self):
        """Test: D√©tecter une affirmation (pas de workflow)."""
        update_text = "Merci beaucoup, √ßa fonctionne parfaitement !"
        context = {"task_title": "Test", "task_status": "completed", "original_description": "Test"}
        
        result = await update_analyzer_service.analyze_update_intent(update_text, context)
        
        assert result.type == "AFFIRMATION"
        assert result.requires_workflow == False
    
    @pytest.mark.asyncio
    async def test_detect_bug_report(self):
        """Test: D√©tecter un signalement de bug."""
        update_text = "Il y a un bug, le bouton ne fonctionne plus sur mobile"
        context = {"task_title": "Feature", "task_status": "completed", "original_description": "Feature"}
        
        result = await update_analyzer_service.analyze_update_intent(update_text, context)
        
        assert result.type == "BUG_REPORT"
        assert result.requires_workflow == True
        assert result.extracted_requirements['task_type'] == "bugfix"
    
    @pytest.mark.asyncio
    async def test_detect_question(self):
        """Test: D√©tecter une simple question."""
        update_text = "Comment je peux configurer cette feature ?"
        context = {"task_title": "Feature", "task_status": "completed", "original_description": "Feature"}
        
        result = await update_analyzer_service.analyze_update_intent(update_text, context)
        
        assert result.type == "QUESTION"
        assert result.requires_workflow == False


class TestWorkflowTrigger:
    """Tests pour le d√©clenchement de workflow."""
    
    @pytest.mark.asyncio
    async def test_trigger_workflow_from_update(self):
        """Test: D√©clencher un workflow complet depuis un update."""
        # TODO: Mock DB, Mock Celery, etc.
        pass
    
    @pytest.mark.asyncio
    async def test_create_task_request_from_update(self):
        """Test: Cr√©er un TaskRequest depuis une analyse d'update."""
        # TODO: Impl√©menter
        pass
```

---

## üìÇ Fichiers √† Cr√©er/Modifier

### **Nouveaux Fichiers** :

1. ‚úÖ `services/update_analyzer_service.py` (Nouveau)
2. ‚úÖ `services/workflow_trigger_service.py` (Nouveau)
3. ‚úÖ `test_update_workflow_trigger.py` (Nouveau)
4. ‚úÖ `data/migration_task_update_triggers.sql` (Nouveau)
5. ‚úÖ `PLAN_IMPLEMENTATION_NOUVEAU_WORKFLOW_UPDATE.md` (Ce fichier)

### **Fichiers √† Modifier** :

1. ‚úÖ `services/webhook_persistence_service.py`
   - Modifier `_handle_update_event()`
   
2. ‚úÖ `models/schemas.py`
   - Ajouter `UpdateType`, `UpdateIntent`, `UpdateAnalysisContext`
   
3. ‚úÖ `services/database_persistence_service.py`
   - Ajouter m√©thodes pour `task_update_triggers`
   - Ajouter `get_task_by_id()` avec tous les d√©tails
   
4. ‚úÖ `main.py`
   - Aucune modification n√©cessaire (webhook d√©j√† g√©r√©)
   
5. ‚úÖ `requirements.txt`
   - Aucune d√©pendance suppl√©mentaire n√©cessaire

---

## ‚úÖ Checklist de D√©ploiement

### **Phase 1 : D√©veloppement (2-3 heures)**

- [ ] Cr√©er `services/update_analyzer_service.py` avec analyse LLM
- [ ] Cr√©er `services/workflow_trigger_service.py` avec d√©clenchement
- [ ] Ajouter les mod√®les dans `models/schemas.py`
- [ ] Modifier `webhook_persistence_service.py`
- [ ] Ajouter m√©thodes DB dans `database_persistence_service.py`

### **Phase 2 : Base de Donn√©es (30 min)**

- [ ] Cr√©er le script de migration SQL
- [ ] Tester la migration sur une DB de test
- [ ] Appliquer la migration sur la DB de production

### **Phase 3 : Tests (1-2 heures)**

- [ ] √âcrire les tests unitaires pour `UpdateAnalyzerService`
- [ ] √âcrire les tests unitaires pour `WorkflowTriggerService`
- [ ] √âcrire les tests d'int√©gration complets
- [ ] Tester manuellement avec Monday.com

### **Phase 4 : D√©ploiement (30 min)**

- [ ] Commit et push du code
- [ ] Red√©marrer les services (FastAPI + Celery)
- [ ] V√©rifier les logs
- [ ] Tester avec un commentaire r√©el dans Monday

### **Phase 5 : Monitoring (Continu)**

- [ ] Surveiller les logs pour les d√©clenchements
- [ ] V√©rifier les m√©triques de confiance du LLM
- [ ] Ajuster les prompts si n√©cessaire
- [ ] Documenter les cas edge

---

## üéØ Crit√®res de Succ√®s

1. ‚úÖ Un commentaire de demande sur une t√¢che termin√©e d√©clenche automatiquement un nouveau workflow
2. ‚úÖ Les affirmations/remerciements ne d√©clenchent PAS de workflow
3. ‚úÖ Le nouveau workflow cr√©e un nouveau `task_run` li√© √† la m√™me t√¢che
4. ‚úÖ L'historique complet est conserv√© dans la DB
5. ‚úÖ Un commentaire de confirmation est post√© dans Monday
6. ‚úÖ Le syst√®me fonctionne sans intervention manuelle

---

## üö® Points d'Attention

### **S√©curit√©**
- ‚ö†Ô∏è Limiter le nombre de workflows d√©clench√©s par update (max 1)
- ‚ö†Ô∏è V√©rifier que l'update n'est pas d√©j√† trait√© (idempotence)
- ‚ö†Ô∏è Limiter le taux de d√©clenchement (rate limiting)

### **Performance**
- ‚ö†Ô∏è L'analyse LLM ajoute ~1-2s de latence
- ‚ö†Ô∏è Pr√©voir un cache pour les analyses similaires
- ‚ö†Ô∏è Utiliser un timeout pour les appels LLM

### **Gestion d'Erreurs**
- ‚ö†Ô∏è Si l'analyse LLM √©choue ‚Üí logger et ignorer (pas de workflow)
- ‚ö†Ô∏è Si Celery √©choue ‚Üí retry automatique
- ‚ö†Ô∏è Si DB √©choue ‚Üí rollback et notification

---

## üìä M√©triques √† Suivre

1. **Nombre d'updates analys√©s** par jour
2. **Taux de d√©clenchement** (workflows d√©clench√©s / updates analys√©s)
3. **Confiance moyenne** du LLM dans la d√©tection
4. **Faux positifs** (workflows d√©clench√©s √† tort)
5. **Faux n√©gatifs** (demandes manqu√©es)
6. **Temps de r√©ponse** de l'analyse LLM

---

## üîÑ √âvolutions Futures

1. **D√©tection multi-langue** (Fran√ßais + Anglais)
2. **Analyse de sentiment** pour la priorit√©
3. **Extraction automatique des fichiers** mentionn√©s
4. **Suggestion de type de t√¢che** (feature/bugfix/etc)
5. **Notification Slack/Email** pour les nouvelles demandes
6. **Dashboard de monitoring** des d√©clenchements

---

## üìö Documentation Associ√©e

- `SYNTHESE_IMPLEMENTATION_LLM.md` - Premi√®re impl√©mentation LLM
- `RAPPORT_VERIFICATION_WORKFLOW.md` - V√©rification du workflow actuel
- `GUIDE_IMPLEMENTATION_LLM_DETECTION.md` - Guide d√©tection de langage

---

**Pr√™t pour l'impl√©mentation ! üöÄ**
