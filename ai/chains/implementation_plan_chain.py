"""Cha√Æne LangChain pour la g√©n√©ration de plans d'impl√©mentation structur√©s."""

from enum import Enum
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from config.settings import get_settings
from utils.logger import get_logger

logger = get_logger(__name__)
settings = get_settings()


class RiskLevel(str, Enum):
    """Niveau de risque pour une √©tape d'impl√©mentation."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class ImplementationStep(BaseModel):
    """Mod√®le Pydantic pour une √©tape d'impl√©mentation."""
    step_number: int = Field(description="Num√©ro de l'√©tape (s√©quentiel)")
    title: str = Field(description="Titre court de l'√©tape")
    description: str = Field(description="Description d√©taill√©e de ce qui doit √™tre fait")
    files_to_modify: List[str] = Field(
        default_factory=list,
        description="Liste des fichiers √† cr√©er ou modifier"
    )
    dependencies: List[str] = Field(
        default_factory=list,
        description="D√©pendances/packages requis pour cette √©tape"
    )
    estimated_complexity: int = Field(
        ge=1,
        le=10,
        description="Complexit√© estim√©e (1=tr√®s simple, 10=tr√®s complexe)"
    )
    risk_level: RiskLevel = Field(
        default=RiskLevel.LOW,
        description="Niveau de risque de cette √©tape"
    )
    risk_mitigation: Optional[str] = Field(
        default=None,
        description="Strat√©gie de mitigation du risque si risque > LOW"
    )
    validation_criteria: List[str] = Field(
        default_factory=list,
        description="Crit√®res de validation pour consid√©rer l'√©tape comme termin√©e"
    )


class ImplementationPlan(BaseModel):
    """Mod√®le Pydantic pour un plan d'impl√©mentation complet."""
    task_summary: str = Field(description="R√©sum√© de la t√¢che √† impl√©menter")
    architecture_approach: str = Field(
        description="Approche architecturale recommand√©e"
    )
    steps: List[ImplementationStep] = Field(
        min_length=1,
        description="Liste ordonn√©e des √©tapes d'impl√©mentation"
    )
    total_estimated_complexity: int = Field(
        ge=1,
        description="Complexit√© totale estim√©e (somme des complexit√©s)"
    )
    overall_risk_assessment: str = Field(
        description="√âvaluation globale des risques du projet"
    )
    recommended_testing_strategy: str = Field(
        description="Strat√©gie de tests recommand√©e"
    )
    potential_blockers: List[str] = Field(
        default_factory=list,
        description="Liste des bloqueurs potentiels identifi√©s"
    )
    
    class Config:
        """Configuration Pydantic."""
        json_schema_extra = {
            "example": {
                "task_summary": "Cr√©er une API REST pour g√©rer les utilisateurs",
                "architecture_approach": "Architecture MVC avec FastAPI",
                "steps": [
                    {
                        "step_number": 1,
                        "title": "Cr√©er les mod√®les de donn√©es",
                        "description": "D√©finir les mod√®les Pydantic pour User",
                        "files_to_modify": ["models/user.py"],
                        "dependencies": ["pydantic"],
                        "estimated_complexity": 3,
                        "risk_level": "low",
                        "validation_criteria": ["Mod√®les valident correctement"]
                    }
                ],
                "total_estimated_complexity": 15,
                "overall_risk_assessment": "Risque faible, technologies matures",
                "recommended_testing_strategy": "Tests unitaires + tests d'int√©gration",
                "potential_blockers": ["Sch√©ma DB non finalis√©"]
            }
        }


def create_implementation_plan_chain(
    provider: str = "anthropic",
    model: Optional[str] = None,
    temperature: float = 0.1,
    max_tokens: int = 4000
):
    """
    Cr√©e une cha√Æne LCEL pour g√©n√©rer un plan d'impl√©mentation structur√©.
    
    Args:
        provider: Provider LLM √† utiliser ("anthropic" ou "openai")
        model: Nom du mod√®le (optionnel, utilise le d√©faut du provider)
        temperature: Temp√©rature du mod√®le (0.0-1.0)
        max_tokens: Nombre maximum de tokens
        
    Returns:
        Cha√Æne LCEL configur√©e (Prompt ‚Üí LLM ‚Üí Parser)
        
    Raises:
        ValueError: Si le provider n'est pas support√©
        Exception: Si les cl√©s API sont manquantes
    """
    logger.info(f"üîó Cr√©ation implementation_plan_chain avec provider={provider}")
    
    # 1. Cr√©er le parser Pydantic
    parser = PydanticOutputParser(pydantic_object=ImplementationPlan)
    
    # 2. Cr√©er le prompt template avec instructions de formatage
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", """Tu es un architecte logiciel expert qui cr√©e des plans d'impl√©mentation d√©taill√©s et structur√©s.
Tu dois analyser la t√¢che fournie et g√©n√©rer un plan complet au format JSON strict.

IMPORTANT: Tu DOIS retourner UNIQUEMENT du JSON valide, sans texte avant ou apr√®s.
Utilise le sch√©ma suivant:

{format_instructions}

Sois pr√©cis, actionnable et identifie tous les risques potentiels."""),
        ("user", """T√¢che √† analyser:

Titre: {task_title}
Description: {task_description}
Type: {task_type}
Contexte additionnel: {additional_context}

G√©n√®re un plan d'impl√©mentation complet et structur√©.""")
    ])
    
    # 3. Injecter les instructions de formatage du parser dans le prompt
    prompt = prompt_template.partial(format_instructions=parser.get_format_instructions())
    
    # 4. Cr√©er le LLM selon le provider
    if provider.lower() == "anthropic":
        if not settings.anthropic_api_key:
            raise Exception("ANTHROPIC_API_KEY manquante dans la configuration")
        
        llm = ChatAnthropic(
            model=model or "claude-3-5-sonnet-20241022",
            anthropic_api_key=settings.anthropic_api_key,
            temperature=temperature,
            max_tokens=max_tokens
        )
        logger.info(f"‚úÖ LLM Anthropic initialis√©: {model or 'claude-3-5-sonnet-20241022'}")
        
    elif provider.lower() == "openai":
        if not settings.openai_api_key:
            raise Exception("OPENAI_API_KEY manquante dans la configuration")
        
        llm = ChatOpenAI(
            model=model or "gpt-4",
            openai_api_key=settings.openai_api_key,
            temperature=temperature,
            max_tokens=max_tokens
        )
        logger.info(f"‚úÖ LLM OpenAI initialis√©: {model or 'gpt-4'}")
        
    else:
        raise ValueError(f"Provider non support√©: {provider}. Utilisez 'anthropic' ou 'openai'")
    
    # 5. Cr√©er la cha√Æne LCEL: Prompt ‚Üí LLM ‚Üí Parser
    chain = prompt | llm | parser
    
    logger.info("‚úÖ Implementation plan chain cr√©√©e avec succ√®s")
    return chain


async def generate_implementation_plan(
    task_title: str,
    task_description: str,
    task_type: str = "feature",
    additional_context: Optional[Dict[str, Any]] = None,
    provider: str = "anthropic",
    fallback_to_openai: bool = True,
    run_step_id: Optional[int] = None
) -> ImplementationPlan:
    """
    G√©n√®re un plan d'impl√©mentation structur√© avec fallback automatique.
    
    Args:
        task_title: Titre de la t√¢che
        task_description: Description d√©taill√©e
        task_type: Type de t√¢che (feature, bugfix, refactor, etc.)
        additional_context: Contexte additionnel (dict)
        provider: Provider principal ("anthropic" ou "openai")
        fallback_to_openai: Si True, fallback vers OpenAI si le provider principal √©choue
        
    Returns:
        ImplementationPlan valid√© par Pydantic
        
    Raises:
        Exception: Si tous les providers √©chouent
    """
    context_str = str(additional_context) if additional_context else "Aucun contexte additionnel"
    
    inputs = {
        "task_title": task_title,
        "task_description": task_description,
        "task_type": task_type,
        "additional_context": context_str
    }
    
    # Cr√©er le callback pour enregistrer les interactions IA
    callbacks = []
    if run_step_id:
        from utils.langchain_db_callback import create_db_callback
        callbacks = [create_db_callback(run_step_id)]
        logger.debug(f"üìù Callback DB activ√© pour run_step_id={run_step_id}")
    
    # Tentative avec le provider principal
    try:
        logger.info(f"üöÄ G√©n√©ration plan avec {provider}...")
        chain = create_implementation_plan_chain(provider=provider)
        plan = await chain.ainvoke(inputs, config={"callbacks": callbacks})
        
        logger.info(f"‚úÖ Plan g√©n√©r√© avec succ√®s: {len(plan.steps)} √©tapes, complexit√©={plan.total_estimated_complexity}")
        return plan
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec g√©n√©ration plan avec {provider}: {e}")
        
        # Fallback vers OpenAI si configur√©
        if fallback_to_openai and provider.lower() != "openai":
            try:
                logger.info("üîÑ Fallback vers OpenAI...")
                chain_fallback = create_implementation_plan_chain(provider="openai")
                plan = await chain_fallback.ainvoke(inputs, config={"callbacks": callbacks})
                
                logger.info(f"‚úÖ Plan g√©n√©r√© avec succ√®s (fallback OpenAI): {len(plan.steps)} √©tapes")
                return plan
                
            except Exception as fallback_error:
                logger.error(f"‚ùå Fallback OpenAI √©chou√©: {fallback_error}")
                raise Exception(f"Tous les providers ont √©chou√©. Principal: {e}, Fallback: {fallback_error}")
        
        # Pas de fallback configur√©
        raise Exception(f"G√©n√©ration plan √©chou√©e avec {provider}: {e}")


def extract_plan_metrics(plan: ImplementationPlan) -> Dict[str, Any]:
    """
    Extrait les m√©triques d'un plan d'impl√©mentation.
    
    Args:
        plan: Plan d'impl√©mentation valid√©
        
    Returns:
        Dictionnaire de m√©triques
    """
    high_risk_steps = [s for s in plan.steps if s.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]]
    files_to_modify = set()
    for step in plan.steps:
        files_to_modify.update(step.files_to_modify)
    
    return {
        "total_steps": len(plan.steps),
        "total_complexity": plan.total_estimated_complexity,
        "average_complexity": plan.total_estimated_complexity / len(plan.steps) if plan.steps else 0,
        "high_risk_steps_count": len(high_risk_steps),
        "high_risk_steps_percentage": (len(high_risk_steps) / len(plan.steps) * 100) if plan.steps else 0,
        "total_files_to_modify": len(files_to_modify),
        "total_blockers": len(plan.potential_blockers),
        "has_critical_risks": any(s.risk_level == RiskLevel.CRITICAL for s in plan.steps)
    }

