═══════════════════════════════════════════════════════════════════
  ANALYSE LOGS CELERY - RECOMMANDATIONS D'AMÉLIORATION
  Date: 7 octobre 2025
═══════════════════════════════════════════════════════════════════

📊 RÉSUMÉ EXÉCUTIF
─────────────────────────────────────────────────────────────────

✅ STATUT GÉNÉRAL : AUCUNE ERREUR CRITIQUE
Le workflow s'est exécuté avec succès de bout en bout :
- Connexion RabbitMQ stable
- Traitement webhook Monday.com réussi
- Génération de code et tests automatiques
- Validation humaine détectée et traitée
- PR #23 créée, mergée et branche supprimée
- Statut Monday.com mis à jour à "Done"

Durée totale : 76.25 secondes
Tâches Celery : 2 (process_monday_webhook + execute_workflow)
Nœuds workflow : 6 (prepare → analyze → implement → test → QA → finalize → validate → merge → update)

═══════════════════════════════════════════════════════════════════
⚠️ AVERTISSEMENTS MINEURS (NON-BLOQUANTS)
═══════════════════════════════════════════════════════════════════

1. COLONNES MONDAY.COM MANQUANTES
───────────────────────────────────────────────────────────────────
Log détecté :
  "⚠️ Aucune colonne attendue trouvée. Colonnes disponibles: ['person', 'status', 'date4']"

Impact :
  - L'agent cherche des colonnes spécifiques (description, repository_url)
  - Fallback sur les updates Monday.com (fonctionne mais moins optimal)
  - Requêtes API supplémentaires pour récupérer la description

Recommandation :
  Fichier : services/monday_service.py
  
  # Ajouter configuration flexible des colonnes
  EXPECTED_COLUMNS = {
      "description": ["description", "task_description", "details", "text"],
      "repository": ["repository_url", "repo", "github_url", "git"],
      "branch": ["branch", "git_branch", "feature_branch"],
  }
  
  def get_column_value(item_columns, column_type):
      """Cherche une colonne par type avec plusieurs alias possibles"""
      for alias in EXPECTED_COLUMNS.get(column_type, []):
          if alias in item_columns:
              return item_columns[alias]
      return None
  
  # Configurer les colonnes dans votre board Monday.com :
  # - Ajouter une colonne "description" (type: Long Text)
  # - Ajouter une colonne "repository_url" (type: Link)
  # - Ou utiliser les updates (fonctionne déjà)


2. TESTS DE SMOKE SEULEMENT
───────────────────────────────────────────────────────────────────
Log détecté :
  "📝 Aucun test existant trouvé - création de tests automatiques OBLIGATOIRES"
  "🔥 Création de tests de smoke pour validation minimale"
  "✅ Test de smoke créé: smoke_tests/test_smoke.py"

Impact :
  - Validation minimale uniquement (import basique)
  - Pas de tests unitaires robustes
  - Couverture de code faible

Recommandation :
  Fichier : services/test_generator.py (à créer)
  
  class IntelligentTestGenerator:
      """Génère des tests basés sur le type de fichier et le code"""
      
      def generate_tests(self, modified_files: list, code_context: dict):
          tests = []
          
          for file_path in modified_files:
              if file_path.endswith('.py'):
                  tests.extend(self._generate_python_tests(file_path, code_context))
              elif file_path.endswith('.js') or file_path.endswith('.ts'):
                  tests.extend(self._generate_js_tests(file_path, code_context))
          
          return tests
      
      def _generate_python_tests(self, file_path, context):
          # Analyser le code pour détecter :
          # - Fonctions définies → test_function_name()
          # - Classes → test_class_initialization()
          # - API endpoints → test_endpoint_response()
          # Utiliser l'IA pour générer tests pertinents
          pass
  
  Fichier : graph/nodes/test_node.py
  
  # Modifier pour utiliser le générateur intelligent
  if not existing_tests:
      test_generator = IntelligentTestGenerator()
      generated_tests = test_generator.generate_tests(
          modified_files=state.get("modified_files", []),
          code_context=state.get("generated_code", {})
      )


3. WARNINGS DE LINTING NON CORRIGÉS
───────────────────────────────────────────────────────────────────
Log détecté :
  "⚠️ 2 avertissement(s) de linting détecté(s) (non-bloquants)"

Impact :
  - Code style non optimal
  - Potentiels bugs mineurs non détectés
  - Qualité de code réduite

Recommandation :
  Fichier : graph/nodes/quality_assurance_node.py
  
  # Ajouter auto-fix avant analyse
  def run_linting(self, file_path):
      # 1. Tenter correction automatique
      subprocess.run(["ruff", "check", "--fix", file_path])
      subprocess.run(["black", file_path])
      
      # 2. Vérifier problèmes restants
      result = subprocess.run(
          ["ruff", "check", file_path],
          capture_output=True
      )
      
      # 3. Si problèmes critiques, bloquer
      if result.returncode != 0 and self._has_critical_issues(result.stderr):
          return {"passed": False, "issues": self._parse_issues(result.stderr)}
      
      return {"passed": True, "warnings": self._parse_warnings(result.stderr)}
  
  Fichier : ruff.toml (déjà existant - vérifier config)
  
  [tool.ruff]
  line-length = 100
  target-version = "py312"
  
  [tool.ruff.lint]
  select = ["E", "F", "W", "I", "N"]
  ignore = ["E501"]  # Ligne trop longue (géré par black)
  
  [tool.ruff.lint.per-file-ignores]
  "__init__.py" = ["F401"]  # Imports inutilisés OK dans __init__


4. POLLING INTENSIF VALIDATION HUMAINE
───────────────────────────────────────────────────────────────────
Log détecté :
  "⏳ Attente de reply humaine (timeout: 10min, check_interval: 5s, max_no_changes: 24)"
  Requêtes API : 3 tentatives avant de trouver la réponse "oui"
  
  Tentative 1 (5s)  : Aucune reply
  Tentative 2 (10s) : Aucune reply
  Tentative 3 (15s) : Reply trouvée ✅

Impact :
  - Latence de 10-15 secondes
  - 3 appels API Monday.com au lieu de 1
  - Limite rate API consommée

Recommandation A (Court terme) :
  Fichier : graph/nodes/monday_validation_node.py
  
  # Backoff exponentiel avec jitter
  async def wait_for_human_reply(self, update_id, timeout=600):
      check_intervals = [2, 3, 5, 8, 13, 21]  # Suite Fibonacci
      start_time = time.time()
      
      for interval in itertools.cycle(check_intervals):
          if time.time() - start_time > timeout:
              raise TimeoutError("Pas de réponse humaine")
          
          reply = await self._check_for_reply(update_id)
          if reply:
              return reply
          
          # Ajouter jitter pour éviter thundering herd
          jitter = random.uniform(0, 0.5)
          await asyncio.sleep(interval + jitter)

Recommandation B (Long terme - OPTIMAL) :
  Fichier : services/webhook_receiver.py (à créer)
  
  # Implémenter webhook Monday.com pour notifications temps réel
  from fastapi import FastAPI, Request
  
  app = FastAPI()
  validation_responses = {}  # Cache des réponses
  
  @app.post("/monday/validation-response")
  async def receive_validation_response(request: Request):
      """Reçoit les réponses de validation en temps réel"""
      data = await request.json()
      
      if data.get("event", {}).get("type") == "create_update":
          update_id = data["event"]["parentUpdateId"]
          reply_text = data["event"]["textBody"]
          
          # Stocker dans cache + notifier workflow
          validation_responses[update_id] = reply_text
          await notify_workflow(update_id, reply_text)
      
      return {"status": "ok"}
  
  # Configuration Monday.com :
  # 1. Aller dans Intégrations → Webhooks
  # 2. Créer webhook : Event = "create_update"
  # 3. URL = https://votre-domaine.com/monday/validation-response
  # 4. Filtrer sur board_id = 2135637353


5. LOGS EN WARNING AU LIEU D'INFO
───────────────────────────────────────────────────────────────────
Log détecté :
  [WARNING] "✅ Service de persistence initialisé"
  [WARNING] "✅ Persistence base de données initialisée"
  [WARNING] "📋 Tâche créée: Ajouter un fichier main"
  [WARNING] "🚀 Démarrage du monitoring custom"

Impact :
  - Logs normaux marqués comme warnings
  - Difficulté à filtrer les vrais problèmes
  - Alerting pollué

Recommandation :
  Fichiers multiples : services/*.py, graph/nodes/*.py
  
  # Remplacer tous les logger.warning par logger.info pour événements normaux
  
  # ❌ AVANT
  logger.warning(json.dumps({"event": "✅ Service initialisé", "level": "info"}))
  
  # ✅ APRÈS
  logger.info(json.dumps({"event": "✅ Service initialisé", "level": "info"}))
  
  # Garder logger.warning seulement pour vrais avertissements
  logger.warning(json.dumps({"event": "⚠️ Colonne manquante", "level": "warning"}))
  
  # Utiliser logger.error pour erreurs
  logger.error(json.dumps({"event": "❌ Échec API", "level": "error"}))


═══════════════════════════════════════════════════════════════════
🚀 OPTIMISATIONS RECOMMANDÉES
═══════════════════════════════════════════════════════════════════

1. MÉTRIQUES DE PERFORMANCE PAR TÂCHE
───────────────────────────────────────────────────────────────────
Fichier : services/celery_app.py

from celery.signals import task_prerun, task_postrun, task_failure
import time

task_metrics = {}

@task_prerun.connect
def task_prerun_handler(task_id, task, *args, **kwargs):
    """Enregistre le début d'exécution"""
    task_metrics[task_id] = {
        "name": task.name,
        "start_time": time.time(),
        "args": args,
        "kwargs": kwargs
    }
    logger.info(f"⏱️ Démarrage tâche {task.name} (ID: {task_id})")

@task_postrun.connect
def task_postrun_handler(task_id, task, *args, **kwargs):
    """Calcule et log la durée"""
    if task_id in task_metrics:
        duration = time.time() - task_metrics[task_id]["start_time"]
        logger.info(f"✅ Tâche {task.name} terminée en {duration:.2f}s")
        
        # Sauvegarder métriques en DB pour analyse
        save_task_metrics(task_id, task.name, duration, success=True)
        
        del task_metrics[task_id]

@task_failure.connect
def task_failure_handler(task_id, exception, *args, **kwargs):
    """Log les échecs"""
    if task_id in task_metrics:
        duration = time.time() - task_metrics[task_id]["start_time"]
        logger.error(f"❌ Tâche échouée après {duration:.2f}s: {exception}")
        
        save_task_metrics(task_id, task.name, duration, success=False, error=str(exception))
        
        del task_metrics[task_id]


2. AMÉLIORATION DÉTECTION RÉPONSES MONDAY.COM
───────────────────────────────────────────────────────────────────
Fichier : services/monday_service.py

APPROVAL_KEYWORDS = {
    "approve": {
        "french": ["oui", "ok", "valide", "parfait", "c'est bon", "go", "approuvé"],
        "english": ["yes", "approve", "approved", "lgtm", "looks good", "ok", "go"],
        "emoji": ["👍", "✅", "✔️", "👌", "💯"],
    },
    "reject": {
        "french": ["non", "refuse", "refusé", "pas bon", "incorrect", "ko"],
        "english": ["no", "reject", "rejected", "nope", "decline", "declined"],
        "emoji": ["👎", "❌", "🚫", "⛔"],
    },
    "needs_changes": {
        "french": ["modif", "modification", "correction", "change", "à revoir", "presque"],
        "english": ["change", "modify", "fix", "update", "revise", "almost"],
        "emoji": ["⚠️", "🔧", "🔨", "📝"],
    }
}

def analyze_human_response(reply_text: str) -> dict:
    """
    Analyse intelligente avec score de confiance
    """
    reply_lower = reply_text.lower().strip()
    reply_clean = re.sub(r'<[^>]+>', '', reply_lower)  # Retirer HTML
    
    # Recherche exacte
    for decision, keywords_dict in APPROVAL_KEYWORDS.items():
        for lang, keywords in keywords_dict.items():
            for keyword in keywords:
                if keyword in reply_clean or keyword in reply_text:
                    # Confiance haute pour match exact
                    return {
                        "decision": decision,
                        "confidence": 0.95 if lang == "emoji" else 0.98,
                        "matched_keyword": keyword,
                        "language": lang
                    }
    
    # Fallback : analyse IA pour réponses ambiguës
    if len(reply_clean) > 50:  # Réponse longue
        return analyze_with_ai(reply_text)
    
    # Réponse courte non reconnue
    return {
        "decision": "unclear",
        "confidence": 0.0,
        "original_text": reply_text
    }


3. RETRY AUTOMATIQUE AVEC EXPONENTIAL BACKOFF
───────────────────────────────────────────────────────────────────
Fichier : services/celery_app.py

@celery_app.task(
    bind=True,
    autoretry_for=(Exception,),
    retry_kwargs={'max_retries': 3},
    retry_backoff=True,  # Exponential backoff
    retry_backoff_max=600,  # Max 10 minutes
    retry_jitter=True  # Ajoute randomisation
)
def process_monday_webhook(self, webhook_data: dict):
    try:
        # Traitement normal
        result = handle_webhook(webhook_data)
        return result
    except TemporaryError as exc:
        # Retry automatique
        logger.warning(f"⚠️ Erreur temporaire, retry dans {self.request.retries * 60}s")
        raise self.retry(exc=exc)
    except PermanentError as exc:
        # Pas de retry
        logger.error(f"❌ Erreur permanente, pas de retry: {exc}")
        raise


4. NETTOYAGE AUTOMATIQUE DES RÉSULTATS
───────────────────────────────────────────────────────────────────
Fichier : config/celery_config.py

# Configuration Celery optimisée
celery_config = {
    # Résultats
    "result_expires": 3600,  # Nettoyer après 1h
    "result_compression": "gzip",  # Compresser les gros résultats
    
    # Tasks
    "task_acks_late": True,  # ACK après succès
    "task_reject_on_worker_lost": True,  # Rejeter si worker crash
    "task_time_limit": 1800,  # 30 min max
    "task_soft_time_limit": 1500,  # Warning à 25 min
    
    # Worker
    "worker_prefetch_multiplier": 1,  # Pas de prefetch (workflows longs)
    "worker_max_tasks_per_child": 100,  # Redémarrer worker tous les 100 tasks
    
    # Retry
    "task_default_retry_delay": 60,  # 1 min entre retries
    "task_max_retries": 3,
}

# Tâche périodique de nettoyage
@celery_app.task
def cleanup_old_results():
    """Nettoie les anciens résultats et états"""
    from datetime import datetime, timedelta
    
    cutoff = datetime.utcnow() - timedelta(hours=24)
    
    # Nettoyer DB
    db.query(TaskRun).filter(
        TaskRun.completed_at < cutoff,
        TaskRun.status.in_(["completed", "failed"])
    ).delete()
    
    logger.info("🧹 Nettoyage des anciens résultats terminé")

# Ajouter dans beat schedule
celery_app.conf.beat_schedule = {
    "cleanup-every-hour": {
        "task": "cleanup_old_results",
        "schedule": crontab(minute=0),  # Toutes les heures
    }
}


5. MONITORING AVEC FLOWER
───────────────────────────────────────────────────────────────────
Installation :
  pip install flower

Lancement :
  celery -A services.celery_app flower --port=5555

Configuration : config/flower_config.py
  
  flower_config = {
      "port": 5555,
      "broker_api": "http://localhost:15672/api/",
      "persistent": True,
      "db": "flower.db",
      "max_tasks": 10000,
      
      # Auth (production)
      "basic_auth": ["admin:password"],
      
      # Email alerts
      "email": {
          "from": "celery@aiagent.com",
          "to": ["admin@aiagent.com"],
          "smtp": "smtp.gmail.com:587",
      }
  }

Accès : http://localhost:5555
  - Dashboard temps réel
  - Statistiques par worker
  - Graphiques de performance
  - Gestion des tâches (retry, revoke)


═══════════════════════════════════════════════════════════════════
📋 CHECKLIST D'IMPLÉMENTATION
═══════════════════════════════════════════════════════════════════

PRIORITÉ HAUTE (À faire maintenant) ⚠️
───────────────────────────────────────────────────────────────────
□ Changer tous les logger.warning → logger.info pour événements normaux
  Fichiers : services/*.py, graph/nodes/*.py
  Temps estimé : 30 minutes
  Impact : Clarté des logs, facilite debugging

□ Ajouter configuration flexible colonnes Monday.com
  Fichier : services/monday_service.py
  Temps estimé : 1 heure
  Impact : Moins de requêtes API, performance améliorée

□ Améliorer détection réponses validation (keywords + emojis)
  Fichier : services/monday_service.py
  Temps estimé : 2 heures
  Impact : Validation plus robuste, moins d'erreurs


PRIORITÉ MOYENNE (Cette semaine) 📅
───────────────────────────────────────────────────────────────────
□ Implémenter générateur de tests intelligent
  Fichiers : services/test_generator.py (nouveau), graph/nodes/test_node.py
  Temps estimé : 1 jour
  Impact : Meilleure couverture de tests, moins de bugs

□ Optimiser polling validation (backoff exponentiel)
  Fichier : graph/nodes/monday_validation_node.py
  Temps estimé : 2 heures
  Impact : Réduction latence, économie API calls

□ Ajouter auto-fix linting (ruff --fix, black)
  Fichier : graph/nodes/quality_assurance_node.py
  Temps estimé : 1 heure
  Impact : Code style consistant automatiquement

□ Configurer retry automatique avec exponential backoff
  Fichier : services/celery_app.py
  Temps estimé : 1 heure
  Impact : Résilience améliorée


PRIORITÉ BASSE (Amélioration continue) 🔄
───────────────────────────────────────────────────────────────────
□ Implémenter webhook Monday.com pour validation temps réel
  Fichiers : services/webhook_receiver.py (nouveau)
  Temps estimé : 1 jour
  Impact : Latence quasi-nulle, meilleure UX

□ Ajouter métriques de performance par tâche
  Fichier : services/celery_app.py
  Temps estimé : 3 heures
  Impact : Monitoring précis, optimisation ciblée

□ Installer et configurer Flower pour monitoring
  Installation + configuration
  Temps estimé : 2 heures
  Impact : Dashboard visuel, alerting

□ Implémenter nettoyage automatique résultats
  Fichier : config/celery_config.py
  Temps estimé : 1 heure
  Impact : Base de données optimisée

□ Créer dashboard métriques temps réel (Prometheus + Grafana)
  Setup complet infrastructure
  Temps estimé : 2 jours
  Impact : Observabilité production


═══════════════════════════════════════════════════════════════════
📊 MÉTRIQUES DE PERFORMANCE ACTUELLES
═══════════════════════════════════════════════════════════════════

Workflow complet : 76.25 secondes
├─ process_monday_webhook : 3.08s
└─ execute_workflow : 76.25s
   ├─ prepare_environment : 2.04s
   ├─ analyze_requirements : 11.28s (API Anthropic)
   ├─ implement_task : 25.32s (API Anthropic)
   ├─ run_tests : 0.08s
   ├─ quality_assurance : 1.80s
   ├─ finalize_pr : 7.91s (Push GitHub + Create PR)
   ├─ monday_validation : 16.98s (Polling + Wait reply)
   ├─ merge_after_validation : 6.03s (Merge PR + Delete branch)
   └─ update_monday : 2.78s (Update status + Comment)

GOULOTS D'ÉTRANGLEMENT :
1. implement_task (25s) - Génération code IA → Normal
2. monday_validation (17s) - Polling → OPTIMISABLE
3. analyze_requirements (11s) - Analyse IA → Normal
4. finalize_pr (8s) - GitHub API → Normal

OBJECTIF POST-OPTIMISATION :
- Réduire monday_validation : 17s → 2s (webhook ou backoff)
- Total workflow : 76s → 61s (-20%)


═══════════════════════════════════════════════════════════════════
✅ CONCLUSION
═══════════════════════════════════════════════════════════════════

STATUT : SYSTÈME FONCTIONNEL - AUCUNE ERREUR CRITIQUE ✅

Le workflow Celery fonctionne parfaitement de bout en bout. Les logs
montrent une exécution réussie avec :
- Détection webhook Monday.com
- Génération code par IA
- Tests automatiques
- Validation humaine
- Merge automatique
- Mise à jour statut

Les recommandations ci-dessus sont des OPTIMISATIONS pour améliorer :
- Performance (réduction latence validation)
- Robustesse (retry, tests meilleurs)
- Maintenabilité (logs propres, monitoring)
- Expérience utilisateur (feedback plus rapide)

Aucune urgence, implémentation progressive recommandée selon priorités.

═══════════════════════════════════════════════════════════════════
📞 SUPPORT
═══════════════════════════════════════════════════════════════════

Questions ou aide pour implémenter ces recommandations ?
Contactez l'équipe de développement ou consultez la documentation :
- Celery : https://docs.celeryproject.org/
- RabbitMQ : https://www.rabbitmq.com/documentation.html
- Monday.com API : https://developer.monday.com/api-reference
- LangChain : https://python.langchain.com/docs/

═══════════════════════════════════════════════════════════════════
