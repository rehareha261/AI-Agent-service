-- ============================================================
--  AI‑Agent — Schéma PostgreSQL (hybride optimisé)
--  Conçu pour : webhook Monday -> FastAPI -> Celery/Redis ->
--                LangGraph -> GitHub -> Monday + Monitoring
--  Principes : TIMESTAMPTZ partout, BIGINT IDs, JSONB + GIN,
--              index composés, partition pour événements/logs.
-- ============================================================

-- Extensions utiles (facultatives mais recommandées)
-- CREATE EXTENSION IF NOT EXISTS pg_trgm;       -- recherche texte
-- CREATE EXTENSION IF NOT EXISTS btree_gin;     -- GIN sur types scalaires

-- ============================================================
-- 1) TÂCHES (entités « métier » venant de Monday)
-- ============================================================
CREATE TABLE IF NOT EXISTS tasks (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    monday_item_id BIGINT UNIQUE NOT NULL,
    monday_board_id BIGINT,

    title VARCHAR(500) NOT NULL,
    description TEXT,
    priority VARCHAR(50),  -- 'low'|'medium'|'high' etc. (mappé depuis Monday)

    repository_url VARCHAR(500) NOT NULL,
    repository_name VARCHAR(200),
    default_branch VARCHAR(100) DEFAULT 'main',

    monday_status VARCHAR(100),
    internal_status VARCHAR(50) NOT NULL DEFAULT 'pending',

    created_by_user_id BIGINT,
    assigned_to TEXT,

    -- Dénormalisation utile : pointeur vers le dernier run
    last_run_id BIGINT,

    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,

    CONSTRAINT tasks_internal_status_chk CHECK (
        internal_status IN ('pending','processing','testing','debugging','quality_check','completed','failed')
    )
);

CREATE INDEX IF NOT EXISTS idx_tasks_monday_item_id ON tasks(monday_item_id);
CREATE INDEX IF NOT EXISTS idx_tasks_internal_status ON tasks(internal_status);
CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_tasks_updated_at ON tasks(updated_at DESC);

-- ============================================================
-- 2) EXÉCUTIONS (runs) — correspond à un job Celery / workflow
-- ============================================================
CREATE TABLE IF NOT EXISTS task_runs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,

    run_number INTEGER,  -- numérotation par tâche (optionnelle, gérée app)
    status VARCHAR(50) NOT NULL DEFAULT 'started',
    celery_task_id VARCHAR(255) UNIQUE,

    current_node VARCHAR(100),
    progress_percentage INTEGER DEFAULT 0,

    ai_provider VARCHAR(50),    -- 'claude' | 'openai' | ...
    model_name  VARCHAR(100),

    result JSONB,
    error_message TEXT,

    git_branch_name VARCHAR(255),
    pull_request_url VARCHAR(500),

    started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMPTZ,
    duration_seconds INTEGER,

    CONSTRAINT task_runs_status_chk CHECK (
        status IN ('started','running','completed','failed','retry')
    )
);

CREATE UNIQUE INDEX IF NOT EXISTS uq_task_runs_task_run_number ON task_runs(task_id, run_number);
CREATE INDEX IF NOT EXISTS idx_task_runs_task_started ON task_runs(task_id, started_at DESC);
CREATE INDEX IF NOT EXISTS idx_task_runs_status ON task_runs(status);
CREATE INDEX IF NOT EXISTS idx_task_runs_celery ON task_runs(celery_task_id);

-- ============================================================
-- 3) ÉTAPES (nœuds LangGraph) d'un run
-- ============================================================
CREATE TABLE IF NOT EXISTS run_steps (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL REFERENCES task_runs(id) ON DELETE CASCADE,

    node_name VARCHAR(100) NOT NULL,   -- ex: 'prepare_environment'
    step_order INTEGER NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    retry_count INTEGER NOT NULL DEFAULT 0,
    max_retries INTEGER NOT NULL DEFAULT 3,

    input_data  JSONB,
    output_data JSONB,
    output_log  TEXT,
    error_details TEXT,

    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    duration_seconds INTEGER,

    CONSTRAINT run_steps_status_chk CHECK (
        status IN ('pending','running','completed','failed','skipped','retry')
    )
);

CREATE INDEX IF NOT EXISTS idx_run_steps_run_order ON run_steps(task_run_id, step_order);
CREATE INDEX IF NOT EXISTS idx_run_steps_name_status ON run_steps(node_name, status);
CREATE INDEX IF NOT EXISTS idx_run_steps_task_run ON run_steps(task_run_id);
CREATE INDEX IF NOT EXISTS gin_run_steps_input ON run_steps USING GIN (input_data);
CREATE INDEX IF NOT EXISTS gin_run_steps_output ON run_steps USING GIN (output_data);

-- ============================================================
-- 4) INTERACTIONS IA (prompts/completions + métadonnées)
-- ============================================================
CREATE TABLE IF NOT EXISTS ai_interactions (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    run_step_id BIGINT NOT NULL REFERENCES run_steps(id) ON DELETE CASCADE,

    ai_provider VARCHAR(50) NOT NULL,
    model_name  VARCHAR(100) NOT NULL,

    prompt   TEXT NOT NULL,
    response TEXT,

    token_usage JSONB,    -- {"prompt_tokens": n, "completion_tokens": m}
    latency_ms INTEGER,

    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_ai_interactions_step ON ai_interactions(run_step_id);
CREATE INDEX IF NOT EXISTS gin_ai_interactions_token ON ai_interactions USING GIN (token_usage);

-- ============================================================
-- 5) GÉNÉRATIONS DE CODE IA (détails par itération)
-- ============================================================
CREATE TABLE IF NOT EXISTS ai_code_generations (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL REFERENCES task_runs(id) ON DELETE CASCADE,

    provider VARCHAR(50) NOT NULL,
    model VARCHAR(100) NOT NULL,
    generation_type VARCHAR(50),   -- 'initial' | 'debug' | 'refactor'

    prompt TEXT NOT NULL,
    generated_code TEXT,

    tokens_used INTEGER,
    response_time_ms INTEGER,
    cost_estimate NUMERIC(12,6),

    compilation_successful BOOLEAN,
    syntax_valid BOOLEAN,

    files_modified JSONB,      -- array de chemins de fichiers
    generated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_ai_code_gen_run ON ai_code_generations(task_run_id);
CREATE INDEX IF NOT EXISTS gin_ai_code_gen_files ON ai_code_generations USING GIN (files_modified);

-- ============================================================
-- 6) RÉSULTATS DE TEST
-- ============================================================
CREATE TABLE IF NOT EXISTS test_results (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL UNIQUE REFERENCES task_runs(id) ON DELETE CASCADE,

    passed BOOLEAN NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'passed',  -- 'passed'/'failed'/'error'/'timeout'

    tests_total INTEGER DEFAULT 0,
    tests_passed INTEGER DEFAULT 0,
    tests_failed INTEGER DEFAULT 0,
    tests_skipped INTEGER DEFAULT 0,

    coverage_percentage NUMERIC(5,2),
    pytest_report JSONB,
    security_scan_report JSONB,

    executed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    duration_seconds INTEGER
);

CREATE INDEX IF NOT EXISTS idx_test_results_run ON test_results(task_run_id);
CREATE INDEX IF NOT EXISTS gin_test_results_pytest ON test_results USING GIN (pytest_report);
CREATE INDEX IF NOT EXISTS gin_test_results_sec ON test_results USING GIN (security_scan_report);

-- ============================================================
-- 7) PULL REQUESTS GITHUB
-- ============================================================
CREATE TABLE IF NOT EXISTS pull_requests (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(id) ON DELETE SET NULL,

    github_pr_number INTEGER,
    github_pr_url VARCHAR(500),

    pr_title VARCHAR(500),
    pr_description TEXT,

    pr_status VARCHAR(50),  -- 'open'|'merged'|'closed'
    mergeable BOOLEAN,
    conflicts BOOLEAN DEFAULT FALSE,

    reviews_required INTEGER DEFAULT 1,
    reviews_approved INTEGER DEFAULT 0,

    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    merged_at TIMESTAMPTZ,
    closed_at TIMESTAMPTZ,

    head_sha CHAR(40),
    base_branch VARCHAR(100) DEFAULT 'main',
    feature_branch VARCHAR(100)
);

CREATE INDEX IF NOT EXISTS idx_pr_task ON pull_requests(task_id);
CREATE INDEX IF NOT EXISTS idx_pr_status ON pull_requests(pr_status);
CREATE INDEX IF NOT EXISTS idx_pr_number ON pull_requests(github_pr_number);

-- ============================================================
-- 8) WEBHOOKS (partitionné par temps)
-- ============================================================
CREATE TABLE IF NOT EXISTS webhook_events (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    source VARCHAR(50) NOT NULL,   -- 'monday' | 'github' | ...
    event_type VARCHAR(100),

    payload JSONB NOT NULL,
    headers JSONB,
    signature TEXT,

    processed BOOLEAN NOT NULL DEFAULT FALSE,
    processing_status VARCHAR(50) NOT NULL DEFAULT 'pending',  -- 'pending'|'processed'|'failed'|'ignored'
    error_message TEXT,

    related_task_id BIGINT REFERENCES tasks(id) ON DELETE SET NULL,

    received_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    processed_at TIMESTAMPTZ
) PARTITION BY RANGE (received_at);

-- Exemple de partition mensuelle (à créer par job cron)
CREATE TABLE IF NOT EXISTS webhook_events_2025_09
    PARTITION OF webhook_events FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

CREATE INDEX IF NOT EXISTS idx_webhook_events_processed_part ON webhook_events_2025_09(processed, received_at);
CREATE INDEX IF NOT EXISTS idx_webhook_events_source_part ON webhook_events_2025_09(source, event_type);
CREATE INDEX IF NOT EXISTS gin_webhook_payload_part ON webhook_events_2025_09 USING GIN (payload);
CREATE INDEX IF NOT EXISTS gin_webhook_headers_part ON webhook_events_2025_09 USING GIN (headers);

-- ============================================================
-- 9) LOGS APPLI / AUDIT (option : partitionner par mois aussi)
-- ============================================================
CREATE TABLE IF NOT EXISTS application_logs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(id) ON DELETE SET NULL,
    task_run_id BIGINT REFERENCES task_runs(id) ON DELETE SET NULL,
    run_step_id BIGINT REFERENCES run_steps(id) ON DELETE SET NULL,

    level VARCHAR(20) NOT NULL,      -- 'DEBUG'|'INFO'|'WARNING'|'ERROR'|'CRITICAL'
    source_component VARCHAR(100),   -- 'api_gateway'|'celery_worker'|...
    action VARCHAR(100),
    message TEXT NOT NULL,

    metadata JSONB,
    user_id BIGINT,
    ip_address INET,

    ts TIMESTAMPTZ NOT NULL DEFAULT NOW(),

    CONSTRAINT application_logs_level_chk CHECK (
        level IN ('DEBUG','INFO','WARNING','ERROR','CRITICAL')
    )
);

-- 1. Table des providers AI (optionnelle)
CREATE TABLE ai_providers (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    name VARCHAR(50) UNIQUE NOT NULL,
    api_endpoint VARCHAR(500),
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_app_logs_level_ts ON application_logs(level, ts DESC);
CREATE INDEX IF NOT EXISTS idx_app_logs_task ON application_logs(task_id, ts DESC);
CREATE INDEX IF NOT EXISTS gin_app_logs_metadata ON application_logs USING GIN (metadata);
-- 2. Index sur les colonnes JSONB fréquemment utilisées
CREATE INDEX gin_tasks_metadata ON tasks USING GIN (metadata);
CREATE INDEX gin_webhook_payload ON webhook_events USING GIN (payload);

-- ============================================================
-- 10) MÉTRIQUES DE PERFORMANCE (agrégées par run/tâche)
-- ============================================================
CREATE TABLE IF NOT EXISTS performance_metrics (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(id) ON DELETE CASCADE,

    total_duration_seconds INTEGER,
    queue_wait_time_seconds INTEGER,
    ai_processing_time_seconds INTEGER,
    testing_time_seconds INTEGER,

    total_ai_calls INTEGER DEFAULT 0,
    total_tokens_used INTEGER DEFAULT 0,
    total_ai_cost NUMERIC(12,6) DEFAULT 0.0,

    code_lines_generated INTEGER DEFAULT 0,
    test_coverage_final NUMERIC(5,2),
    security_issues_found INTEGER DEFAULT 0,

    retry_attempts INTEGER DEFAULT 0,
    success_rate NUMERIC(5,2),

    recorded_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_perf_task_run ON performance_metrics(task_id, task_run_id);
CREATE INDEX IF NOT EXISTS idx_perf_recorded ON performance_metrics(recorded_at DESC);

-- ============================================================
-- 11) CONFIGURATION SYSTÈME (clés/valeurs versionnées)
-- ============================================================
CREATE TABLE IF NOT EXISTS system_config (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    key VARCHAR(100) UNIQUE NOT NULL,
    value JSONB NOT NULL,
    description TEXT,
    config_type VARCHAR(50) NOT NULL DEFAULT 'application',

    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_by VARCHAR(100)
);

-- 3. Fonction de nettoyage automatique
CREATE OR REPLACE FUNCTION cleanup_old_logs() RETURNS void AS $$
BEGIN
    DELETE FROM webhook_events WHERE received_at < NOW() - INTERVAL '6 months';
    DELETE FROM application_logs WHERE ts < NOW() - INTERVAL '3 months';
END;
$$ LANGUAGE plpgsql;

-- Trigger générique pour updated_at
CREATE OR REPLACE FUNCTION trg_touch_updated_at() RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;$$ LANGUAGE plpgsql;

DO $$ BEGIN
    IF NOT EXISTS (
        SELECT 1 FROM pg_trigger WHERE tgname = 'touch_tasks_updated_at'
    ) THEN
        CREATE TRIGGER touch_tasks_updated_at
        BEFORE UPDATE ON tasks
        FOR EACH ROW EXECUTE FUNCTION trg_touch_updated_at();
    END IF;

    IF NOT EXISTS (
        SELECT 1 FROM pg_trigger WHERE tgname = 'touch_system_config_updated_at'
    ) THEN
        CREATE TRIGGER touch_system_config_updated_at
        BEFORE UPDATE ON system_config
        FOR EACH ROW EXECUTE FUNCTION trg_touch_updated_at();
    END IF;
END $$;

-- ============================================================
-- 12) VUES PRATIQUES (dashboards)
-- ============================================================
CREATE OR REPLACE VIEW dashboard_summary AS
SELECT 
    t.id AS task_id,
    t.title,
    t.monday_status,
    t.internal_status,
    t.priority,
    t.created_at,
    tr.status AS last_run_status,
    tr.current_node,
    tr.progress_percentage,
    pr.github_pr_url,
    pr.pr_status
FROM tasks t
LEFT JOIN LATERAL (
    SELECT * FROM task_runs r
    WHERE r.task_id = t.id
    ORDER BY r.started_at DESC
    LIMIT 1
) tr ON TRUE
LEFT JOIN LATERAL (
    SELECT * FROM pull_requests p
    WHERE p.task_id = t.id
    ORDER BY p.created_at DESC
    LIMIT 1
) pr ON TRUE
ORDER BY t.created_at DESC;

CREATE OR REPLACE VIEW performance_dashboard AS
SELECT 
    DATE_TRUNC('day', t.created_at) AS date,
    COUNT(t.id) AS total_tasks,
    COUNT(*) FILTER (WHERE tr.status = 'completed') AS completed_tasks,
    COUNT(*) FILTER (WHERE tr.status = 'failed') AS failed_tasks,
    AVG(pm.total_duration_seconds) AS avg_duration,
    AVG(pm.total_ai_cost) AS avg_cost,
    AVG(pm.test_coverage_final) AS avg_coverage
FROM tasks t
LEFT JOIN LATERAL (
    SELECT * FROM task_runs r
    WHERE r.task_id = t.id
    ORDER BY r.started_at DESC
    LIMIT 1
) tr ON TRUE
LEFT JOIN performance_metrics pm ON pm.task_id = t.id
GROUP BY 1
ORDER BY 1 DESC;
