-- ===============================================
-- SCHÉMA COMPLET DE LA BASE DE DONNÉES AI-AGENT
-- ===============================================
-- Description: Schéma complet combinant toutes les tables du projet
-- Version: 2.0
-- Date: 06 Octobre 2025
-- Compatible: PostgreSQL 14+
-- ===============================================

-- ===============================================
-- 1. TABLES PRINCIPALES DU WORKFLOW
-- ===============================================

-- 1.1) TÂCHES (entités « métier » venant de Monday.com)
CREATE TABLE IF NOT EXISTS tasks (
    tasks_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    monday_item_id BIGINT UNIQUE NOT NULL,
    monday_board_id BIGINT,
    title VARCHAR(500) NOT NULL,
    description TEXT,
    priority VARCHAR(50),  -- 'low'|'medium'|'high' etc.
    repository_url VARCHAR(500) NOT NULL,
    repository_name VARCHAR(200),
    default_branch VARCHAR(100) DEFAULT 'main',
    monday_status VARCHAR(100),
    internal_status VARCHAR(50) NOT NULL DEFAULT 'pending',
    created_by_user_id BIGINT,
    assigned_to TEXT,
    
    -- Dénormalisation : pointeur vers le dernier run
    last_run_id BIGINT,
    
    -- Timestamps
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    
    CONSTRAINT tasks_internal_status_chk CHECK (
        internal_status IN ('pending','processing','testing','debugging','quality_check','completed','failed')
    )
);

CREATE INDEX IF NOT EXISTS idx_tasks_monday_item_id ON tasks(monday_item_id);
CREATE INDEX IF NOT EXISTS idx_tasks_internal_status_partial ON tasks(internal_status) 
    WHERE internal_status IN ('pending','processing');
CREATE INDEX IF NOT EXISTS idx_tasks_repository ON tasks(repository_url);
CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks(created_at DESC);

COMMENT ON TABLE tasks IS 'Tâches provenant de Monday.com pour le workflow AI';
COMMENT ON COLUMN tasks.monday_item_id IS 'ID de l''item Monday.com (unique)';
COMMENT ON COLUMN tasks.tasks_id IS 'ID interne de la base de données (utilisé pour les foreign keys)';

-- ===============================================
-- 1.2) EXÉCUTIONS (runs) — correspond à un job Celery / workflow LangGraph
-- ===============================================
CREATE TABLE IF NOT EXISTS task_runs (
    tasks_runs_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE SET NULL,
    run_number INTEGER,  -- numérotation par tâche
    status VARCHAR(50) NOT NULL DEFAULT 'started',
    celery_task_id VARCHAR(255) UNIQUE,
    current_node VARCHAR(100),
    progress_percentage INTEGER DEFAULT 0,
    ai_provider VARCHAR(50),    -- 'claude' | 'openai'
    model_name VARCHAR(100),
    result JSONB,
    error_message TEXT,
    git_branch_name VARCHAR(255),
    pull_request_url VARCHAR(500),
    
    -- Timestamps
    started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMPTZ,
    duration_seconds INTEGER,
    
    CONSTRAINT task_runs_status_chk CHECK (
        status IN ('started','running','completed','failed','retry')
    )
);

CREATE UNIQUE INDEX IF NOT EXISTS uq_task_runs_task_run_number ON task_runs(task_id, run_number);
CREATE INDEX IF NOT EXISTS idx_task_runs_task_started ON task_runs(task_id, started_at DESC);
CREATE INDEX IF NOT EXISTS idx_task_runs_status ON task_runs(status);
CREATE INDEX IF NOT EXISTS idx_task_runs_celery ON task_runs(celery_task_id);

COMMENT ON TABLE task_runs IS 'Exécutions de workflows (jobs Celery)';
COMMENT ON COLUMN task_runs.celery_task_id IS 'ID de la tâche Celery (UUID)';

-- ===============================================
-- 1.3) ÉTAPES (nœuds LangGraph) d'un run
-- ===============================================
CREATE TABLE IF NOT EXISTS run_steps (
    run_steps_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    node_name VARCHAR(100) NOT NULL,   -- ex: 'prepare_environment', 'implement_task'
    step_order INTEGER NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    retry_count INTEGER NOT NULL DEFAULT 0,
    max_retries INTEGER NOT NULL DEFAULT 3,
    
    -- Données d'entrée/sortie
    input_data JSONB,
    output_data JSONB,
    output_log TEXT,
    error_details TEXT,
    checkpoint_data JSONB,
    
    -- Timestamps
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    checkpoint_saved_at TIMESTAMPTZ,
    duration_seconds INTEGER,
    
    CONSTRAINT run_steps_status_chk CHECK (
        status IN ('pending','running','completed','failed','skipped','retry')
    )
);

CREATE INDEX IF NOT EXISTS idx_run_steps_run_order ON run_steps(task_run_id, step_order);
CREATE INDEX IF NOT EXISTS idx_run_steps_name_status ON run_steps(node_name, status);
CREATE INDEX IF NOT EXISTS idx_run_steps_task_run ON run_steps(task_run_id);

COMMENT ON TABLE run_steps IS 'Étapes individuelles d''un workflow (nœuds LangGraph)';

-- ===============================================
-- 1.4) CHECKPOINTS des étapes
-- ===============================================
CREATE TABLE IF NOT EXISTS run_step_checkpoints (
    checkpoint_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    step_id BIGINT NOT NULL REFERENCES run_steps(run_steps_id) ON DELETE CASCADE,
    checkpoint_data JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ
);

CREATE INDEX IF NOT EXISTS idx_checkpoints_step_id ON run_step_checkpoints(step_id);
CREATE INDEX IF NOT EXISTS idx_checkpoints_created_at ON run_step_checkpoints(created_at DESC);

COMMENT ON TABLE run_step_checkpoints IS 'Checkpoints pour la reprise après erreur';

-- ===============================================
-- 2. TABLES D'INTERACTIONS IA
-- ===============================================

-- 2.1) INTERACTIONS IA (prompts/completions + métadonnées)
CREATE TABLE IF NOT EXISTS ai_interactions (
    ai_interactions_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    run_step_id BIGINT NOT NULL REFERENCES run_steps(run_steps_id) ON DELETE CASCADE,
    ai_provider VARCHAR(50) NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    prompt TEXT NOT NULL,
    response TEXT,
    token_usage JSONB,    -- {"prompt_tokens": n, "completion_tokens": m}
    latency_ms INTEGER,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_ai_interactions_step ON ai_interactions(run_step_id);
CREATE INDEX IF NOT EXISTS idx_ai_interactions_provider ON ai_interactions(ai_provider, created_at DESC);

COMMENT ON TABLE ai_interactions IS 'Historique des interactions avec les modèles IA';

-- 2.2) GÉNÉRATIONS DE CODE IA (détails par itération)
CREATE TABLE IF NOT EXISTS ai_code_generations (
    ai_code_generations_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    provider VARCHAR(50) NOT NULL,
    model VARCHAR(100) NOT NULL,
    generation_type VARCHAR(50),   -- 'initial' | 'debug' | 'refactor'
    prompt TEXT NOT NULL,
    generated_code TEXT,
    tokens_used INTEGER,
    response_time_ms INTEGER,
    cost_estimate NUMERIC(12,6),
    compilation_successful BOOLEAN,
    syntax_valid BOOLEAN,
    files_modified JSONB,      -- array de chemins de fichiers
    generated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_ai_code_gen_run ON ai_code_generations(task_run_id);
CREATE INDEX IF NOT EXISTS idx_ai_code_gen_provider ON ai_code_generations(provider, generated_at DESC);

COMMENT ON TABLE ai_code_generations IS 'Historique des générations de code par IA';

-- 2.3) COÛTS IA (tracking détaillé)
CREATE TABLE IF NOT EXISTS ai_cost_tracking (
    ai_cost_tracking_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    provider VARCHAR(50) NOT NULL,
    model VARCHAR(100) NOT NULL,
    operation_type VARCHAR(50),  -- 'code_generation', 'analysis', 'debugging'
    prompt_tokens INTEGER NOT NULL,
    completion_tokens INTEGER NOT NULL,
    total_tokens INTEGER NOT NULL,
    cost_usd NUMERIC(12,6) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_ai_cost_task ON ai_cost_tracking(task_id);
CREATE INDEX IF NOT EXISTS idx_ai_cost_run ON ai_cost_tracking(task_run_id);
CREATE INDEX IF NOT EXISTS idx_ai_cost_provider_date ON ai_cost_tracking(provider, created_at DESC);

COMMENT ON TABLE ai_cost_tracking IS 'Tracking des coûts d''utilisation des API IA';

-- ===============================================
-- 3. TABLES DE QUALITÉ ET TESTS
-- ===============================================

-- 3.1) RÉSULTATS DE TEST
CREATE TABLE IF NOT EXISTS test_results (
    test_results_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_run_id BIGINT NOT NULL REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    passed BOOLEAN NOT NULL,
    status VARCHAR(50) NOT NULL DEFAULT 'passed',  -- 'passed'/'failed'/'error'/'timeout'
    tests_total INTEGER DEFAULT 0,
    tests_passed INTEGER DEFAULT 0,
    tests_failed INTEGER DEFAULT 0,
    tests_skipped INTEGER DEFAULT 0,
    coverage_percentage NUMERIC(5,2),
    pytest_report JSONB,
    security_scan_report JSONB,
    executed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    duration_seconds INTEGER
);

CREATE INDEX IF NOT EXISTS idx_test_results_run ON test_results(task_run_id);
CREATE INDEX IF NOT EXISTS idx_test_results_status ON test_results(status, executed_at DESC);

COMMENT ON TABLE test_results IS 'Résultats des tests automatisés';

-- ===============================================
-- 4. TABLES GITHUB
-- ===============================================

-- 4.1) PULL REQUESTS GITHUB
CREATE TABLE IF NOT EXISTS pull_requests (
    pull_requests_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT NOT NULL REFERENCES tasks(tasks_id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE SET NULL,
    github_pr_number INTEGER,
    github_pr_url VARCHAR(500),
    pr_title VARCHAR(500),
    pr_description TEXT,
    pr_status VARCHAR(50),  -- 'open'|'merged'|'closed'
    mergeable BOOLEAN,
    conflicts BOOLEAN DEFAULT FALSE,
    reviews_required INTEGER DEFAULT 1,
    reviews_approved INTEGER DEFAULT 0,
    
    -- Timestamps
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    merged_at TIMESTAMPTZ,
    closed_at TIMESTAMPTZ,
    
    -- Git info
    head_sha CHAR(40),
    base_branch VARCHAR(100) DEFAULT 'main',
    feature_branch VARCHAR(100)
);

CREATE INDEX IF NOT EXISTS idx_pr_task ON pull_requests(task_id);
CREATE INDEX IF NOT EXISTS idx_pr_status ON pull_requests(pr_status);
CREATE INDEX IF NOT EXISTS idx_pr_number ON pull_requests(github_pr_number);
CREATE INDEX IF NOT EXISTS idx_pr_created ON pull_requests(created_at DESC);

COMMENT ON TABLE pull_requests IS 'Pull Requests créées par l''agent IA';

-- ===============================================
-- 5. TABLES DE VALIDATION HUMAINE
-- ===============================================

-- 5.1) DEMANDES DE VALIDATION HUMAINE
CREATE TABLE IF NOT EXISTS human_validations (
    human_validations_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    validation_id VARCHAR(100) UNIQUE NOT NULL, -- ID unique généré par l'application
    
    -- Références vers les entités existantes
    task_id BIGINT NOT NULL REFERENCES tasks(tasks_id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    run_step_id BIGINT REFERENCES run_steps(run_steps_id) ON DELETE CASCADE,
    
    -- Informations de la tâche (dénormalisées pour performance)
    task_title VARCHAR(500) NOT NULL,
    task_description TEXT,
    original_request TEXT NOT NULL,
    
    -- Statut de validation
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    
    -- Code généré à valider
    generated_code JSONB NOT NULL, -- {"filename": "content", ...}
    code_summary TEXT NOT NULL,
    files_modified TEXT[] NOT NULL, -- Array des fichiers modifiés
    implementation_notes TEXT,
    
    -- Résultats des tests (si disponibles)
    test_results JSONB,
    
    -- Informations de la Pull Request
    pr_info JSONB, -- {"number": 123, "url": "...", "title": "..."}
    
    -- Métadonnées de validation
    workflow_id VARCHAR(255),
    requested_by VARCHAR(100) DEFAULT 'ai_agent',
    
    -- Timestamps
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    expires_at TIMESTAMPTZ, -- Date d'expiration de la demande
    
    CONSTRAINT human_validations_status_chk CHECK (
        status IN ('pending', 'approved', 'rejected', 'expired', 'cancelled')
    )
);

-- Index pour les validations
CREATE INDEX IF NOT EXISTS idx_human_validations_validation_id ON human_validations(validation_id);
CREATE INDEX IF NOT EXISTS idx_human_validations_task_id ON human_validations(task_id);
CREATE INDEX IF NOT EXISTS idx_human_validations_status ON human_validations(status);
CREATE INDEX IF NOT EXISTS idx_human_validations_expires_at ON human_validations(expires_at) WHERE expires_at IS NOT NULL;
CREATE INDEX IF NOT EXISTS idx_human_validations_created_at ON human_validations(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_human_validations_updated_at ON human_validations(updated_at DESC);
CREATE INDEX IF NOT EXISTS idx_human_validations_status_expires ON human_validations(status, expires_at);

COMMENT ON TABLE human_validations IS 'Demandes de validation humaine pour les codes générés par l''IA';
COMMENT ON COLUMN human_validations.validation_id IS 'ID unique généré par l''application pour tracking';
COMMENT ON COLUMN human_validations.task_id IS 'FK vers tasks.tasks_id (ID DB, PAS Monday item ID)';
COMMENT ON COLUMN human_validations.generated_code IS 'Code généré au format JSON {"filename": "content"}';
COMMENT ON COLUMN human_validations.files_modified IS 'Array PostgreSQL des fichiers modifiés';
COMMENT ON COLUMN human_validations.expires_at IS 'Date limite pour la validation (24h par défaut)';

-- 5.2) RÉPONSES DE VALIDATION HUMAINE
CREATE TABLE IF NOT EXISTS human_validation_responses (
    human_validation_responses_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    
    -- Référence vers la demande de validation
    human_validation_id BIGINT NOT NULL REFERENCES human_validations(human_validations_id) ON DELETE CASCADE,
    validation_id VARCHAR(100) NOT NULL, -- Dénormalisé pour performance
    
    -- Statut de la réponse
    response_status VARCHAR(50) NOT NULL,
    
    -- Feedback humain
    comments TEXT,
    suggested_changes TEXT,
    approval_notes TEXT,
    
    -- Informations du validateur
    validated_by VARCHAR(100),
    validated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    -- Actions à prendre
    should_merge BOOLEAN NOT NULL DEFAULT FALSE,
    should_continue_workflow BOOLEAN NOT NULL DEFAULT TRUE,
    
    -- Métadonnées
    validation_duration_seconds INTEGER, -- Temps pris pour valider
    user_agent TEXT, -- Navigateur/interface utilisé
    ip_address INET, -- Adresse IP du validateur (optionnel)
    
    CONSTRAINT human_validation_responses_status_chk CHECK (
        response_status IN ('approved', 'rejected', 'expired', 'cancelled')
    )
);

-- Index pour les réponses
CREATE INDEX IF NOT EXISTS idx_human_validation_responses_validation_id ON human_validation_responses(validation_id);
CREATE INDEX IF NOT EXISTS idx_human_validation_responses_status ON human_validation_responses(response_status);
CREATE INDEX IF NOT EXISTS idx_human_validation_responses_validated_at ON human_validation_responses(validated_at DESC);
CREATE INDEX IF NOT EXISTS idx_human_validation_responses_validated_by ON human_validation_responses(validated_by);

COMMENT ON TABLE human_validation_responses IS 'Réponses des validateurs humains (approbation/rejet)';

-- 5.3) ACTIONS POST-VALIDATION (MERGE, ETC.)
CREATE TABLE IF NOT EXISTS validation_actions (
    validation_actions_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    
    -- Référence vers la validation
    human_validation_id BIGINT NOT NULL REFERENCES human_validations(human_validations_id) ON DELETE CASCADE,
    validation_id VARCHAR(100) NOT NULL,
    
    -- Type d'action
    action_type VARCHAR(50) NOT NULL, -- 'merge_pr', 'reject_pr', 'update_monday', etc.
    action_status VARCHAR(50) NOT NULL DEFAULT 'pending',
    
    -- Détails de l'action
    action_data JSONB, -- Données spécifiques à l'action
    result_data JSONB, -- Résultat de l'action
    
    -- Informations de merge (si applicable)
    merge_commit_hash VARCHAR(100),
    merge_commit_url VARCHAR(500),
    
    -- Timestamps
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    
    -- Erreurs
    error_message TEXT,
    retry_count INTEGER NOT NULL DEFAULT 0,
    
    CONSTRAINT validation_actions_type_chk CHECK (
        action_type IN ('merge_pr', 'reject_pr', 'update_monday', 'cleanup_branch', 'notify_user')
    ),
    CONSTRAINT validation_actions_status_chk CHECK (
        action_status IN ('pending', 'in_progress', 'completed', 'failed', 'cancelled')
    )
);

-- Index pour les actions
CREATE INDEX IF NOT EXISTS idx_validation_actions_validation_id ON validation_actions(validation_id);
CREATE INDEX IF NOT EXISTS idx_validation_actions_type_status ON validation_actions(action_type, action_status);
CREATE INDEX IF NOT EXISTS idx_validation_actions_created_at ON validation_actions(created_at DESC);

COMMENT ON TABLE validation_actions IS 'Actions effectuées suite à la validation (merge, etc.)';

-- ===============================================
-- 6. TABLES D'ÉVÉNEMENTS ET LOGS
-- ===============================================

-- 6.1) WEBHOOKS (partitionné par temps)
CREATE TABLE webhook_events (
    webhook_events_id BIGINT GENERATED BY DEFAULT AS IDENTITY,
    source VARCHAR(50) NOT NULL,
    event_type VARCHAR(100),
    payload JSONB NOT NULL,
    headers JSONB,
    signature TEXT,
    processed BOOLEAN NOT NULL DEFAULT FALSE,
    processing_status VARCHAR(50) NOT NULL DEFAULT 'pending',
    error_message TEXT,
    related_task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE SET NULL,
    received_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    processed_at TIMESTAMPTZ,
    PRIMARY KEY (webhook_events_id, received_at)
) PARTITION BY RANGE (received_at);

-- Partitions mensuelles
CREATE TABLE IF NOT EXISTS webhook_events_2025_09
    PARTITION OF webhook_events
    FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

CREATE TABLE IF NOT EXISTS webhook_events_2025_10
    PARTITION OF webhook_events
    FOR VALUES FROM ('2025-10-01') TO ('2025-11-01');

-- Index sur les partitions
CREATE INDEX IF NOT EXISTS idx_webhook_events_processed_2025_09 ON webhook_events_2025_09(processed, received_at);
CREATE INDEX IF NOT EXISTS idx_webhook_events_source_2025_09 ON webhook_events_2025_09(source, event_type);
CREATE INDEX IF NOT EXISTS idx_webhook_events_processed_2025_10 ON webhook_events_2025_10(processed, received_at);
CREATE INDEX IF NOT EXISTS idx_webhook_events_source_2025_10 ON webhook_events_2025_10(source, event_type);

COMMENT ON TABLE webhook_events IS 'Événements webhook reçus (Monday.com, GitHub, etc.)';

-- 6.2) LOGS APPLICATION / AUDIT
CREATE TABLE IF NOT EXISTS application_logs (
    application_logs_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE SET NULL,
    task_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE SET NULL,
    run_step_id BIGINT REFERENCES run_steps(run_steps_id) ON DELETE SET NULL,
    level VARCHAR(20) NOT NULL,      -- 'DEBUG'|'INFO'|'WARNING'|'ERROR'|'CRITICAL'
    source_component VARCHAR(100),   -- 'api_gateway'|'celery_worker'|...
    action VARCHAR(100),
    message TEXT NOT NULL,
    metadata JSONB,
    user_id BIGINT,
    ip_address INET,
    ts TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT application_logs_level_chk CHECK (
        level IN ('DEBUG','INFO','WARNING','ERROR','CRITICAL')
    )
);

CREATE INDEX IF NOT EXISTS idx_application_logs_level ON application_logs(level, ts DESC);
CREATE INDEX IF NOT EXISTS idx_application_logs_task ON application_logs(task_id, ts DESC);
CREATE INDEX IF NOT EXISTS idx_application_logs_component ON application_logs(source_component, ts DESC);

COMMENT ON TABLE application_logs IS 'Logs structurés de l''application pour audit et debug';

-- ===============================================
-- 7. TABLES DE MÉTRIQUES ET CONFIGURATION
-- ===============================================

-- 7.1) MÉTRIQUES DE PERFORMANCE (agrégées par run/tâche)
CREATE TABLE IF NOT EXISTS performance_metrics (
    performance_metrics_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    task_id BIGINT REFERENCES tasks(tasks_id) ON DELETE CASCADE,
    task_run_id BIGINT REFERENCES task_runs(tasks_runs_id) ON DELETE CASCADE,
    total_duration_seconds INTEGER,
    queue_wait_time_seconds INTEGER,
    ai_processing_time_seconds INTEGER,
    testing_time_seconds INTEGER,
    total_ai_calls INTEGER DEFAULT 0,
    total_tokens_used INTEGER DEFAULT 0,
    total_ai_cost NUMERIC(12,6) DEFAULT 0.0,
    code_lines_generated INTEGER DEFAULT 0,
    test_coverage_final NUMERIC(5,2),
    security_issues_found INTEGER DEFAULT 0,
    retry_attempts INTEGER DEFAULT 0,
    success_rate NUMERIC(5,2),
    recorded_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_perf_task_run ON performance_metrics(task_id, task_run_id);
CREATE INDEX IF NOT EXISTS idx_perf_recorded ON performance_metrics(recorded_at DESC);

COMMENT ON TABLE performance_metrics IS 'Métriques de performance agrégées par workflow';

-- 7.2) CONFIGURATION SYSTÈME (clés/valeurs versionnées)
CREATE TABLE IF NOT EXISTS system_config (
    system_config_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    key VARCHAR(100) UNIQUE NOT NULL,
    value JSONB NOT NULL,
    description TEXT,
    config_type VARCHAR(50) NOT NULL DEFAULT 'application',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_by VARCHAR(100)
);

CREATE INDEX IF NOT EXISTS idx_system_config_type ON system_config(config_type);

COMMENT ON TABLE system_config IS 'Configuration système versionnée';

-- ===============================================
-- 8. FONCTIONS ET TRIGGERS
-- ===============================================

-- 8.1) Fonction générique pour mettre à jour updated_at
CREATE OR REPLACE FUNCTION trg_touch_updated_at() RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 8.2) Triggers pour updated_at
DO $$ BEGIN
    IF NOT EXISTS (
        SELECT 1 FROM pg_trigger WHERE tgname = 'touch_tasks_updated_at'
    ) THEN
        CREATE TRIGGER touch_tasks_updated_at
        BEFORE UPDATE ON tasks
        FOR EACH ROW EXECUTE FUNCTION trg_touch_updated_at();
    END IF;
END $$;

DO $$ BEGIN
    IF NOT EXISTS (
        SELECT 1 FROM pg_trigger WHERE tgname = 'touch_system_config_updated_at'
    ) THEN
        CREATE TRIGGER touch_system_config_updated_at
        BEFORE UPDATE ON system_config
        FOR EACH ROW EXECUTE FUNCTION trg_touch_updated_at();
    END IF;
END $$;

-- 8.3) Fonction pour marquer les validations expirées
CREATE OR REPLACE FUNCTION mark_expired_validations() RETURNS INTEGER AS $$
DECLARE
    expired_count INTEGER;
BEGIN
    UPDATE human_validations 
    SET status = 'expired', 
        updated_at = NOW()
    WHERE status = 'pending' 
      AND expires_at IS NOT NULL 
      AND expires_at < NOW();
    
    GET DIAGNOSTICS expired_count = ROW_COUNT;
    
    -- Log l'opération
    IF expired_count > 0 THEN
        INSERT INTO application_logs (level, source_component, message, metadata)
        VALUES ('INFO', 'human_validation', 'Marked expired validations', 
                jsonb_build_object('expired_count', expired_count));
    END IF;
    
    RETURN expired_count;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION mark_expired_validations() IS 'Marque automatiquement les validations expirées';

-- 8.4) Fonction trigger pour synchroniser le statut de validation
CREATE OR REPLACE FUNCTION sync_validation_status() RETURNS TRIGGER AS $$
BEGIN
    -- Quand une réponse est créée, mettre à jour le statut de la validation
    UPDATE human_validations 
    SET status = NEW.response_status,
        updated_at = NOW()
    WHERE human_validations_id = NEW.human_validation_id;
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Créer le trigger
DO $$ BEGIN
    IF NOT EXISTS (
        SELECT 1 FROM pg_trigger WHERE tgname = 'sync_validation_status_trigger'
    ) THEN
        CREATE TRIGGER sync_validation_status_trigger
        AFTER INSERT ON human_validation_responses
        FOR EACH ROW EXECUTE FUNCTION sync_validation_status();
    END IF;
END $$;

COMMENT ON FUNCTION sync_validation_status() IS 'Synchronise automatiquement le statut de validation avec les réponses';

-- 8.5) Fonction pour calculer les statistiques de validation
CREATE OR REPLACE FUNCTION get_validation_stats() RETURNS TABLE (
    total_validations BIGINT,
    pending_validations BIGINT,
    approved_validations BIGINT,
    rejected_validations BIGINT,
    expired_validations BIGINT,
    avg_validation_time_minutes NUMERIC,
    urgent_validations BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        COUNT(*) as total_validations,
        COUNT(*) FILTER (WHERE status = 'pending') as pending_validations,
        COUNT(*) FILTER (WHERE status = 'approved') as approved_validations,
        COUNT(*) FILTER (WHERE status = 'rejected') as rejected_validations,
        COUNT(*) FILTER (WHERE status = 'expired') as expired_validations,
        ROUND(AVG(
            CASE 
                WHEN hvr.validated_at IS NOT NULL AND hv.created_at IS NOT NULL
                THEN EXTRACT(EPOCH FROM (hvr.validated_at - hv.created_at)) / 60.0
                ELSE NULL
            END
        ), 2) as avg_validation_time_minutes,
        COUNT(*) FILTER (
            WHERE status = 'pending' 
              AND expires_at IS NOT NULL 
              AND expires_at < NOW() + INTERVAL '1 hour'
        ) as urgent_validations
    FROM human_validations hv
    LEFT JOIN human_validation_responses hvr ON hv.human_validations_id = hvr.human_validation_id
    WHERE hv.created_at >= NOW() - INTERVAL '30 days'; -- Stats des 30 derniers jours
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION get_validation_stats() IS 'Retourne les statistiques de validation pour le dashboard';

-- 8.6) Fonction de nettoyage (logs, webhooks, validations anciennes)
CREATE OR REPLACE FUNCTION cleanup_old_data() RETURNS void AS $$
BEGIN
    -- Nettoyage des webhooks anciens (6 mois)
    DELETE FROM webhook_events WHERE received_at < NOW() - INTERVAL '6 months';
    
    -- Nettoyage des logs anciens (3 mois)
    DELETE FROM application_logs WHERE ts < NOW() - INTERVAL '3 months';
    
    -- Nettoyage des anciennes validations (3 mois)
    DELETE FROM human_validations WHERE created_at < NOW() - INTERVAL '3 months';
    DELETE FROM validation_actions WHERE created_at < NOW() - INTERVAL '3 months';
    
    -- Marquer les validations expirées
    PERFORM mark_expired_validations();
    
    -- Log le nettoyage
    INSERT INTO application_logs (level, source_component, message)
    VALUES ('INFO', 'maintenance', 'Cleanup job executed successfully');
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION cleanup_old_data() IS 'Nettoie les données anciennes (logs, webhooks, validations)';

-- ===============================================
-- 9. VUES POUR L'ADMINISTRATION ET MONITORING
-- ===============================================

-- 9.1) Vue pour le dashboard des validations
CREATE OR REPLACE VIEW validation_dashboard AS
SELECT 
    hv.human_validations_id,
    hv.validation_id,
    hv.task_title,
    hv.status,
    hv.created_at,
    hv.expires_at,
    CASE 
        WHEN hv.expires_at IS NOT NULL AND hv.expires_at < NOW() + INTERVAL '1 hour' 
        THEN TRUE 
        ELSE FALSE 
    END as is_urgent,
    CASE 
        WHEN hv.test_results IS NOT NULL AND (hv.test_results->>'success')::boolean = FALSE
        THEN TRUE
        ELSE FALSE
    END as has_test_failures,
    array_length(hv.files_modified, 1) as files_count,
    hv.pr_info->>'url' as pr_url,
    t.priority,
    t.repository_url,
    hvr.validated_by,
    hvr.validated_at,
    hvr.comments as validation_comments
FROM human_validations hv
JOIN tasks t ON hv.task_id = t.tasks_id
LEFT JOIN human_validation_responses hvr ON hv.human_validations_id = hvr.human_validation_id
ORDER BY 
    CASE WHEN hv.status = 'pending' THEN 0 ELSE 1 END,
    CASE 
        WHEN hv.expires_at IS NOT NULL AND hv.expires_at < NOW() + INTERVAL '1 hour' 
        THEN 0 
        ELSE 1 
    END,
    hv.created_at DESC;

COMMENT ON VIEW validation_dashboard IS 'Vue optimisée pour l''interface d''administration des validations';

-- 9.2) Vue pour l'historique des validations
CREATE OR REPLACE VIEW validation_history AS
SELECT 
    hv.validation_id,
    hv.task_title,
    hv.status,
    hv.created_at,
    hv.expires_at,
    hvr.response_status,
    hvr.validated_by,
    hvr.validated_at,
    hvr.validation_duration_seconds,
    va.action_type,
    va.action_status,
    va.merge_commit_hash,
    t.repository_url,
    t.priority
FROM human_validations hv
JOIN tasks t ON hv.task_id = t.tasks_id
LEFT JOIN human_validation_responses hvr ON hv.human_validations_id = hvr.human_validation_id
LEFT JOIN validation_actions va ON hv.human_validations_id = va.human_validation_id
WHERE hv.status != 'pending'
ORDER BY hv.created_at DESC;

COMMENT ON VIEW validation_history IS 'Historique complet des validations avec actions associées';

-- 9.3) Vue pour les métriques de workflow
CREATE OR REPLACE VIEW workflow_metrics_summary AS
SELECT 
    t.tasks_id,
    t.title,
    t.repository_url,
    t.internal_status,
    COUNT(DISTINCT tr.tasks_runs_id) as total_runs,
    COUNT(DISTINCT tr.tasks_runs_id) FILTER (WHERE tr.status = 'completed') as successful_runs,
    COUNT(DISTINCT tr.tasks_runs_id) FILTER (WHERE tr.status = 'failed') as failed_runs,
    AVG(pm.total_duration_seconds) as avg_duration_seconds,
    AVG(pm.total_ai_cost) as avg_cost_usd,
    MAX(tr.completed_at) as last_run_at
FROM tasks t
LEFT JOIN task_runs tr ON t.tasks_id = tr.task_id
LEFT JOIN performance_metrics pm ON tr.tasks_runs_id = pm.task_run_id
GROUP BY t.tasks_id, t.title, t.repository_url, t.internal_status
ORDER BY last_run_at DESC NULLS LAST;

COMMENT ON VIEW workflow_metrics_summary IS 'Résumé des métriques par tâche';

-- ===============================================
-- 10. SÉCURITÉ ET PERMISSIONS
-- ===============================================

-- Créer un rôle pour l'application
DO $$ BEGIN
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'ai_agent_app') THEN
        CREATE ROLE ai_agent_app WITH LOGIN PASSWORD 'CHANGE_ME_IN_PRODUCTION';
    END IF;
END $$;

-- Donner les permissions nécessaires
GRANT CONNECT ON DATABASE ai_agent_admin TO ai_agent_app;
GRANT USAGE ON SCHEMA public TO ai_agent_app;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO ai_agent_app;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO ai_agent_app;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA public TO ai_agent_app;

-- Permissions pour les partitions futures
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO ai_agent_app;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO ai_agent_app;

-- ===============================================
-- 11. INFORMATIONS ET DOCUMENTATION
-- ===============================================

-- Résumé des tables
COMMENT ON DATABASE ai_agent_admin IS 'Base de données AI-Agent - Workflow automation avec IA';

-- Informations de version
INSERT INTO system_config (key, value, description, config_type) 
VALUES 
    ('schema_version', '"2.0"', 'Version du schéma de base de données', 'system'),
    ('schema_date', '"2025-10-06"', 'Date de la dernière mise à jour du schéma', 'system'),
    ('schema_description', '"Schéma complet AI-Agent avec validation humaine"', 'Description du schéma', 'system')
ON CONFLICT (key) DO UPDATE SET 
    value = EXCLUDED.value,
    updated_at = NOW();

-- ===============================================
-- FIN DU SCHÉMA
-- ===============================================

-- Afficher un résumé
DO $$ 
BEGIN
    RAISE NOTICE '========================================';
    RAISE NOTICE 'Schéma AI-Agent v2.0 installé avec succès';
    RAISE NOTICE '========================================';
    RAISE NOTICE 'Tables principales: 17';
    RAISE NOTICE 'Vues: 3';
    RAISE NOTICE 'Fonctions: 5';
    RAISE NOTICE 'Triggers: 3';
    RAISE NOTICE '========================================';
    RAISE NOTICE 'Prochaines étapes:';
    RAISE NOTICE '1. Modifier le mot de passe du rôle ai_agent_app';
    RAISE NOTICE '2. Créer les partitions futures pour webhook_events';
    RAISE NOTICE '3. Configurer le job de nettoyage (cleanup_old_data)';
    RAISE NOTICE '4. Vérifier les permissions et la sécurité';
    RAISE NOTICE '========================================';
END $$;

