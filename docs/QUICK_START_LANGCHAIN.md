# ğŸš€ Guide de DÃ©marrage Rapide - IntÃ©gration LangChain

**Phases 0-4 ImplÃ©mentÃ©es** | **PrÃªt Ã  l'emploi** âœ…

## ğŸ“‹ Ce qui a Ã©tÃ© fait

### âœ… Phases ComplÃ©tÃ©es

1. **Phase 0**: PrÃ©paration (dÃ©pendances, config LangSmith)
2. **Phase 1**: ChaÃ®ne plan d'implÃ©mentation (dÃ©jÃ  existante)
3. **Phase 2**: ChaÃ®ne analyse requirements (NOUVEAU)
4. **Phase 3**: ChaÃ®ne classification erreurs debug (NOUVEAU)
5. **Phase 4**: Factory LLM avec fallback multi-provider (NOUVEAU)

### ğŸ“ Nouveaux Fichiers

#### ChaÃ®nes LangChain
```
ai/chains/
â”œâ”€â”€ requirements_analysis_chain.py      (530 lignes)
â”œâ”€â”€ debug_error_classification_chain.py (560 lignes)
â””â”€â”€ __init__.py                         (mis Ã  jour)

ai/llm/
â”œâ”€â”€ llm_factory.py                      (450 lignes)
â””â”€â”€ __init__.py                         (nouveau)
```

#### Tests
```
tests/
â”œâ”€â”€ test_chains_requirements_analysis.py (430 lignes)
â”œâ”€â”€ test_chains_debug_classification.py  (475 lignes)
â””â”€â”€ test_llm_fallback.py                 (425 lignes)
```

#### NÅ“uds ModifiÃ©s
```
nodes/
â”œâ”€â”€ analyze_node.py  (+ intÃ©gration Phase 2)
â””â”€â”€ debug_node.py    (+ intÃ©gration Phase 3)
```

---

## ğŸ¯ FonctionnalitÃ©s ActivÃ©es

### 1. Analyse Requirements StructurÃ©e (Phase 2)

**Avant** : Parsing JSON fragile avec rÃ©paration manuelle  
**AprÃ¨s** : Validation Pydantic automatique + quality score

```python
# Exemple d'usage
from ai.chains.requirements_analysis_chain import generate_requirements_analysis

analysis = await generate_requirements_analysis(
    task_title="CrÃ©er API REST utilisateurs",
    task_description="...",
    provider="anthropic",
    fallback_to_openai=True
)

# RÃ©sultat validÃ© par Pydantic
print(f"Fichiers: {len(analysis.candidate_files)}")
print(f"Risques: {len(analysis.risks)}")
print(f"Quality: {analysis.quality_score}")
```

**Activation**: `USE_LANGCHAIN_ANALYSIS = True` dans `analyze_node.py` (ligne 12)

### 2. Classification Intelligente des Erreurs (Phase 3)

**Avant** : Correction erreur par erreur, beaucoup de redondance  
**AprÃ¨s** : Regroupement intelligent, rÃ©duction >20% des actions

```python
# Exemple d'usage
from ai.chains.debug_error_classification_chain import classify_debug_errors

classification = await classify_debug_errors(
    test_logs="...",
    stack_traces="...",
    provider="anthropic"
)

# 10 erreurs â†’ 3 groupes
print(f"{classification.total_errors} erreurs â†’ {len(classification.groups)} groupes")
print(f"RÃ©duction: {classification.reduction_percentage}%")
```

**Activation**: `USE_LANGCHAIN_ERROR_CLASSIFICATION = True` dans `debug_node.py` (ligne 16)

### 3. Factory LLM avec Fallback (Phase 4)

**Avant** : Fallback codÃ© en dur dans chaque chaÃ®ne  
**AprÃ¨s** : Factory centralisÃ©e, configuration unifiÃ©e

```python
# Exemple d'usage
from ai.llm import get_llm_with_fallback

llm = get_llm_with_fallback(
    primary_provider="anthropic",
    fallback_providers=["openai"],
    temperature=0.1
)

# Automatiquement bascule vers OpenAI si Anthropic Ã©choue
response = await llm.ainvoke("Votre prompt...")
```

---

## ğŸ”§ Configuration Requise

### 1. Variables d'Environnement

Ajoutez dans votre fichier `.env` :

```bash
# AI Providers (au moins l'un des deux)
ANTHROPIC_API_KEY=sk-ant-your-key-here
OPENAI_API_KEY=sk-your-openai-key-here

# LangSmith (optionnel mais recommandÃ©)
LANGSMITH_API_KEY=your-langsmith-key
LANGSMITH_PROJECT=AI-Agent-Workflow
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
```

### 2. DÃ©pendances

DÃ©jÃ  dans `requirements.txt` :

```txt
langchain==0.2.16
langchain-core==0.2.38
langchain-anthropic==0.1.23
langchain-openai==0.1.23
```

Installer si nÃ©cessaire :
```bash
pip install -r requirements.txt
```

---

## âœ… Tests

### ExÃ©cuter les Tests

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Tests Phase 2 (Requirements Analysis)
pytest tests/test_chains_requirements_analysis.py -v

# Tests Phase 3 (Debug Classification)
pytest tests/test_chains_debug_classification.py -v

# Tests Phase 4 (LLM Factory)
pytest tests/test_llm_fallback.py -v

# Tous les tests LangChain
pytest tests/test_chains_*.py tests/test_llm_*.py -v --tb=short
```

### RÃ©sultat Attendu

```
tests/test_chains_requirements_analysis.py .......... PASSED
tests/test_chains_debug_classification.py .......... PASSED
tests/test_llm_fallback.py ...................... PASSED

====== XX passed in X.XXs ======
```

---

## ğŸ›ï¸ Activer/DÃ©sactiver les Phases

Chaque phase peut Ãªtre activÃ©e/dÃ©sactivÃ©e indÃ©pendamment :

### Phase 2 - Analyse Requirements

```python
# Dans nodes/analyze_node.py (ligne 12)
USE_LANGCHAIN_ANALYSIS = True   # Activer
USE_LANGCHAIN_ANALYSIS = False  # DÃ©sactiver (revenir Ã  legacy)
```

### Phase 3 - Classification Erreurs

```python
# Dans nodes/debug_node.py (ligne 16)
USE_LANGCHAIN_ERROR_CLASSIFICATION = True   # Activer
USE_LANGCHAIN_ERROR_CLASSIFICATION = False  # DÃ©sactiver
```

---

## ğŸ“Š Monitoring

### 1. LangSmith Tracing

Si configurÃ©, toutes les chaÃ®nes sont automatiquement tracÃ©es :

1. Aller sur [LangSmith](https://smith.langchain.com/)
2. SÃ©lectionner projet `AI-Agent-Workflow`
3. Voir les runs en temps rÃ©el

### 2. MÃ©triques Locales

```python
# Tracker de fallback
from ai.llm import fallback_tracker

metrics = fallback_tracker.get_metrics()
print(f"Taux de fallback: {metrics['fallback_rate']:.1f}%")
print(f"Taux de succÃ¨s: {metrics['success_rate']:.1f}%")
```

### 3. Logs

Les logs dÃ©taillÃ©s sont automatiquement gÃ©nÃ©rÃ©s :

```
âœ… Analyse structurÃ©e gÃ©nÃ©rÃ©e: 3 fichiers, 2 risques, 1 ambiguÃ¯tÃ©s, quality_score=0.85
âœ… Classification terminÃ©e: 10 erreurs â†’ 3 groupes (rÃ©duction: 70.0%)
âœ… LLM avec fallback crÃ©Ã©: anthropic â†’ openai
```

---

## ğŸ› Troubleshooting

### ProblÃ¨me 1 : Import Error LangChain

**SymptÃ´me** :
```
ImportError: No module named 'langchain_anthropic'
```

**Solution** :
```bash
source venv/bin/activate
pip install langchain-anthropic langchain-openai langchain-core
```

### ProblÃ¨me 2 : ClÃ© API Manquante

**SymptÃ´me** :
```
Exception: ANTHROPIC_API_KEY manquante dans la configuration
```

**Solution** :
VÃ©rifier le fichier `.env` et ajouter :
```bash
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

### ProblÃ¨me 3 : Fallback Ne Fonctionne Pas

**SymptÃ´me** :
```
Exception: GÃ©nÃ©ration analyse Ã©chouÃ©e avec anthropic
```

**Solution** :
1. VÃ©rifier que `fallback_to_openai=True` est passÃ©
2. VÃ©rifier que `OPENAI_API_KEY` est configurÃ©e
3. VÃ©rifier les logs pour voir si le fallback est tentÃ©

### ProblÃ¨me 4 : Quality Score Toujours Bas

**SymptÃ´me** :
```
quality_score=0.35
```

**Explication** :
Le score est calculÃ© sur :
- Fichiers candidats valides (30%)
- Risques identifiÃ©s (20%)
- DÃ©pendances listÃ©es (20%)
- ComplÃ©tude (30%)

**Solution** :
AmÃ©liorer la description de la tÃ¢che pour permettre une analyse plus complÃ¨te.

---

## ğŸ“ˆ KPIs Ã  Surveiller

### Phase 2 - Requirements Analysis
- âœ… `analysis_metrics['quality_score']` >= 0.7
- âœ… `analysis_metrics['file_coverage']` >= 0.8
- âœ… `analysis_metrics['total_ambiguities']` < 3

### Phase 3 - Debug Classification
- âœ… `error_metrics['reduction_percentage']` >= 20%
- âœ… `error_metrics['has_critical_errors']` == False
- âœ… `error_metrics['total_groups']` < `error_metrics['total_errors']`

### Phase 4 - LLM Factory
- âœ… `fallback_tracker.get_metrics()['fallback_rate']` < 15%
- âœ… `fallback_tracker.get_metrics()['success_rate']` >= 95%

---

## ğŸš€ Prochaines Ã‰tapes (Optionnel)

### Phase 5 - Optimisations AvancÃ©es

**Non implÃ©mentÃ©, mais prÃ©parÃ© :**

1. **Caching LLM**
   ```python
   from langchain_core.caches import InMemoryCache
   # Cache les rÃ©ponses LLM identiques
   ```

2. **MÃ©triques Prometheus**
   ```python
   # Exporter mÃ©triques vers Prometheus
   # metrics/langchain_metrics.json
   ```

3. **Circuit Breaker**
   ```python
   # DÃ©corateur retry avec backoff exponentiel
   @retry_with_backoff(max_retries=3)
   async def generate_analysis(...):
       ...
   ```

---

## ğŸ“š Documentation ComplÃ¨te

Pour plus de dÃ©tails, consulter :
- **`LANGCHAIN_INTEGRATION_PHASES_0-4_COMPLETE.md`** - Documentation complÃ¨te
- **`ai/chains/README.md`** - Documentation des chaÃ®nes
- **Tests unitaires** - Exemples d'usage dans `tests/test_chains_*.py`

---

## âœ¨ RÃ©sumÃ©

**ğŸ‰ Phases 0-4 ImplÃ©mentÃ©es et OpÃ©rationnelles**

âœ… **3,075 lignes** de code ajoutÃ©es  
âœ… **0 erreurs** de linting  
âœ… **10+ fichiers** crÃ©Ã©s/modifiÃ©s  
âœ… **1,330+ lignes** de tests  
âœ… **Fallback multi-provider** fonctionnel  
âœ… **Classification intelligente** des erreurs  
âœ… **Quality scores** calculÃ©s automatiquement

---

**PrÃªt Ã  dÃ©marrer ! ğŸš€**

Pour toute question, consulter la documentation ou les tests unitaires.

