"""Service de r√©ception et traitement des webhooks Monday.com."""

import hashlib
import hmac
import json
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio
import time

from models.schemas import TaskRequest, WebhookPayload
from tools.monday_tool import MondayTool
# from graph.workflow_graph import run_workflow  # ‚úÖ Retir√© - on utilise Celery maintenant
from utils.logger import get_logger
from config.settings import get_settings
from admin.backend.database import get_db_connection
from utils.github_parser import enrich_task_with_description_info

logger = get_logger(__name__)

class WebhookService:
    """Service de gestion des webhooks Monday.com."""

    def __init__(self):
        self.settings = get_settings()
        self.monday_tool = MondayTool()

        # ‚úÖ NOUVEAU: Cache pour d√©duplication des webhooks
        self._webhook_cache = {}
        self._cache_expiry = 300  # 5 minutes
        self._processing_locks = {}  # Verrous pour √©viter le traitement parall√®le

    async def process_webhook(self, payload: Dict[str, Any], signature: Optional[str] = None) -> Dict[str, Any]:
        """
        Traite un webhook Monday.com avec d√©duplication renforc√©e.
        """
        try:
            # ‚úÖ NOUVEAU: Cr√©er une signature unique du webhook
            webhook_signature = self._create_webhook_signature(payload)

            # ‚úÖ NOUVEAU: V√©rifier si ce webhook est d√©j√† en cours de traitement
            current_time = time.time()

            # Nettoyer le cache expir√©
            self._cleanup_webhook_cache(current_time)

            # V√©rifier si ce webhook a d√©j√† √©t√© trait√© r√©cemment
            if webhook_signature in self._webhook_cache:
                cached_data = self._webhook_cache[webhook_signature]
                logger.warning(f"üö´ Webhook d√©j√† trait√© il y a {current_time - cached_data['timestamp']:.1f}s")
                logger.warning(f"   Signature: {webhook_signature}")
                logger.warning(f"   Task ID: {cached_data.get('task_id', 'unknown')}")
                return {
                    "success": True,
                    "task_id": cached_data.get('task_id'),
                    "task_exists": True,
                    "message": "Webhook d√©j√† trait√© (d√©duplication)",
                    "deduplicated": True
                }

            # ‚úÖ NOUVEAU: Acqu√©rir un verrou pour ce webhook
            if webhook_signature in self._processing_locks:
                logger.warning("üîí Webhook en cours de traitement - attente...")
                # Attendre maximum 30 secondes
                for _ in range(30):
                    await asyncio.sleep(1)
                    if webhook_signature not in self._processing_locks:
                        break
                else:
                    logger.error("‚ùå Timeout - webhook toujours en cours de traitement")
                    return {
                        "success": False,
                        "error": "Webhook timeout - traitement parall√®le d√©tect√©"
                    }

            # Marquer comme en cours de traitement
            self._processing_locks[webhook_signature] = current_time

            try:
                # Marquer dans le cache imm√©diatement
                self._webhook_cache[webhook_signature] = {
                    "timestamp": current_time,
                    "status": "processing"
                }

                logger.info("üì® R√©ception d'un webhook Monday.com")

                # 1. Sauvegarder le webhook en base
                webhook_id = await self._save_webhook_event(payload, signature)

                # 2. Valider la signature si fournie
                if signature and not self._validate_signature(payload, signature):
                    logger.warning("‚ùå Signature webhook invalide")
                    await self._update_webhook_status(webhook_id, 'failed', 'Signature invalide')
                    return {
                        "success": False,
                        "error": "Signature webhook invalide",
                        "status_code": 401
                    }

                # 3. Parser le payload
                webhook_data = WebhookPayload(**payload)

                # 4. V√©rifier si c'est un challenge de validation
                if webhook_data.challenge:
                    logger.info("‚úÖ Challenge webhook re√ßu")
                    await self._update_webhook_status(webhook_id, 'processed')
                    return {
                        "success": True,
                        "challenge": webhook_data.challenge,
                        "status_code": 200
                    }

                # 5. Traiter l'√©v√©nement
                if not webhook_data.event:
                    logger.warning("‚ö†Ô∏è Webhook sans √©v√©nement")
                    await self._update_webhook_status(webhook_id, 'ignored', 'Aucun √©v√©nement')
                    return {
                        "success": False,
                        "error": "Aucun √©v√©nement dans le webhook",
                        "status_code": 400
                    }

                # 6. V√©rifier les webhooks en doublon (protection contre les multiples envois Monday.com)
                duplicate_check = await self._check_duplicate_webhook(payload)
                if duplicate_check:
                    logger.warning("‚ö†Ô∏è Webhook en doublon d√©tect√©:")
                    logger.warning(f"   Webhook similaire trait√©: {duplicate_check['webhook_events_id']} √† {duplicate_check['processed_at']}")
                    logger.warning("   üõë Webhook ignor√© pour √©viter la duplication")
                    await self._update_webhook_status(webhook_id, 'processed', 'Doublon ignor√©')
                    return {
                        "success": True,
                        "message": "Webhook doublon ignor√©",
                        "status_code": 200
                    }

                # 7. Extraire les informations de la t√¢che
                task_info = self.monday_tool.parse_monday_webhook(payload)

                if not task_info:
                    logger.info("‚ÑπÔ∏è Webhook ignor√© - pas pertinent pour notre workflow")
                    await self._update_webhook_status(webhook_id, 'ignored', 'Pas pertinent')
                    return {
                        "success": True,
                        "message": "Webhook ignor√©",
                        "status_code": 200
                    }

                # 7. Cr√©er une requ√™te de t√¢che
                task_request = await self._create_task_request(task_info)

                if not task_request:
                    logger.warning("‚ùå Impossible de cr√©er la requ√™te de t√¢che")
                    await self._update_webhook_status(webhook_id, 'failed', 'Impossible de cr√©er la requ√™te')
                    return {
                        "success": False,
                        "error": "Impossible de cr√©er la requ√™te de t√¢che",
                        "status_code": 400
                    }

                # 8. Sauvegarder la t√¢che en base (seulement si elle n'existe pas)
                task_id = await self._save_task(task_request)

                # ‚úÖ CORRECTION: Ne plus cr√©er le run ici - il sera cr√©√© par le workflow lui-m√™me
                # √âvite la duplication et les conflits de statut
                # run_id = await self._save_task_run(task_id, task_request)

                # Note : Le statut de la t√¢che sera mis √† jour par le workflow via les triggers

                # 10. Mettre √† jour le webhook avec la t√¢che li√©e
                await self._update_webhook_status(webhook_id, 'processed', related_task_id=task_id)

                # 11. ‚úÖ T√¢che cr√©√©e et pr√™te - le workflow sera lanc√© par celery_app
                logger.info(f"üìã T√¢che cr√©√©e et pr√™te pour workflow: {task_request.title} (ID: {task_id})")

                # Retourner le succ√®s - le workflow sera g√©r√© par celery_app.process_monday_webhook
                return {
                    "success": True,
                    "message": "T√¢che cr√©√©e avec succ√®s - workflow g√©r√© par Celery",
                    "task_id": task_id,  # ‚úÖ Retourner le tasks_id de la BD
                    "status": "created",
                    "status_code": 201  # Created
                }

                # ANCIEN CODE SUPPRIM√â pour √©viter le double lancement :
                # - celery_app.send_task("ai_agent_background.execute_workflow")
                # Ce workflow est maintenant g√©r√© directement par main.py

            except Exception as wf_err:
                err_msg = str(wf_err)
                logger.error(f"‚ùå Erreur lors de la cr√©ation de la t√¢che: {err_msg}")

                # ‚úÖ CORRECTION: Ne pas modifier le statut ici - laisser le workflow g√©rer
                # Le workflow mettra √† jour le statut correctement selon son ex√©cution
                
                # Gestion sp√©ciale pour les transitions de statut (ne devrait plus arriver)
                if "Invalid status transition" in err_msg:
                    logger.warning(f"‚ö†Ô∏è Transition de statut d√©tect√©e (ignor√©e): {err_msg}")
                    return {
                        "success": True,
                        "message": "T√¢che cr√©√©e avec avertissement (transition ignor√©e)",
                        "task_id": getattr(task_request, 'task_id', 'unknown'),
                        "warning": err_msg,
                        "status_code": 200
                    }

                # Relancer l'exception pour le gestionnaire global
                raise

            except Exception as e:
                error_msg = f"Erreur lors du traitement du webhook: {str(e)}"
                logger.error(error_msg, exc_info=True)

                # Gestion sp√©ciale pour les transitions de statut identiques
                if "Invalid status transition" in str(e):
                    logger.warning(f"‚ö†Ô∏è Transition de statut identique d√©tect√©e (webhook trait√© quand m√™me): {str(e)}")
                    await self._update_webhook_status(webhook_id, 'processed')
                    return {
                        "success": True,
                        "message": "Webhook trait√© (transition de statut identique ignor√©e)",
                        "warning": str(e),
                        "status_code": 200
                    }

                await self._update_webhook_status(webhook_id, 'failed', error_msg)

                return {
                    "success": False,
                    "error": error_msg,
                    "status_code": 500
                }
            finally:
                # ‚úÖ NOUVEAU: Lib√©rer le verrou apr√®s le traitement
                if webhook_signature in self._processing_locks:
                    del self._processing_locks[webhook_signature]
                    logger.debug(f"üîì Lib√©ration du verrou pour signature: {webhook_signature}")
        except Exception as e:
            logger.error(f"Erreur g√©n√©rale lors du traitement du webhook: {e}", exc_info=True)
            return {"success": False, "error": str(e), "status_code": 500}

    def _create_webhook_signature(self, payload: Dict[str, Any]) -> str:
        """Cr√©e une signature unique pour un webhook."""
        payload_str = json.dumps(payload, sort_keys=True).encode('utf-8')
        return hashlib.sha256(payload_str).hexdigest()

    def _cleanup_webhook_cache(self, current_time: float):
        """Nettoie le cache des webhooks qui ont expir√©."""
        expired_keys = [
            k for k, v in self._webhook_cache.items()
            if current_time - v['timestamp'] > self._cache_expiry
        ]
        for key in expired_keys:
            logger.debug(f"üßπ Nettoyage du cache webhook: {key}")
            del self._webhook_cache[key]

    def _validate_signature(self, payload: Dict[str, Any], signature: str) -> bool:
        """Valide la signature du webhook Monday.com."""

        try:
            # Monday.com utilise HMAC-SHA256
            payload_bytes = json.dumps(payload, sort_keys=True).encode('utf-8')

            expected_signature = hmac.new(
                self.settings.webhook_secret.encode('utf-8'),
                payload_bytes,
                hashlib.sha256
            ).hexdigest()

            # Comparer en toute s√©curit√©
            return hmac.compare_digest(signature, expected_signature)

        except Exception as e:
            logger.error(f"Erreur lors de la validation de signature: {e}")
            return False

    async def _save_webhook_event(self, payload: Dict[str, Any], signature: Optional[str] = None) -> int:
        """Sauvegarde le webhook en base de donn√©es."""
        try:
            conn = await get_db_connection()
            logger.debug("Connexion DB √©tablie pour sauvegarde webhook")

            result = await conn.fetchrow("""
                INSERT INTO webhook_events (source, event_type, payload, signature, processed, processing_status)
                VALUES ($1, $2, $3, $4, $5, $6)
                RETURNING webhook_events_id
            """,
                'monday',
                payload.get('event', {}).get('type'),
                json.dumps(payload),
                signature,
                False,
                'pending'
            )
            return result['webhook_events_id']
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde webhook en base: {e}")
            # Retourner un ID temporaire pour continuer le traitement
            return -1
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _save_task(self, task_request: TaskRequest) -> int:
        """Sauvegarde la t√¢che en base de donn√©es avec gestion des doublons am√©lior√©e."""
        try:
            conn = await get_db_connection()
            logger.debug("Connexion DB √©tablie pour sauvegarde t√¢che")

            # 1. V√©rifier si la t√¢che existe d√©j√† par monday_item_id
            existing_task = await conn.fetchrow("""
                SELECT tasks_id, internal_status, description, repository_url FROM tasks
                WHERE monday_item_id = $1
            """, int(task_request.task_id))

            if existing_task:
                logger.info(f"üìã T√¢che existante trouv√©e par ID: {existing_task['tasks_id']}, statut: {existing_task['internal_status']}")
                
                # ‚úÖ CORRECTION CRITIQUE: TOUJOURS mettre √† jour la description si elle a chang√©
                # (pour capturer les updates/commentaires Monday.com enrichis)
                needs_update = False
                updates = []
                params = []
                param_idx = 1
                
                # Mettre √† jour la description si:
                # 1. Elle est vide dans la DB ET on en a une nouvelle
                # 2. La nouvelle est PLUS LONGUE (enrichie avec updates)
                # ‚ö†Ô∏è PROTECTION: Ne JAMAIS √©craser une longue description par une plus courte
                if task_request.description and (
                    not existing_task['description'] or  # Cas 1: vide en DB
                    len(task_request.description) > len(existing_task['description'] or '')  # Cas 2: enrichie (plus longue)
                ):
                    updates.append(f"description = ${param_idx}")
                    params.append(task_request.description)
                    param_idx += 1
                    needs_update = True
                    logger.info(f"‚úÖ Mise √† jour de la description (ancienne: {len(existing_task['description'] or '')} chars ‚Üí nouvelle: {len(task_request.description)} chars)")
                    if "--- Commentaires et pr√©cisions additionnelles ---" in task_request.description:
                        logger.info("üìù Description enrichie avec des updates Monday.com d√©tect√©e")
                
                if not existing_task['repository_url'] and task_request.repository_url:
                    updates.append(f"repository_url = ${param_idx}")
                    params.append(task_request.repository_url)
                    param_idx += 1
                    needs_update = True
                    logger.info(f"‚úÖ Mise √† jour de l'URL du repository: {task_request.repository_url}")
                
                if needs_update:
                    params.append(existing_task['tasks_id'])
                    update_query = f"""
                        UPDATE tasks 
                        SET {', '.join(updates)}, updated_at = NOW()
                        WHERE tasks_id = ${param_idx}
                    """
                    await conn.execute(update_query, *params)
                    logger.info(f"üìù T√¢che {existing_task['tasks_id']} mise √† jour avec les nouvelles donn√©es")
                
                return existing_task['tasks_id']

            # 2. V√©rifier les doublons par titre + cr√©√© dans les 5 derni√®res minutes
            # (protection contre les webhooks multiples de Monday.com)
            similar_task = await conn.fetchrow("""
                SELECT tasks_id, monday_item_id, internal_status
                FROM tasks
                WHERE title = $1
                AND created_at >= NOW() - INTERVAL '5 minutes'
                AND internal_status IN ('pending', 'processing')
                ORDER BY created_at DESC
                LIMIT 1
            """, task_request.title)

            if similar_task:
                logger.warning("‚ö†Ô∏è T√¢che similaire d√©tect√©e dans les 5 derni√®res minutes:")
                logger.warning(f"   Existante: ID {similar_task['tasks_id']}, Monday ID {similar_task['monday_item_id']}")
                logger.warning(f"   Nouvelle: Monday ID {task_request.task_id}")
                logger.warning(f"   Titre: {task_request.title}")
                logger.warning("   üõë Duplication probable d√©tect√©e - utilisation de la t√¢che existante")
                return similar_task['tasks_id']

            # Cr√©er une nouvelle t√¢che
            result = await conn.fetchrow("""
                INSERT INTO tasks (
                    monday_item_id, monday_board_id, title, description, priority,
                    repository_url, repository_name, default_branch, internal_status
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                RETURNING tasks_id
            """,
                int(task_request.task_id),
                None,
                task_request.title,
                task_request.description,
                task_request.priority.value,
                task_request.repository_url or '',
                None,
                task_request.base_branch,
                'pending'  # Statut initial
            )
            logger.info(f"üìã Nouvelle t√¢che cr√©√©e: ID {result['tasks_id']}")
            return result['tasks_id']
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde t√¢che en base: {e}")
            raise
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _save_task_run(self, task_id: int, task_request: TaskRequest) -> int:
        """Sauvegarde le run en base de donn√©es avec gestion des doublons."""
        try:
            conn = await get_db_connection()

            # V√©rifier s'il y a d√©j√† un run actif pour cette t√¢che
            existing_run = await conn.fetchrow("""
                SELECT tasks_runs_id, status FROM task_runs
                WHERE task_id = $1 AND status IN ('started', 'running', 'pending')
                ORDER BY started_at DESC
                LIMIT 1
            """, task_id)

            if existing_run:
                logger.info(f"üìä Run existant trouv√©: ID {existing_run['tasks_runs_id']}, statut: {existing_run['status']}")
                return existing_run['tasks_runs_id']

            # Cr√©er un nouveau run
            result = await conn.fetchrow("""
                INSERT INTO task_runs (
                    task_id, status, git_branch_name, ai_provider
                ) VALUES ($1, $2, $3, $4)
                RETURNING tasks_runs_id
            """,
                task_id,
                'started',  # Statut 'started' au lieu de 'pending'
                task_request.branch_name,
                'claude'
            )
            logger.info(f"üìä Nouveau run cr√©√©: ID {result['tasks_runs_id']}")
            return result['tasks_runs_id']
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde run en base: {e}")
            raise
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _update_task_status(self, task_db_id: int, new_status: str):
        """Met √† jour le statut d'une t√¢che de mani√®re idempotente."""
        try:
            conn = await get_db_connection()

            # V√©rifier le statut actuel
            row = await conn.fetchrow("SELECT internal_status FROM tasks WHERE tasks_id=$1", task_db_id)

            if row and row["internal_status"] != new_status:
                await conn.execute(
                    "UPDATE tasks SET internal_status=$1, updated_at=NOW() WHERE tasks_id=$2",
                    new_status, task_db_id
                )
                logger.info(f"üìä Statut t√¢che {task_db_id} mis √† jour: {row['internal_status']} ‚Üí {new_status}")
            else:
                logger.debug(f"üìä Statut identique pour t√¢che {task_db_id}: {new_status}")
                # C'est normal - ne pas lever d'exception

        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour statut t√¢che {task_db_id}: {e}")
            # Ne pas relancer l'exception pour √©viter de faire √©chouer le traitement
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _update_webhook_status(self, webhook_id: int, status: str, error_message: Optional[str] = None, related_task_id: Optional[int] = None):
        """Met √† jour le statut du webhook."""
        try:
            conn = await get_db_connection()

            await conn.execute("""
                UPDATE webhook_events
                SET processing_status = $1,
                    error_message = $2,
                    related_task_id = $3,
                    processed = $4,
                    processed_at = CASE WHEN $4 THEN NOW() ELSE processed_at END
                WHERE webhook_events_id = $5
            """, status, error_message, related_task_id, status == 'processed', webhook_id)

        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour webhook {webhook_id}: {e}")
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _create_task_request(self, task_info: Dict[str, Any]) -> Optional[TaskRequest]:
        """Cr√©e une TaskRequest √† partir des informations d'une t√¢che Monday.com."""

        try:
            item_id = task_info.get("task_id", "")

            # ‚úÖ AM√âLIORATION: V√©rification pr√©coce des items de test
            if self._is_test_item(item_id):
                logger.info(f"‚ö†Ô∏è Item de test d√©tect√© ({item_id}) - Traitement simplifi√©")
                return self._create_test_task_request(task_info)

            # R√©cup√©rer les informations d√©taill√©es de l'item depuis Monday.com
            logger.info(f"üì• R√©cup√©ration des d√©tails pour l'item Monday.com: {item_id}")

            item_data = await self.monday_tool._get_item_info(item_id)

            if not item_data.get("success"):
                error_msg = item_data.get("error", "Erreur inconnue")
                logger.error(f"‚ùå Impossible de r√©cup√©rer les d√©tails de l'item {item_id}: {error_msg}")

                # ‚úÖ AM√âLIORATION: Gestion diff√©rentielle selon le type d'erreur
                if "non trouv√©" in error_msg or "supprim√©" in error_msg:
                    # L'item a probablement √©t√© supprim√© entre l'envoi du webhook et le traitement
                    logger.warning(f"‚ö†Ô∏è Item {item_id} supprim√© apr√®s envoi du webhook - Ceci peut arriver lors de suppressions rapides")
                    # Cr√©er une t√¢che minimale pour √©viter l'arr√™t complet du workflow
                    return self._create_fallback_task_request(task_info, f"Item supprim√©: {error_msg}")
                else:
                    # Autres erreurs (permissions, API down, etc.)
                    raise ValueError(f"Item Monday.com {item_id} inaccessible: {error_msg}")

            # Extraire les informations n√©cessaires
            title = item_data.get("name", task_info.get("title", "T√¢che sans titre"))

            # ‚úÖ AM√âLIORATION: Extraction de description plus robuste
            description = None

            # Fonction helper pour extraire texte s√©curis√©
            def safe_extract_column_text(column: Dict[str, Any]) -> str:
                """Extrait le texte d'une colonne Monday.com de mani√®re s√©curis√©e."""
                if not isinstance(column, dict):
                    return ""

                # Essayer plusieurs propri√©t√©s possibles dans l'ordre de priorit√©
                text_value = (
                    column.get("text") or
                    column.get("value") or
                    (column.get("display_value") if column.get("display_value") else "") or
                    ""
                ).strip()

                # Si c'est un dict dans value, essayer d'extraire le texte
                if not text_value and isinstance(column.get("value"), dict):
                    value_dict = column.get("value", {})
                    text_value = (
                        value_dict.get("text") or
                        value_dict.get("value") or
                        str(value_dict.get("display_value", ""))
                    ).strip()

                return text_value

            # DEBUG: Afficher toutes les colonnes disponibles
            if "column_values" in item_data:
                # ‚úÖ PROTECTION: Normaliser column_values en liste pour le traitement
                column_values_raw = item_data["column_values"]
                column_values = []
                
                if isinstance(column_values_raw, dict):
                    # Cas dict: transformer en liste en pr√©servant les IDs des colonnes
                    logger.debug(f"üîß column_values re√ßu comme dict, conversion en liste ({len(column_values_raw)} colonnes)")
                    for col_id, col_data in column_values_raw.items():
                        if isinstance(col_data, dict):
                            # Ajouter l'ID √† l'objet colonne s'il n'existe pas d√©j√†
                            if "id" not in col_data:
                                col_data["id"] = col_id
                            column_values.append(col_data)
                        else:
                            # Format inattendu: cr√©er un objet colonne basique
                            column_values.append({"id": col_id, "text": str(col_data), "value": col_data})
                elif isinstance(column_values_raw, list):
                    # Cas liste: utiliser directement
                    column_values = column_values_raw
                else:
                    # Cas anormal : type inattendu
                    logger.warning(f"‚ö†Ô∏è column_values type inattendu: {type(column_values_raw)}, fallback vers liste vide")
                    column_values = []

                # Afficher les colonnes pour debug
                column_names = [col.get("id", "no_id") for col in column_values if isinstance(col, dict)]
                logger.info(f"üîç DEBUG - Colonnes disponibles dans Monday.com: {column_names}")
                
                # Log d√©taill√© des colonnes pour debugging
                if column_names:
                    logger.info(f"üìã {len(column_names)} colonnes trouv√©es: {', '.join(column_names[:10])}{'...' if len(column_names) > 10 else ''}")
                
                # ‚úÖ VALIDATION: V√©rifier les colonnes importantes (pas bloquant)
                # On cherche des colonnes utiles mais ce n'est pas obligatoire car on peut
                # r√©cup√©rer les infos depuis les updates Monday.com
                important_columns = {
                    "link": "Repository URL (configur√©)",
                    "monday_doc_v2": "Documentation",
                    "task_owner": "Propri√©taire",
                    "task_status": "Statut"
                }
                
                found_important = []
                for col_id, description in important_columns.items():
                    if col_id in column_names:
                        found_important.append(f"{description} ({col_id})")
                
                if found_important:
                    logger.info(f"‚úÖ Colonnes utiles disponibles: {', '.join(found_important[:3])}")
                
                # Note: Les descriptions viennent des updates Monday.com, pas des colonnes

                # ‚úÖ AM√âLIORATION: Chercher la description avec plus de flexibilit√©
                description_candidates = []

                for col in column_values:
                    col_id = col.get("id", "").lower()
                    col_title = col.get("title", "").lower()
                    col_text = safe_extract_column_text(col)

                    # Logger les colonnes potentielles pour debug
                    if any(keyword in col_id for keyword in ["desc", "detail", "note", "comment", "text", "sujet"]) or \
                       any(keyword in col_title for keyword in ["desc", "detail", "note", "comment", "text", "sujet"]):
                        logger.info(f"üîç DEBUG - Colonne potentielle: id='{col.get('id')}', title='{col.get('title')}', text='{col_text[:50]}...'")

                        if col_text and len(col_text) > 10:  # Priorit√© aux descriptions substantielles
                            description_candidates.append((col_text, len(col_text), col.get("id")))

                # Choisir la meilleure description (la plus longue)
                if description_candidates:
                    description_candidates.sort(key=lambda x: x[1], reverse=True)  # Trier par longueur
                    description = description_candidates[0][0]
                    source_column = description_candidates[0][2]
                    logger.info(f"üìù Description s√©lectionn√©e depuis colonne '{source_column}': {description[:100]}...")

            # ‚úÖ AM√âLIORATION CRITIQUE: TOUJOURS r√©cup√©rer les updates/commentaires Monday.com
            # pour enrichir la description avec les pr√©cisions de l'utilisateur
            additional_context = []
            logger.info("üîç R√©cup√©ration des updates Monday.com pour enrichir le contexte...")
            try:
                # ‚úÖ CORRECTION: V√©rifier la configuration Monday.com avant l'appel
                if not hasattr(self.monday_tool, 'api_token') or not self.monday_tool.api_token:
                    logger.info("üí° Monday.com non configur√© - skip des updates")
                else:
                    updates_result = await self.monday_tool._arun(
                        action="get_item_updates",
                        item_id=task_info["task_id"]
                    )

                    if updates_result.get("success") and updates_result.get("updates"):
                        import re
                        # R√©cup√©rer TOUTES les updates pertinentes (pas seulement la premi√®re)
                        for update in updates_result["updates"][:10]:  # Maximum 10 updates r√©centes
                            update_body = update.get("body", "").strip()
                            if update_body and len(update_body) > 15:  # Filtrer les updates trop courtes
                                # Nettoyer le HTML si pr√©sent
                                clean_body = re.sub(r'<[^>]+>', '', update_body).strip()
                                if clean_body and len(clean_body) > 15:
                                    # Ajouter le cr√©ateur si disponible
                                    creator_name = update.get("creator", {}).get("name", "Utilisateur")
                                    additional_context.append(f"[{creator_name}]: {clean_body}")
                                    logger.info(f"üìù Update r√©cup√©r√©e de {creator_name}: {clean_body[:80]}...")
                        
                        if additional_context:
                            logger.info(f"‚úÖ {len(additional_context)} update(s) r√©cup√©r√©e(s) depuis Monday.com")
                    else:
                        logger.info("‚ÑπÔ∏è Aucune update trouv√©e dans Monday.com")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur r√©cup√©ration updates: {e}")

            # ‚úÖ FALLBACK 1: Si pas de description de base, utiliser la premi√®re update
            if not description and additional_context:
                description = additional_context[0]
                additional_context = additional_context[1:]  # Retirer la premi√®re qu'on a utilis√©e
                logger.info(f"üìù Description g√©n√©r√©e depuis premi√®re update: {description[:100]}...")

            # ‚úÖ FALLBACK 2: Utiliser le titre de la t√¢che comme description minimale
            if not description and title:
                description = f"T√¢che: {title}"
                logger.info(f"üìù Description g√©n√©r√©e depuis le titre: {description}")

            # ‚úÖ VALIDATION: S'assurer qu'on a au moins quelque chose
            if not description:
                description = "Description non disponible - Veuillez ajouter plus de d√©tails dans Monday.com"
                logger.warning("‚ö†Ô∏è Aucune description trouv√©e dans Monday.com apr√®s toutes les tentatives")

            # ‚úÖ ENRICHISSEMENT FINAL: Ajouter les commentaires/updates √† la description
            if additional_context:
                # Ajouter une section s√©par√©e pour les commentaires
                description += "\n\n--- Commentaires et pr√©cisions additionnelles ---\n"
                description += "\n".join(additional_context)
                logger.info(f"‚úÖ Description enrichie avec {len(additional_context)} commentaire(s) Monday.com")

            logger.info(f"üìÑ Description finale: {description[:100]}{'...' if len(description) > 100 else ''}")

            # Rechercher la branche Git
            git_branch = self._extract_column_value(item_data, "branche_git", "text")
            if not git_branch:
                git_branch = self._generate_branch_name(title)

            # Autres informations
            assignee = self._extract_column_value(item_data, "personne", "name")
            priority = self._extract_column_value(item_data, "priorite", "text", "medium")
            
            # ‚úÖ CORRECTION: Lire la colonne Repository URL configur√©e
            from config.settings import get_settings
            settings = get_settings()
            repository_url = ""
            
            # Essayer d'abord avec l'ID de colonne configur√©
            if settings.monday_repository_url_column_id:
                # Pour une colonne de type "link", essayer "url" et "text"
                repository_url = (
                    self._extract_column_value(item_data, settings.monday_repository_url_column_id, "url") or
                    self._extract_column_value(item_data, settings.monday_repository_url_column_id, "text") or
                    ""
                )
                if repository_url:
                    logger.info(f"üîó URL repository trouv√©e dans colonne configur√©e ({settings.monday_repository_url_column_id}): {repository_url}")
            
            # Fallback: essayer avec le nom g√©n√©rique
            if not repository_url:
                repository_url = self._extract_column_value(item_data, "repo_url", "text") or ""
                if repository_url:
                    logger.info(f"üîó URL repository trouv√©e dans colonne 'repo_url': {repository_url}")

            # Pr√©parer les donn√©es de base de la t√¢che
            base_task_data = {
                "task_id": task_info["task_id"],
                "title": title,
                "description": description,
                "branch_name": git_branch,
                "repository_url": repository_url,
                "priority": priority,
                "assignee": assignee
            }

            # Enrichir avec les informations extraites de la description
            logger.info(f"üìù Analyse de la description pour enrichissement: {description[:100]}...")
            logger.info(f"üîó URL de base (avant enrichissement): {repository_url}")

            enriched_data = enrich_task_with_description_info(base_task_data, description)

            final_url = enriched_data.get("repository_url", "")
            if final_url != repository_url:
                logger.info(f"üéØ URL GitHub finale (apr√®s enrichissement): {final_url}")
            else:
                logger.info(f"üìù URL GitHub finale (inchang√©e): {final_url}")

            # Validation critique: URL GitHub obligatoire
            if not final_url or not final_url.strip():
                error_msg = "‚ùå ERREUR CRITIQUE: Aucune URL GitHub trouv√©e dans la description ni dans les colonnes Monday.com"
                logger.error(error_msg)
                logger.error("üí° SOLUTION: Ajoutez l'URL GitHub dans la description de la t√¢che Monday.com")
                logger.error("üìù EXEMPLE: 'Impl√©mente login JWT pour: https://github.com/user/repo'")

                raise ValueError(
                    "URL GitHub manquante. "
                    "Veuillez sp√©cifier l'URL GitHub dans la description de la t√¢che Monday.com. "
                    "Exemple: 'Impl√©mente login pour: https://github.com/user/repo'"
                )

            # ‚úÖ AJOUT: V√©rifier la d√©duplication avant de cr√©er la t√¢che
            task_id = enriched_data["task_id"]

            # V√©rifier si une t√¢che similaire est d√©j√† en cours
            if hasattr(self, '_active_tasks'):
                if task_id in self._active_tasks:
                    logger.warning(f"‚ö†Ô∏è T√¢che {task_id} d√©j√† en cours - ignorer webhook dupliqu√©")
                    return None
            else:
                self._active_tasks = set()

            # Marquer la t√¢che comme active
            self._active_tasks.add(task_id)

            # Cr√©er la requ√™te de t√¢che avec les donn√©es enrichies
            task_request = TaskRequest(
                task_id=enriched_data["task_id"],
                title=enriched_data["title"],
                description=enriched_data["description"],
                branch_name=enriched_data["branch_name"],
                repository_url=enriched_data["repository_url"],
                priority=enriched_data["priority"],
                files_to_modify=enriched_data.get("files_to_modify")
            )

            logger.info(f"üìã T√¢che cr√©√©e: {task_request.title} (Branche: {task_request.branch_name})")

            # ‚úÖ AJOUT: Programmer le nettoyage de la t√¢che apr√®s un d√©lai
            # Cela √©vite les fuites m√©moire et permet de refaire la t√¢che plus tard si n√©cessaire
            import asyncio
            asyncio.create_task(self._cleanup_task_later(task_id, delay_minutes=10))

            return task_request

        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation de la requ√™te de t√¢che: {e}")
            return None

    async def _cleanup_task_later(self, task_id: str, delay_minutes: int = 10):
        """Nettoie une t√¢che de la liste des t√¢ches actives apr√®s un d√©lai."""
        import asyncio
        await asyncio.sleep(delay_minutes * 60)  # Attendre le d√©lai en secondes

        if hasattr(self, '_active_tasks') and task_id in self._active_tasks:
            self._active_tasks.discard(task_id)
            logger.info(f"üßπ Nettoyage t√¢che {task_id} de la liste des t√¢ches actives")

    def _extract_column_value(self, item_data: Dict[str, Any], column_name: str,
                            value_type: str = "text", default: Any = None) -> Any:
        """Extrait une valeur de colonne Monday.com."""

        try:
            column_values = item_data.get("column_values", [])

            # ‚úÖ PROTECTION: Normaliser column_values en liste
            if isinstance(column_values, dict):
                # Format dict normal de l'API Monday.com
                logger.debug(f"üîß _extract_column_value: Conversion dict ‚Üí liste ({len(column_values)} colonnes)")
                column_values = list(column_values.values())
            elif not isinstance(column_values, list):
                # Type inattendu
                logger.warning(f"‚ö†Ô∏è _extract_column_value: Type column_values inattendu: {type(column_values)}")
                column_values = []

            for column in column_values:
                if (column.get("id", "").lower() == column_name.lower() or
                    column_name.lower() in column.get("id", "").lower()):

                    if value_type == "text":
                        return column.get("text", default)
                    elif value_type == "value":
                        return column.get("value", default)
                    elif value_type == "name":
                        value = column.get("value")
                        if value and isinstance(value, dict):
                            return value.get("name", default)
                        return default

            return default

        except Exception as e:
            logger.warning(f"Erreur extraction colonne {column_name}: {e}")
            return default

    def _generate_branch_name(self, title: str) -> str:
        """G√©n√®re un nom de branche Git √† partir du titre de la t√¢che."""

        import re

        clean_title = re.sub(r'[^\w\s-]', '', title.lower())
        clean_title = re.sub(r'\s+', '-', clean_title.strip())

        if len(clean_title) > 50:
            clean_title = clean_title[:50].rstrip('-')

        branch_name = f"feature/{clean_title}"
        timestamp = datetime.now().strftime("%m%d")
        branch_name += f"-{timestamp}"

        return branch_name

    def _is_test_item(self, item_id: str) -> bool:
        """V√©rifie si l'item est un item de test (par exemple, un item avec un ID sp√©cifique)."""
        # Ajoutez ici les conditions pour d√©tecter les items de test
        # Par exemple, si l'ID de l'item contient "test" ou "sandbox"
        return "test" in item_id.lower() or "sandbox" in item_id.lower()

    def _create_test_task_request(self, task_info: Dict[str, Any]) -> Optional[TaskRequest]:
        """Cr√©e une requ√™te de t√¢che pour un item de test."""
        logger.warning(f"üß™ Cr√©ation d'une requ√™te de t√¢che pour un item de test: {task_info.get('item_id')}")

        title = f"Test Task - {task_info.get('item_id', 'N/A')}"
        description = f"This is a test task created for item ID: {task_info.get('item_id', 'N/A')}. Please ignore."
        git_branch = self._generate_branch_name(title)
        repository_url = "" # Pas d'URL GitHub pour les items de test
        priority = "medium"
        assignee = None

        task_request = TaskRequest(
            task_id=task_info["task_id"],
            title=title,
            description=description,
            branch_name=git_branch,
            repository_url=repository_url,
            priority=priority,
            files_to_modify=[]
        )
        logger.info(f"üìã Requ√™te de t√¢che de test cr√©√©e: {task_request.title}")
        return task_request

    def _create_fallback_task_request(self, task_info: Dict[str, Any], error_reason: str) -> TaskRequest:
        """Cr√©e une TaskRequest de fallback pour des items inaccessibles."""

        item_id = task_info.get("task_id", "unknown")
        title = task_info.get("title", f"T√¢che {item_id}")

        logger.info(f"üîÑ Cr√©ation t√¢che fallback pour item {item_id}: {error_reason}")

        # Cr√©er une t√¢che minimale mais fonctionnelle
        fallback_task = TaskRequest(
            task_id=item_id,
            title=f"[ITEM INACCESSIBLE] {title}",
            description=f"""‚ö†Ô∏è **Item Monday.com inaccessible**

**Raison**: {error_reason}

**Action**: Cette t√¢che a √©t√© cr√©√©e automatiquement car l'item Monday.com original n'√©tait plus accessible lors du traitement du webhook.

**Informations disponibles du webhook**:
- ID Item: {item_id}
- Titre: {title}
- Type: {task_info.get('task_type', 'N/A')}
- Priorit√©: {task_info.get('priority', 'N/A')}

**Recommandation**: V√©rifiez l'√©tat de l'item dans Monday.com et relancez manuellement si n√©cessaire.""",
            branch_name=self._generate_branch_name(f"fallback-{item_id}"),
            repository_url=getattr(self.settings, "default_repo_url", "") or "",
            priority=task_info.get("priority", "low"),  # Priorit√© basse pour les fallbacks
            task_type="analysis"  # Utiliser un type valide pour les fallbacks
        )

        return fallback_task

    async def handle_task_completion(self, task_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """G√®re la completion d'une t√¢che."""

        try:
            success = result.get("success", False)
            pr_url = result.get("pr_url")

            if success and pr_url:
                update_result = await self.monday_tool._arun(
                    action="complete_task",
                    item_id=task_id,
                    pr_url=pr_url
                )
            else:
                status = "Bloqu√©" if not success else "√Ä v√©rifier"

                error_summary = ""
                if result.get("error_summary"):
                    error_summary = " | ".join(result["error_summary"][:3])

                comment = f"""‚ùå **Impl√©mentation automatique √©chou√©e**

Erreurs rencontr√©es: {error_summary}

Intervention manuelle requise."""

                status_result = await self.monday_tool._arun(
                    action="update_item_status",
                    item_id=task_id,
                    status=status
                )

                comment_result = await self.monday_tool._arun(
                    action="add_comment",
                    item_id=task_id,
                    comment=comment
                )

                update_result = {
                    "success": status_result.get("success", False) and comment_result.get("success", False)
                }

            return update_result

        except Exception as e:
            logger.error(f"Erreur lors de la gestion de completion: {e}")
            return {"success": False, "error": str(e)}

    async def cleanup_stuck_tasks(self):
        """Nettoie les t√¢ches rest√©es en processing trop longtemps."""
        try:
            conn = await get_db_connection()

            result = await conn.execute("""
                UPDATE tasks
                SET internal_status = 'failed',
                    updated_at = NOW()
                WHERE internal_status = 'processing'
                AND updated_at < NOW() - INTERVAL '1 hour'
            """)

            logger.info(f"üßπ T√¢ches bloqu√©es nettoy√©es: {result}")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du cleanup des t√¢ches: {e}")
        finally:
            if 'conn' in locals():
                await conn.close()

    async def _check_duplicate_webhook(self, payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """V√©rifie si un webhook similaire a d√©j√† √©t√© trait√© r√©cemment."""
        try:
            # Extraire l'identifiant de la t√¢che du payload
            if 'event' not in payload:
                return None

            event = payload['event']
            pulse_id = event.get('pulseId')
            pulse_name = event.get('pulseName', '')
            event_type = event.get('type')

            if not pulse_id or not pulse_name:
                return None

            conn = await get_db_connection()

            # Chercher des webhooks similaires trait√©s dans les 5 derni√®res minutes
            # ‚úÖ AM√âLIORATION : Recherche par pulse_id (plus fiable que le titre)
            # Fen√™tre de 5 minutes pour √©viter les doublons pendant tout le workflow
            similar_webhook = await conn.fetchrow("""
                SELECT
                    webhook_events_id,
                    processed_at,
                    processing_status
                FROM webhook_events
                WHERE processing_status = 'processed'
                AND received_at >= NOW() - INTERVAL '5 minutes'
                AND payload::jsonb -> 'event' ->> 'pulseId' = $1
                ORDER BY received_at DESC
                LIMIT 1
            """, str(pulse_id))

            await conn.close()

            return similar_webhook

        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification doublon webhook: {e}")
            return None
