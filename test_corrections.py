#!/usr/bin/env python3
"""
Script de test pour vÃ©rifier les corrections apportÃ©es au systÃ¨me AI-Agent.

Ce script teste :
1. La correction de la sÃ©rialisation JSON dans database_persistence_service
2. La rÃ©cupÃ©ration du rÃ©pertoire de travail dans les nÅ“uds
3. La crÃ©ation de PR aprÃ¨s validation humaine
4. La configuration de logging Celery
"""

import asyncio
import json
import os
import tempfile
import logging
from unittest.mock import Mock, patch
from typing import Dict, Any

# Import des modules Ã  tester
from services.database_persistence_service import DatabasePersistenceService
from utils.helpers import get_working_directory, validate_working_directory, ensure_working_directory
from services.pull_request_service import pr_service
from services.logging_service import logging_service
from models.state import GraphState
from models.schemas import TaskRequest, TaskPriority, TaskType


def test_json_serialization():
    """Test la correction de la sÃ©rialisation JSON."""
    print("ğŸ§ª Test 1: SÃ©rialisation JSON corrigÃ©e")
    
    persistence = DatabasePersistenceService()
    
    # Test avec un dictionnaire normal
    normal_dict = {"test": "value", "number": 42}
    cleaned = persistence._clean_for_json_serialization(normal_dict)
    print(f"  âœ… Dict normal: {cleaned}")
    
    # Test avec un objet complexe
    class ComplexObject:
        def __init__(self):
            self.attribute = "value"
            self.nested = {"inner": "data"}
    
    complex_obj = ComplexObject()
    cleaned_complex = persistence._clean_for_json_serialization(complex_obj)
    print(f"  âœ… Objet complexe: {cleaned_complex}")
    
    # Test de sÃ©rialisation JSON complÃ¨te
    try:
        json_str = json.dumps(cleaned_complex)
        print(f"  âœ… SÃ©rialisation JSON rÃ©ussie: {len(json_str)} caractÃ¨res")
    except Exception as e:
        print(f"  âŒ Erreur sÃ©rialisation: {e}")
        return False
    
    print("  âœ… Test sÃ©rialisation JSON: RÃ‰USSI\n")
    return True


def test_working_directory_recovery():
    """Test la rÃ©cupÃ©ration du rÃ©pertoire de travail."""
    print("ğŸ§ª Test 2: RÃ©cupÃ©ration du rÃ©pertoire de travail")
    
    # CrÃ©er un rÃ©pertoire temporaire pour les tests
    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"  ğŸ“ RÃ©pertoire temporaire crÃ©Ã©: {temp_dir}")
        
        # Test 1: Ã‰tat avec working_directory au niveau racine
        state1 = {
            "working_directory": temp_dir,
            "results": {}
        }
        
        wd1 = get_working_directory(state1)
        print(f"  âœ… RÃ©cupÃ©ration niveau racine: {wd1}")
        assert wd1 == temp_dir, f"Expected {temp_dir}, got {wd1}"
        
        # Test 2: Ã‰tat avec working_directory dans results
        state2 = {
            "results": {
                "working_directory": temp_dir,
                "prepare_result": {"working_directory": temp_dir}
            }
        }
        
        wd2 = get_working_directory(state2)
        print(f"  âœ… RÃ©cupÃ©ration depuis results: {wd2}")
        assert wd2 == temp_dir, f"Expected {temp_dir}, got {wd2}"
        
        # Test 3: Validation du rÃ©pertoire
        is_valid = validate_working_directory(temp_dir, "test_node")
        print(f"  âœ… Validation rÃ©pertoire: {is_valid}")
        assert is_valid, "Le rÃ©pertoire temporaire devrait Ãªtre valide"
        
        # Test 4: ensure_working_directory avec rÃ©cupÃ©ration
        state3 = {
            "results": {
                "prepare_result": {"working_directory": temp_dir}
            }
        }
        
        ensured_wd = ensure_working_directory(state3, "test_")
        print(f"  âœ… RÃ©pertoire assurÃ©: {ensured_wd}")
        assert os.path.exists(ensured_wd), "Le rÃ©pertoire assurÃ© devrait exister"
    
    print("  âœ… Test rÃ©cupÃ©ration rÃ©pertoire de travail: RÃ‰USSI\n")
    return True


async def test_pr_creation():
    """Test la crÃ©ation de PR aprÃ¨s validation."""
    print("ğŸ§ª Test 3: CrÃ©ation de PR aprÃ¨s validation")
    
    # Mock des outils GitHub
    with patch('nodes.merge_node.GitHubTool') as mock_github_tool:
        # Configurer le mock pour retourner un succÃ¨s
        mock_instance = Mock()
        # Le mock doit retourner une coroutine
        async def mock_arun(*args, **kwargs):
            return {
                "success": True,
                "pr_number": 123,
                "pr_url": "https://github.com/test/repo/pull/123"
            }
        mock_instance._arun = mock_arun
        mock_github_tool.return_value = mock_instance
        
        # CrÃ©er un Ã©tat de test
        task_request = TaskRequest(
            task_id="test_task",
            title="Test PR Creation",
            description="Test description for PR creation",
            priority=TaskPriority.MEDIUM,
            task_type=TaskType.FEATURE,
            repository_url="https://github.com/test/repo"
        )
        
        # CrÃ©er un rÃ©pertoire temporaire rÃ©el pour le test
        with tempfile.TemporaryDirectory() as temp_dir:
            state = GraphState(
                task=task_request,
                results={
                    "working_directory": temp_dir,
                    "git_result": {
                        "branch_name": "feature/test-branch"
                    },
                    "modified_files": ["test_file.py"],
                    "test_results": [{"success": True}],
                    "qa_results": {"overall_score": 85}
                }
            )
            
            # Tester la crÃ©ation de PR
            result = await pr_service.ensure_pull_request_created(state)
            
            print(f"  âœ… RÃ©sultat crÃ©ation PR: {result}")
            assert result.success, f"La crÃ©ation de PR devrait rÃ©ussir: {result.error}"
            assert result.pr_info.number == 123, "Le numÃ©ro de PR devrait Ãªtre 123"
            
            # VÃ©rifier les propriÃ©tÃ©s du PR crÃ©Ã©
            assert result.pr_info.number == 123, "Le numÃ©ro de PR devrait Ãªtre 123"
            assert result.pr_info.url == "https://github.com/test/repo/pull/123", "L'URL devrait Ãªtre correcte"
            assert result.pr_info.branch == "feature/test-branch", "La branche devrait Ãªtre correcte"
        
    print("  âœ… Test crÃ©ation PR: RÃ‰USSI\n")
    return True


def test_celery_logging_config():
    """Test la configuration du logging Celery."""
    print("ğŸ§ª Test 4: Configuration du logging Celery")
    
    # CrÃ©er un rÃ©pertoire temporaire pour les logs
    with tempfile.TemporaryDirectory() as temp_dir:
        # Changer temporairement le rÃ©pertoire de travail
        original_cwd = os.getcwd()
        os.chdir(temp_dir)
        
        try:
            # Tester la configuration du logging
            logging_service.setup_logging()
            
            # VÃ©rifier que le rÃ©pertoire logs a Ã©tÃ© crÃ©Ã©
            logs_info = logging_service.get_logs_info()
            logs_dir = logs_info['logs_directory']
            assert os.path.exists(logs_dir), "Le rÃ©pertoire logs devrait Ãªtre crÃ©Ã©"
            print(f"  âœ… RÃ©pertoire logs crÃ©Ã©: {logs_dir}")
            
            # VÃ©rifier que des handlers ont Ã©tÃ© crÃ©Ã©s
            assert logs_info['handlers_count'] > 0, "Des handlers devraient Ãªtre crÃ©Ã©s"
            print(f"  âœ… Handlers crÃ©Ã©s: {logs_info['handlers']}")
            
            # âœ… NOUVEAU: VÃ©rifier le fichier logs.txt principal
            main_log_file = logs_info['main_log_file']
            assert main_log_file is not None, "Le fichier logs.txt devrait Ãªtre configurÃ©"
            print(f"  âœ… Fichier logs.txt configurÃ©: {main_log_file}")
            
            # Tester qu'un logger existe et fonctionne
            logger = logging.getLogger('ai_agent_background')
            logger.info("Test message for logs.txt file")
            assert len(logger.handlers) > 0, "Le logger devrait avoir des handlers"
            print(f"  âœ… Logger configurÃ© avec {len(logger.handlers)} handlers")
            
            # VÃ©rifier que le fichier logs.txt a Ã©tÃ© crÃ©Ã©
            if os.path.exists(main_log_file):
                file_size = os.path.getsize(main_log_file)
                print(f"  âœ… Fichier logs.txt crÃ©Ã©: {file_size} bytes")
                
                # VÃ©rifier le contenu
                with open(main_log_file, 'r') as f:
                    content = f.read()
                    if "Test message for logs.txt file" in content:
                        print(f"  âœ… Message de test trouvÃ© dans logs.txt")
                    else:
                        print(f"  âš ï¸ Message de test non trouvÃ© dans logs.txt")
            else:
                print(f"  âš ï¸ Fichier logs.txt non crÃ©Ã© encore")
            
            # VÃ©rifier le fichier de mÃ©tadonnÃ©es
            metadata_file = os.path.join(logs_dir, "session_metadata.json")
            if os.path.exists(metadata_file):
                print(f"  âœ… MÃ©tadonnÃ©es session crÃ©Ã©es: {metadata_file}")
            else:
                print(f"  âš ï¸ MÃ©tadonnÃ©es session non crÃ©Ã©es (peut Ãªtre normal)")
            print(f"  âœ… Configuration logging: OK")
            
        finally:
            os.chdir(original_cwd)
    
    print("  âœ… Test configuration logging Celery: RÃ‰USSI\n")
    return True


def test_error_handling():
    """Test la gestion d'erreurs amÃ©liorÃ©e."""
    print("ğŸ§ª Test 5: Gestion d'erreurs amÃ©liorÃ©e")
    
    # Test 1: Validation de rÃ©pertoire inexistant
    fake_dir = "/path/that/does/not/exist"
    is_valid = validate_working_directory(fake_dir, "test_node")
    assert not is_valid, "Un rÃ©pertoire inexistant ne devrait pas Ãªtre valide"
    print(f"  âœ… Validation rÃ©pertoire inexistant: {not is_valid}")
    
    # Test 2: get_working_directory avec Ã©tat vide
    empty_state = {}
    wd_empty = get_working_directory(empty_state)
    assert wd_empty is None, "Ã‰tat vide devrait retourner None"
    print(f"  âœ… Ã‰tat vide: {wd_empty is None}")
    
    # Test 3: SÃ©rialisation d'objet non-sÃ©rialisable
    persistence = DatabasePersistenceService()
    
    class NonSerializable:
        def __init__(self):
            self.func = lambda x: x  # Les fonctions ne sont pas sÃ©rialisables
    
    non_ser = NonSerializable()
    cleaned = persistence._clean_for_json_serialization(non_ser)
    print(f"  âœ… Objet non-sÃ©rialisable nettoyÃ©: {type(cleaned)}")
    
    # Le rÃ©sultat devrait Ãªtre un dict avec les attributs convertis
    assert isinstance(cleaned, dict), "Le rÃ©sultat devrait Ãªtre un dict"
    
    print("  âœ… Test gestion d'erreurs: RÃ‰USSI\n")
    return True


async def main():
    """Fonction principale qui lance tous les tests."""
    print("ğŸ§ª DÃ‰MARRAGE DES TESTS DE CORRECTION AI-AGENT")
    print("=" * 60)
    
    tests = [
        ("SÃ©rialisation JSON", test_json_serialization),
        ("RÃ©cupÃ©ration rÃ©pertoire de travail", test_working_directory_recovery),
        ("CrÃ©ation PR", test_pr_creation),
        ("Configuration logging Celery", test_celery_logging_config),
        ("Gestion d'erreurs", test_error_handling),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"  âŒ Erreur dans {test_name}: {e}")
            results.append((test_name, False))
    
    # RÃ©sumÃ© des rÃ©sultats
    print("=" * 60)
    print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… RÃ‰USSI" if result else "âŒ Ã‰CHOUÃ‰"
        print(f"{test_name:.<50} {status}")
        if result:
            passed += 1
    
    print("=" * 60)
    print(f"ğŸ¯ RÃ‰SULTAT GLOBAL: {passed}/{total} tests rÃ©ussis")
    
    if passed == total:
        print("ğŸ‰ TOUS LES TESTS SONT RÃ‰USSIS ! Les corrections sont fonctionnelles.")
        return True
    else:
        print("âš ï¸ Certains tests ont Ã©chouÃ©. VÃ©rifiez les corrections.")
        return False


if __name__ == "__main__":
    import sys
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 