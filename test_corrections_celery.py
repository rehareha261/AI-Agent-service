#!/usr/bin/env python3
"""Script de test pour v√©rifier les corrections des probl√®mes Celery."""

import asyncio
import json
import time
import hashlib
from typing import Dict, Any
from services.webhook_service import WebhookService
from services.monitoring_service import monitoring_service
from models.schemas import TaskRequest
from utils.logger import get_logger

logger = get_logger(__name__)

class CeleryFixesTest:
    """Tests pour v√©rifier les corrections des probl√®mes Celery."""
    
    def __init__(self):
        self.webhook_service = WebhookService()
        self.test_results = []
        
    async def test_duplicate_webhook_prevention(self):
        """Test de pr√©vention des webhooks dupliqu√©s."""
        logger.info("üß™ Test 1: Pr√©vention des webhooks dupliqu√©s")
        
        # Cr√©er un webhook de test
        test_payload = {
            "event": {
                "pulseId": "test_duplicate_123",
                "boardId": "987654321",
                "pulseName": "Test duplication",
                "columnValues": {}
            },
            "type": "create_pulse"
        }
        
        try:
            # Premier appel
            start_time = time.time()
            result1 = await self.webhook_service.process_webhook(test_payload)
            end_time = time.time()
            
            logger.info(f"Premier webhook trait√© en {end_time - start_time:.2f}s")
            logger.info(f"R√©sultat 1: {result1}")
            
            # Deuxi√®me appel imm√©diat (devrait √™tre bloqu√©)
            start_time = time.time()
            result2 = await self.webhook_service.process_webhook(test_payload)
            end_time = time.time()
            
            logger.info(f"Deuxi√®me webhook trait√© en {end_time - start_time:.2f}s")
            logger.info(f"R√©sultat 2: {result2}")
            
            # V√©rifier que le deuxi√®me a √©t√© d√©dupliqu√©
            is_deduplicated = result2.get('deduplicated', False) or result2.get('task_exists', False)
            
            if is_deduplicated:
                logger.info("‚úÖ Test d√©duplication r√©ussi - webhook dupliqu√© bloqu√©")
                self.test_results.append({
                    "test": "duplicate_prevention",
                    "status": "passed",
                    "message": "Webhook dupliqu√© correctement bloqu√©"
                })
            else:
                logger.warning("‚ö†Ô∏è Test d√©duplication √©chou√© - webhook dupliqu√© trait√©")
                self.test_results.append({
                    "test": "duplicate_prevention", 
                    "status": "failed",
                    "message": "Webhook dupliqu√© non bloqu√©"
                })
                
        except Exception as e:
            logger.error(f"‚ùå Erreur test d√©duplication: {e}")
            self.test_results.append({
                "test": "duplicate_prevention",
                "status": "error", 
                "message": str(e)
            })
    
    async def test_monitoring_resilience(self):
        """Test de r√©silience du monitoring."""
        logger.info("üß™ Test 2: R√©silience du monitoring")
        
        try:
            # V√©rifier que le monitoring est actif
            initial_status = monitoring_service.is_monitoring_active
            logger.info(f"Statut initial du monitoring: {initial_status}")
            
            if not initial_status:
                # D√©marrer le monitoring
                await monitoring_service.start_monitoring()
                await asyncio.sleep(2)  # Laisser le temps de d√©marrer
            
            # V√©rifier les t√¢ches en arri√®re-plan
            background_tasks_count = len(monitoring_service.background_tasks)
            logger.info(f"Nombre de t√¢ches de monitoring: {background_tasks_count}")
            
            # Attendre quelques secondes pour voir si les t√¢ches restent actives
            await asyncio.sleep(10)
            
            # V√©rifier que les t√¢ches sont toujours actives
            active_tasks = sum(1 for task in monitoring_service.background_tasks if not task.done())
            logger.info(f"T√¢ches actives apr√®s 10s: {active_tasks}/{background_tasks_count}")
            
            if active_tasks >= 3:  # Au moins 3 t√¢ches principales + watchdog
                logger.info("‚úÖ Test monitoring r√©ussi - t√¢ches restent actives")
                self.test_results.append({
                    "test": "monitoring_resilience",
                    "status": "passed",
                    "message": f"{active_tasks} t√¢ches de monitoring actives"
                })
            else:
                logger.warning("‚ö†Ô∏è Test monitoring √©chou√© - t√¢ches termin√©es pr√©matur√©ment")
                self.test_results.append({
                    "test": "monitoring_resilience",
                    "status": "failed",
                    "message": f"Seulement {active_tasks} t√¢ches actives"
                })
                
        except Exception as e:
            logger.error(f"‚ùå Erreur test monitoring: {e}")
            self.test_results.append({
                "test": "monitoring_resilience",
                "status": "error",
                "message": str(e)
            })
    
    async def test_webhook_signature_generation(self):
        """Test de g√©n√©ration de signature webhook."""
        logger.info("üß™ Test 3: G√©n√©ration de signatures webhook")
        
        try:
            # Cr√©er des webhooks identiques
            payload1 = {
                "event": {"pulseId": "123", "pulseName": "Test"},
                "type": "create_pulse"
            }
            payload2 = {
                "event": {"pulseId": "123", "pulseName": "Test"},
                "type": "create_pulse"
            }
            
            # Tester la g√©n√©ration de signature
            signature1 = self.webhook_service._create_webhook_signature(payload1)
            signature2 = self.webhook_service._create_webhook_signature(payload2)
            
            logger.info(f"Signature 1: {signature1[:16]}...")
            logger.info(f"Signature 2: {signature2[:16]}...")
            
            if signature1 == signature2:
                logger.info("‚úÖ Test signatures r√©ussi - signatures identiques pour payloads identiques")
                self.test_results.append({
                    "test": "signature_generation",
                    "status": "passed",
                    "message": "Signatures correctement g√©n√©r√©es"
                })
            else:
                logger.warning("‚ö†Ô∏è Test signatures √©chou√© - signatures diff√©rentes")
                self.test_results.append({
                    "test": "signature_generation",
                    "status": "failed",
                    "message": "Signatures incoh√©rentes"
                })
                
            # Test avec payloads diff√©rents
            payload3 = {
                "event": {"pulseId": "456", "pulseName": "Test Different"},
                "type": "create_pulse"
            }
            signature3 = self.webhook_service._create_webhook_signature(payload3)
            
            if signature1 != signature3:
                logger.info("‚úÖ Signatures diff√©rentes pour payloads diff√©rents")
            else:
                logger.warning("‚ö†Ô∏è Signatures identiques pour payloads diff√©rents")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur test signatures: {e}")
            self.test_results.append({
                "test": "signature_generation",
                "status": "error",
                "message": str(e)
            })
    
    async def test_webhook_cache_cleanup(self):
        """Test de nettoyage du cache webhook."""
        logger.info("üß™ Test 4: Nettoyage du cache webhook")
        
        try:
            # Ajouter des entr√©es dans le cache
            old_timestamp = time.time() - 400  # Plus de 5 minutes (300s)
            recent_timestamp = time.time() - 100  # Moins de 5 minutes
            
            self.webhook_service._webhook_cache = {
                "old_signature": {"timestamp": old_timestamp, "task_id": "old_task"},
                "recent_signature": {"timestamp": recent_timestamp, "task_id": "recent_task"}
            }
            
            logger.info(f"Cache initial: {len(self.webhook_service._webhook_cache)} entr√©es")
            
            # D√©clencher le nettoyage
            self.webhook_service._cleanup_webhook_cache(time.time())
            
            remaining_count = len(self.webhook_service._webhook_cache)
            logger.info(f"Cache apr√®s nettoyage: {remaining_count} entr√©es")
            
            # V√©rifier que seules les entr√©es r√©centes restent
            if remaining_count == 1 and "recent_signature" in self.webhook_service._webhook_cache:
                logger.info("‚úÖ Test nettoyage cache r√©ussi")
                self.test_results.append({
                    "test": "cache_cleanup",
                    "status": "passed",
                    "message": "Cache nettoy√© correctement"
                })
            else:
                logger.warning("‚ö†Ô∏è Test nettoyage cache √©chou√©")
                self.test_results.append({
                    "test": "cache_cleanup",
                    "status": "failed", 
                    "message": f"Cache non nettoy√© correctement: {remaining_count} entr√©es restantes"
                })
                
        except Exception as e:
            logger.error(f"‚ùå Erreur test nettoyage cache: {e}")
            self.test_results.append({
                "test": "cache_cleanup",
                "status": "error",
                "message": str(e)
            })
    
    async def run_all_tests(self):
        """Ex√©cute tous les tests."""
        logger.info("üöÄ D√©marrage des tests de correction Celery")
        
        # Tests s√©quentiels
        await self.test_webhook_signature_generation()
        await self.test_webhook_cache_cleanup()
        await self.test_duplicate_webhook_prevention()
        await self.test_monitoring_resilience()
        
        # R√©sum√© des r√©sultats
        logger.info("\nüìä R√âSUM√â DES TESTS")
        logger.info("=" * 50)
        
        passed = sum(1 for result in self.test_results if result["status"] == "passed")
        failed = sum(1 for result in self.test_results if result["status"] == "failed")
        errors = sum(1 for result in self.test_results if result["status"] == "error")
        total = len(self.test_results)
        
        for result in self.test_results:
            status_emoji = {"passed": "‚úÖ", "failed": "‚ùå", "error": "üí•"}.get(result["status"], "‚ùì")
            logger.info(f"{status_emoji} {result['test']}: {result['message']}")
        
        logger.info(f"\nTotal: {total} tests")
        logger.info(f"R√©ussites: {passed}")
        logger.info(f"√âchecs: {failed}")
        logger.info(f"Erreurs: {errors}")
        
        success_rate = (passed / total * 100) if total > 0 else 0
        logger.info(f"Taux de r√©ussite: {success_rate:.1f}%")
        
        if success_rate >= 75:
            logger.info("üéâ Tests majoritairement r√©ussis - corrections efficaces")
        else:
            logger.warning("‚ö†Ô∏è Tests en √©chec - corrections n√©cessaires")
        
        return {
            "total": total,
            "passed": passed,
            "failed": failed,
            "errors": errors,
            "success_rate": success_rate,
            "details": self.test_results
        }

async def main():
    """Point d'entr√©e principal."""
    tester = CeleryFixesTest()
    results = await tester.run_all_tests()
    
    # Sauvegarder les r√©sultats
    with open("test_corrections_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    logger.info("üìÅ R√©sultats sauv√©s dans test_corrections_results.json")
    return results

if __name__ == "__main__":
    asyncio.run(main()) 