# -*- coding: utf-8 -*-
"""
Test du m√©canisme de fallback Anthropic ‚Üí OpenAI.

Ce script teste:
1. Fallback automatique quand Anthropic √©choue
2. Utilisation normale d'Anthropic quand disponible
3. Gestion des erreurs et logs appropri√©s
"""

import sys
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

from ai.llm.llm_factory import (
    get_llm,
    get_llm_with_fallback,
    get_default_llm_with_fallback
)
from config.settings import get_settings
from utils.logger import get_logger

logger = get_logger(__name__)


def test_1_anthropic_direct():
    """Test 1: Utilisation directe d'Anthropic."""
    print("\n" + "="*70)
    print("TEST 1: Utilisation directe d'Anthropic")
    print("="*70)
    
    try:
        llm = get_llm(provider="anthropic")
        print(f"‚úÖ LLM Anthropic cr√©√©: {type(llm).__name__}")
        
        # Test simple
        response = llm.invoke("R√©ponds juste 'OK' en un mot.")
        print(f"‚úÖ R√©ponse d'Anthropic: {response.content[:50]}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur Anthropic: {e}")
        return False


def test_2_openai_direct():
    """Test 2: Utilisation directe d'OpenAI."""
    print("\n" + "="*70)
    print("TEST 2: Utilisation directe d'OpenAI")
    print("="*70)
    
    try:
        llm = get_llm(provider="openai")
        print(f"‚úÖ LLM OpenAI cr√©√©: {type(llm).__name__}")
        
        # Test simple
        response = llm.invoke("R√©ponds juste 'OK' en un mot.")
        print(f"‚úÖ R√©ponse d'OpenAI: {response.content[:50]}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur OpenAI: {e}")
        return False


def test_3_fallback_anthropic_to_openai():
    """Test 3: Fallback automatique Anthropic ‚Üí OpenAI."""
    print("\n" + "="*70)
    print("TEST 3: Fallback automatique Anthropic ‚Üí OpenAI")
    print("="*70)
    
    try:
        # Cr√©er un LLM avec fallback
        llm = get_llm_with_fallback(
            primary_provider="anthropic",
            fallback_providers=["openai"],
            temperature=0.1
        )
        print(f"‚úÖ LLM avec fallback cr√©√©: {type(llm).__name__}")
        
        # Tester une requ√™te
        response = llm.invoke("R√©ponds juste 'OK' en un mot.")
        print(f"‚úÖ R√©ponse re√ßue: {response.content[:50]}")
        print(f"‚ÑπÔ∏è  Type de r√©ponse: {type(response)}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur fallback: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_4_default_llm_with_fallback():
    """Test 4: Utilisation du LLM par d√©faut avec fallback."""
    print("\n" + "="*70)
    print("TEST 4: LLM par d√©faut avec fallback (depuis settings)")
    print("="*70)
    
    try:
        settings = get_settings()
        print(f"‚ÑπÔ∏è  Provider par d√©faut: {settings.default_ai_provider}")
        print(f"‚ÑπÔ∏è  Anthropic key pr√©sente: {bool(settings.anthropic_api_key)}")
        print(f"‚ÑπÔ∏è  OpenAI key pr√©sente: {bool(settings.openai_api_key)}")
        
        # Cr√©er le LLM par d√©faut
        llm = get_default_llm_with_fallback(temperature=0.1)
        print(f"‚úÖ LLM par d√©faut cr√©√©: {type(llm).__name__}")
        
        # Tester une requ√™te
        response = llm.invoke("R√©ponds juste 'OK' en un mot.")
        print(f"‚úÖ R√©ponse re√ßue: {response.content[:50]}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur LLM par d√©faut: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_5_simulate_anthropic_failure():
    """Test 5: Simuler une d√©faillance Anthropic pour tester le fallback."""
    print("\n" + "="*70)
    print("TEST 5: Simulation d√©faillance Anthropic (fallback forc√©)")
    print("="*70)
    
    try:
        # Sauvegarder la cl√© Anthropic originale
        settings = get_settings()
        original_key = settings.anthropic_api_key
        
        # Temporairement invalider la cl√© Anthropic
        settings.anthropic_api_key = "sk-ant-invalid-key-for-testing"
        
        print("‚ö†Ô∏è  Cl√© Anthropic temporairement invalid√©e")
        print("‚ö†Ô∏è  Le syst√®me DEVRAIT basculer automatiquement vers OpenAI...")
        
        try:
            # Tenter de cr√©er un LLM avec fallback
            llm = get_llm_with_fallback(
                primary_provider="anthropic",
                fallback_providers=["openai"],
                temperature=0.1
            )
            print(f"‚úÖ LLM cr√©√© malgr√© l'erreur Anthropic: {type(llm).__name__}")
            
            # Restaurer la cl√© originale
            settings.anthropic_api_key = original_key
            
            # Le fallback devrait avoir √©t√© activ√©
            print("‚úÖ Fallback fonctionne! Le syst√®me a bascul√© vers OpenAI")
            return True
        except Exception as e:
            # Restaurer la cl√© originale m√™me en cas d'erreur
            settings.anthropic_api_key = original_key
            print(f"‚ùå Fallback n'a pas fonctionn√©: {e}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur lors du test de simulation: {e}")
        return False


def test_6_verify_fallback_chain():
    """Test 6: V√©rifier la cha√Æne de fallback dans LangChain."""
    print("\n" + "="*70)
    print("TEST 6: V√©rification de la cha√Æne de fallback LangChain")
    print("="*70)
    
    try:
        from langchain_core.runnables import RunnableWithFallbacks
        
        # Cr√©er un LLM avec fallback
        llm = get_llm_with_fallback(
            primary_provider="anthropic",
            fallback_providers=["openai"]
        )
        
        # V√©rifier si c'est bien un RunnableWithFallbacks
        if isinstance(llm, RunnableWithFallbacks):
            print(f"‚úÖ Type correct: RunnableWithFallbacks")
            print(f"‚úÖ Fallback correctement configur√©")
            
            # Tester la cha√Æne
            response = llm.invoke("Test")
            print(f"‚úÖ Cha√Æne de fallback fonctionnelle")
            return True
        else:
            print(f"‚ö†Ô∏è  Type: {type(llm).__name__} (pas de fallback d√©tect√©)")
            print(f"‚ÑπÔ∏è  Cela peut √™tre normal si fallback n'est pas n√©cessaire")
            return True
    except Exception as e:
        print(f"‚ùå Erreur cha√Æne de fallback: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """Ex√©cuter tous les tests."""
    print("\n" + "="*70)
    print("üß™ TESTS DU M√âCANISME DE FALLBACK ANTHROPIC ‚Üí OPENAI")
    print("="*70)
    
    results = {
        "test_1_anthropic_direct": False,
        "test_2_openai_direct": False,
        "test_3_fallback": False,
        "test_4_default_llm": False,
        "test_5_simulate_failure": False,
        "test_6_verify_chain": False
    }
    
    # Test 1: Anthropic direct
    results["test_1_anthropic_direct"] = test_1_anthropic_direct()
    
    # Test 2: OpenAI direct
    results["test_2_openai_direct"] = test_2_openai_direct()
    
    # Test 3: Fallback automatique
    results["test_3_fallback"] = test_3_fallback_anthropic_to_openai()
    
    # Test 4: LLM par d√©faut
    results["test_4_default_llm"] = test_4_default_llm_with_fallback()
    
    # Test 5: Simulation d√©faillance
    results["test_5_simulate_failure"] = test_5_simulate_anthropic_failure()
    
    # Test 6: V√©rification cha√Æne
    results["test_6_verify_chain"] = test_6_verify_fallback_chain()
    
    # R√©sum√©
    print("\n" + "="*70)
    print("üìä R√âSUM√â DES TESTS")
    print("="*70)
    
    total = len(results)
    passed = sum(1 for v in results.values() if v)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} - {test_name}")
    
    print("\n" + "-"*70)
    print(f"R√©sultat: {passed}/{total} tests r√©ussis ({(passed/total)*100:.1f}%)")
    print("="*70)
    
    if passed == total:
        print("\nüéâ TOUS LES TESTS SONT PASS√âS!")
        print("‚úÖ Le m√©canisme de fallback fonctionne correctement")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) ont √©chou√©")
        print("‚ùå V√©rifiez les logs ci-dessus pour plus de d√©tails")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)

