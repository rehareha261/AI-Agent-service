#!/usr/bin/env python3
"""Test final pour valider toutes les corrections du workflow Monday.com."""

import asyncio
from datetime import datetime, timedelta, timezone
from services.monday_validation_service import MondayValidationService
from graph.workflow_graph import _should_merge_or_debug_after_monday_validation
from models.state import GraphState
from config.workflow_limits import WorkflowLimits

async def test_all_workflow_fixes():
    """Test final de toutes les corrections du workflow."""
    
    print("üß™ Test final des corrections du workflow Monday.com")
    
    # Test 1: V√©rifier les nouvelles limites
    print(f"\n‚úÖ Test 1 - Nouvelles limites:")
    print(f"   MAX_NODES_SAFETY_LIMIT: {WorkflowLimits.MAX_NODES_SAFETY_LIMIT}")
    print(f"   MAX_DEBUG_ATTEMPTS: {WorkflowLimits.MAX_DEBUG_ATTEMPTS}")
    
    # Test 2: Validation des r√©ponses humaines avec BOM
    print(f"\n‚úÖ Test 2 - Validation r√©ponses avec BOM:")
    validation_service = MondayValidationService()
    
    # Tester les r√©ponses avec caract√®res invisibles
    test_cases = [
        ("\ufeffdebug", True, "debug avec BOM"),
        ("<p>\ufeffdebug</p>", True, "debug avec BOM et HTML"),
        ("\u200boui", True, "oui avec caract√®re invisible"),
        ("non", True, "non standard"),
        ("valide", True, "valide standard"),
        ("random text", False, "texte non-validation"),
    ]
    
    for reply_text, expected, description in test_cases:
        result = validation_service._is_validation_reply(reply_text)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"   {status} {description}: '{repr(reply_text)}' ‚Üí {result}")
    
    # Test 3: Logique de d√©cision apr√®s validation Monday
    print(f"\n‚úÖ Test 3 - Logique de d√©cision apr√®s validation:")
    
    test_scenarios = [
        # Cas: oui + pas de probl√®mes ‚Üí merge
        {
            "human_validation_status": "approved",
            "test_results": {"success": True, "failed_tests": []},
            "expected": "merge",
            "description": "oui + aucun probl√®me"
        },
        # Cas: oui + probl√®mes d√©tect√©s ‚Üí debug automatique  
        {
            "human_validation_status": "approved", 
            "test_results": {"success": False, "failed_tests": ["test1", "test2"]},
            "expected": "debug",
            "description": "oui + probl√®mes d√©tect√©s ‚Üí debug forc√©"
        },
        # Cas: non/debug ‚Üí debug OpenAI
        {
            "human_validation_status": "debug",
            "test_results": {"success": False, "failed_tests": ["test1"]},
            "expected": "debug", 
            "description": "debug demand√© par humain"
        },
        # Cas: timeout/erreur ‚Üí update seulement
        {
            "human_validation_status": "error",
            "test_results": {"success": False, "failed_tests": []},
            "expected": "update_only",
            "description": "erreur/timeout ‚Üí update seulement"
        }
    ]
    
    for scenario in test_scenarios:
        # Cr√©er un √©tat de test
        state = {
            "results": {
                "human_validation_status": scenario["human_validation_status"],
                "test_results": [scenario["test_results"]],
                "has_errors": len(scenario["test_results"].get("failed_tests", [])) > 0
            }
        }
        
        decision = _should_merge_or_debug_after_monday_validation(state)
        status = "‚úÖ" if decision == scenario["expected"] else "‚ùå"
        print(f"   {status} {scenario['description']}: {scenario['human_validation_status']} ‚Üí {decision}")
    
    # Test 4: Gestion des erreurs de permissions Monday.com
    print(f"\n‚úÖ Test 4 - Gestion permissions Monday.com:")
    
    # Simuler une r√©ponse d'erreur de permissions
    mock_results = {
        "ai_messages": ["Test task completed"],
        "test_results": [{"success": False, "failed_tests": ["test1"]}]
    }
    
    try:
        # Tester avec un item qui pourrait avoir des probl√®mes de permissions
        update_id = await validation_service.post_validation_update("test_item_12345", mock_results)
        print(f"   ‚úÖ Gestion gracieuse des erreurs: update_id = {update_id}")
        
        # V√©rifier que l'update_id est cr√©√© m√™me en cas d'erreur
        if update_id and "failed_update" in update_id:
            print(f"   ‚úÖ Update_id de secours cr√©√© correctement")
        elif update_id:
            print(f"   ‚úÖ Update_id normal cr√©√©: {update_id}")
        else:
            print(f"   ‚ùå Aucun update_id cr√©√©")
            
    except Exception as e:
        print(f"   ‚ùå Exception non g√©r√©e: {e}")
    
    # Test 5: V√©rifier que le workflow peut maintenant d√©passer 25 n≈ìuds
    print(f"\n‚úÖ Test 5 - Limite de n≈ìuds augment√©e:")
    print(f"   Ancienne limite: 25 n≈ìuds")
    print(f"   Nouvelle limite: {WorkflowLimits.MAX_NODES_SAFETY_LIMIT} n≈ìuds")
    print(f"   ‚úÖ Augmentation de {WorkflowLimits.MAX_NODES_SAFETY_LIMIT - 25} n≈ìuds pour permettre les boucles")
    
    print(f"\nüéâ Tous les tests des corrections termin√©s !")
    print(f"\nüìã **R√©sum√© des corrections appliqu√©es:**")
    print(f"   1. ‚úÖ Correction du BOM dans les r√©ponses Monday.com")
    print(f"   2. ‚úÖ Fixation des probl√®mes de timezone (UTC)")
    print(f"   3. ‚úÖ Augmentation limite n≈ìuds: 25 ‚Üí {WorkflowLimits.MAX_NODES_SAFETY_LIMIT}")
    print(f"   4. ‚úÖ R√©duction MAX_DEBUG_ATTEMPTS: 3 ‚Üí {WorkflowLimits.MAX_DEBUG_ATTEMPTS}")
    print(f"   5. ‚úÖ Gestion gracieuse des erreurs de permissions Monday.com")
    print(f"   6. ‚úÖ Logique am√©lior√©e: 'oui' + probl√®mes ‚Üí debug automatique")

if __name__ == "__main__":
    asyncio.run(test_all_workflow_fixes()) 